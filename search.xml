<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>How to Read a Computer Science Research Paper</title>
    <url>/2022/03/19/HowToReadCSPaper/</url>
    <content><![CDATA[<h3 id="Publication-Venues"><a href="#Publication-Venues" class="headerlink" title="Publication Venues"></a>Publication Venues</h3><ul>
<li>General : ACM , IEEE , AAAI , ACL</li>
<li>Specifically Recommended By CCF : <strong><a href="https://www.ccf.org.cn/Academic_Evaluation/By_category/">https://www.ccf.org.cn/Academic_Evaluation/By_category/</a></strong></li>
</ul>
<blockquote>
<p>中国计算机学会（China Computer Federation）</p>
</blockquote>
<h3 id="Different-Types-of-CS-Research-Paper"><a href="#Different-Types-of-CS-Research-Paper" class="headerlink" title="Different Types of CS Research Paper"></a>Different Types of CS Research Paper</h3><p>There are three basic types of CS research paper: <strong>theoretical</strong>, <strong>engineering</strong> and <strong>empirical</strong>.</p>
<ul>
<li>A theoretical paper describes a theory or algorithm or provides a mathematical proof for some hypothesis.</li>
<li>An engineering paper describes an implementation of an algorithm, or part or all of a computer system or application. Engineering papers are now frequently required to include descriptions of system evaluation.</li>
<li>An empirical paper describes an experiment designed to test some hypothesis.</li>
</ul>
<span id="more"></span>



<h3 id="Taxonomy-of-Scientific-Papers"><a href="#Taxonomy-of-Scientific-Papers" class="headerlink" title="Taxonomy of Scientific Papers"></a>Taxonomy of Scientific Papers</h3><ul>
<li><p>Conference Papers</p>
<ul>
<li><p>Review : YES , peer-reviewed , the threshold depends on the conference</p>
</li>
<li><p>Goal : Publish a finished work with possible forthcoming research</p>
</li>
<li><p>Size : 8 - 20 Pages</p>
</li>
</ul>
</li>
<li><p>Journal Papers</p>
<ul>
<li><p>Review : YES , peer-reviewed , more longer than Conference Papers</p>
</li>
<li><p>Goal : Publish a present completed work</p>
</li>
<li><p>Size : 15 Pages</p>
</li>
</ul>
</li>
</ul>
<h3 id="How-call-I-tell-whether-a-research-paper-is-good-before-I-read-it"><a href="#How-call-I-tell-whether-a-research-paper-is-good-before-I-read-it" class="headerlink" title="How call I tell whether a research paper is good before I read it?"></a>How call I tell whether a research paper is good before I read it?</h3><p>Here are some indicators of a good research paper:</p>
<ul>
<li><ol>
<li>The problem the paper addresses is clearly stated, both in the abstract and early on in the paper itself. The technical importance and broader impacts of the paper are described. </li>
</ol>
</li>
<li><ol start="2">
<li>The paper includes a clear description of the experiment, system or theory the problem addresses. This is usually the second section of the paper. </li>
</ol>
</li>
<li><ol start="3">
<li>The paper describes and analyzes the results of the work described (either experimental or evaluation results).</li>
</ol>
</li>
<li><ol start="4">
<li>The authors have some sound, non-trivial ideas for future work. This usually appears at the end of the paper. </li>
</ol>
</li>
<li><ol start="5">
<li>Related work is described and cited correctly. You can get an idea of this by looking at the list of references at the end of the paper. </li>
</ol>
</li>
</ul>
<p>If you know that a researcher has been working in an area for a while, that is usually an indicator that the research is sound; however, do not underestimate the contributions of people new to a field or the impact of politics on research.</p>
<h3 id="Read-with-“three-pass”-method"><a href="#Read-with-“three-pass”-method" class="headerlink" title="Read with “three-pass” method"></a>Read with “three-pass” method</h3><p>The key idea is that you should read the paper in up to three passes, instead of starting at the beginning and plowing your way to the end. Each pass accomplishes specific goals and builds upon the previous pass:</p>
<ul>
<li>The first pass gives you a <strong>general idea</strong> about the paper.</li>
<li>The second pass lets you <strong>grasp the paper’s content</strong>, but not its details. </li>
<li>The third pass helps you <strong>understand the paper in depth</strong>.　</li>
</ul>
<h4 id="THE-FIRST-PASS"><a href="#THE-FIRST-PASS" class="headerlink" title="THE FIRST PASS"></a>THE FIRST PASS</h4><p>This pass should take about five to ten minutes and consists of the following steps:</p>
<ol>
<li> Carefully read the <strong>title</strong>, <strong>abstract</strong>, and <strong>introduction</strong> </li>
<li> Read the section and sub-section <strong>headings</strong>, but ignore everything else </li>
<li> Read the <strong>conclusions</strong></li>
<li> Glance over the <strong>references</strong>, mentally ticking off the ones you’ve already read</li>
</ol>
<h4 id="THE-SECOND-PASS"><a href="#THE-SECOND-PASS" class="headerlink" title="THE SECOND PASS"></a>THE SECOND PASS</h4><ol>
<li><strong>Look carefully at the figures, diagrams and other illustrations in the paper</strong>. Pay special attention to graphs. Are the axes properly labeled? Are results shown with error bars, so that conclusions are statistically significant? Common mistakes like these will separate rushed, shoddy work from the truly excellent. </li>
<li><strong>Remember to mark relevant unread references for further reading</strong> (this is a good way to learn more about the background of the paper).</li>
</ol>
<p>The second pass should take up to an hour.</p>
<h4 id="THE-THIRD-PASS"><a href="#THE-THIRD-PASS" class="headerlink" title="THE THIRD PASS"></a>THE THIRD PASS</h4><p>This pass requires great attention to detail. <strong>You should identify and challenge every assumption in every statement.</strong> Moreover, you should think about how you yourself would present a particular idea. This comparison of the actual with the virtual lends a sharp insight into the proof and presentation techniques in the paper and you can very likely add this to your repertoire of tools. During this pass, you should also jot down ideas for future work.</p>
<p>This pass can take about four or five hours for beginners, and about an hour for an experienced reader.</p>
]]></content>
      <categories>
        <category>兴趣</category>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>IDEA常用快捷键</title>
    <url>/2021/03/25/IDEA%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/</url>
    <content><![CDATA[<table>
<thead>
<tr>
<th>快捷键</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>Alt+Enter</td>
<td>导入包，错误修复</td>
</tr>
<tr>
<td>Ctrl+Y</td>
<td>删除当前行</td>
</tr>
<tr>
<td>Ctrl+D</td>
<td>复制当前行</td>
</tr>
<tr>
<td>Ctrl+Alt+L（自定义：Alt+F）</td>
<td>格式化代码</td>
</tr>
<tr>
<td>Ctrl+/</td>
<td>单行注释</td>
</tr>
<tr>
<td>Ctrl+Shift+/</td>
<td>多行注释</td>
</tr>
<tr>
<td>Alt+Insert</td>
<td>自动生成代码，get，set方法</td>
</tr>
<tr>
<td>ALt+Shift+上下箭头</td>
<td>移动当前代码行</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>学习</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title>JavaSE重点</title>
    <url>/2021/04/14/JavaSE%E9%87%8D%E7%82%B9/</url>
    <content><![CDATA[<h5 id="1-error-和-exception-有啥区别"><a href="#1-error-和-exception-有啥区别" class="headerlink" title="1.error 和 exception 有啥区别"></a>1.error 和 exception 有啥区别</h5><h5 id="2-hash-扩容"><a href="#2-hash-扩容" class="headerlink" title="2.hash 扩容"></a>2.hash 扩容</h5><span id="more"></span>

<hr>
<h5 id="3-Java-和-JavaScript-有啥区别"><a href="#3-Java-和-JavaScript-有啥区别" class="headerlink" title="3.Java 和 JavaScript 有啥区别"></a>3.Java 和 JavaScript 有啥区别</h5><blockquote>
<p><a href="http://www.ruanyifeng.com/blog/2011/06/birth_of_javascript.html">http://www.ruanyifeng.com/blog/2011/06/birth_of_javascript.html</a></p>
</blockquote>
<ul>
<li><p>它们的相同之处包括：</p>
<ul>
<li>它们的语法和 C 语言都很相似；</li>
<li>它们都是面向对象的（虽然实现的方式略有不同）；</li>
<li>JavaScript 在设计时参照了 Java 的命名规则；   </li>
</ul>
</li>
<li><p>它们的不同之处包括：</p>
<ul>
<li> JavaScript 是动态类型语言，而 Java 是静态类型语言；</li>
<li>JavaScript 是弱类型的，Java 属于强类型；</li>
<li>JavaScript 的面向对象是基于原型的（prototype-based）实现的，Java 是基于类（class-based）的；</li>
</ul>
</li>
</ul>
<hr>
<h5 id="4-final，finally，finalized-的区别"><a href="#4-final，finally，finalized-的区别" class="headerlink" title="4.final，finally，finalized 的区别"></a>4.final，finally，finalized 的区别</h5><h5 id="5-final的特点及应用"><a href="#5-final的特点及应用" class="headerlink" title="5.final的特点及应用"></a>5.final的特点及应用</h5><p>final可以修饰类/方法/局部变量/成员变量</p>
<ul>
<li><p>对于类来说：如果用final修饰，则当前类不能有任何子类，那么其中的所有成员方法都不能覆盖重写</p>
</li>
<li><p>对于方法来说：当用final来修饰方法时，则该方法是最终方法。</p>
</li>
</ul>
<blockquote>
<p>注意：对于类与方法来说，abstract与final不能同时使用。</p>
</blockquote>
<ul>
<li>对于局部变量来说：一次赋值，终身不变。同时，对于基本数据类型来说，不可变说的是数据不变。对于引用类型来说，不可变说的是地址值不变。</li>
<li> 对于成员变量来说：一定要进行手动赋值，要么通过构造方法赋值，要么直接赋值。</li>
</ul>
<hr>
<h5 id="6-修饰符使用范围"><a href="#6-修饰符使用范围" class="headerlink" title="6.修饰符使用范围"></a>6.修饰符使用范围</h5><table>
<thead>
<tr>
<th>关键字</th>
<th>private</th>
<th>default</th>
<th>protected</th>
<th>public</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>本类当中/我自己</td>
<td>同一个包/我邻居</td>
<td>不同包子类/我儿子</td>
<td>不同包不同类/陌生人</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>学习</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>基础语法</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux常见命令</title>
    <url>/2021/03/23/Linux%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h4 id="常见命令："><a href="#常见命令：" class="headerlink" title="常见命令："></a>常见命令：</h4><p>pwd ： 查看当前路径</p>
<p>ls : 查看当前目录文件夹</p>
<p>mkdir ：创建<strong>文件夹</strong></p>
<p>rm：删除文件</p>
<p>touch：创建<strong>文件</strong></p>
<p>lsof -i：查看占用端口的进程</p>
<p>cd -：返回上一级目录</p>
<p>cd ~：返回home目录</p>
<p>cd /：返回root目录</p>
]]></content>
      <categories>
        <category>学习</category>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Typora入门技巧</title>
    <url>/2021/03/22/Typora%E5%85%A5%E9%97%A8%E6%8A%80%E5%B7%A7/</url>
    <content><![CDATA[<p>本篇文章主要就是记录一下MarkDown语法。md语法在所有支持 <code>.md</code> 的软件都是通用的，而快捷键是在<code>Typora</code>软件中适用的。</p>
<ol>
<li><strong>使用  <code>Ctrl+Shift+K</code>创建代码块：</strong> </li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">右下角 [选择语言]  ：</span><br><span class="line">                  输入 java &#x2F; c++ &#x2F; shell &#x2F; javascript 等任意语言</span><br></pre></td></tr></table></figure>



<span id="more"></span>

<ol start="2">
<li><strong>使用   <code>&gt;</code>   进行引用，效果如下：</strong></li>
</ol>
<blockquote>
<p>   引用内容</p>
</blockquote>
<ol start="3">
<li><strong>使用  <code>#</code> 更改标题大小</strong></li>
</ol>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># 一级标题</span><br><span class="line">## 二级标题</span><br><span class="line">### 三级标题</span><br></pre></td></tr></table></figure>



<ol start="4">
<li><strong>更改字体格式</strong></li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">斜体        *文字内容*</span><br><span class="line">加粗       **文字内容**</span><br><span class="line">删除线      ~~文字内容~~</span><br></pre></td></tr></table></figure>

<blockquote>
<p> <em>斜体</em>            <strong>加粗</strong>             <del>删除线</del></p>
</blockquote>
<ol start="5">
<li><strong>使用 <code>Ctrl+T</code> 建立表格</strong></li>
</ol>
<table>
<thead>
<tr>
<th align="left">快捷键</th>
<th align="left">功能</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Ctrl + T</td>
<td align="left">新建表格</td>
</tr>
<tr>
<td align="left">双击Enter</td>
<td align="left">清除所有格式，另起一行</td>
</tr>
<tr>
<td align="left">Ctrl+U</td>
<td align="left"><u>下划线</u></td>
</tr>
<tr>
<td align="left">Ctrl+B</td>
<td align="left"><strong>加粗</strong></td>
</tr>
<tr>
<td align="left">Ctrl+I</td>
<td align="left"><em>斜体</em></td>
</tr>
</tbody></table>
<ol start="6">
<li><strong>使用 <code>---</code>进行分割</strong></li>
</ol>
<hr>
<p>创建一条分割线   —</p>
<hr>
<ol start="7">
<li><strong>图片插入</strong>:  <code>Ctrl+Shift+I</code></li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//本地图片</span></span><br><span class="line">[自定义图片名称]（图片路径）</span><br><span class="line">    </span><br><span class="line">ex: [我的照片]（/images/pic/mine.jpg）</span><br></pre></td></tr></table></figure>



<ol start="8">
<li><strong>超链接</strong>：<code>Ctrl+K</code></li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//超链接语法</span></span><br><span class="line"></span><br><span class="line">[我的blog](https:<span class="comment">//eniac286.github.io/)</span></span><br></pre></td></tr></table></figure>

<p>ex： <a href="https://eniac286.github.io/">我的blog</a></p>
<ol start="9">
<li><strong>列表</strong></li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//无序列表：+ - * 均可创建</span></span><br><span class="line">- 目录<span class="number">1</span></span><br><span class="line">+ 目录<span class="number">2</span></span><br><span class="line">* 目录<span class="number">3</span></span><br></pre></td></tr></table></figure>

<ul>
<li>目录1   </li>
</ul>
<ul>
<li>目录2</li>
<li>目录3</li>
</ul>
<ol start="10">
<li><strong>使用  <code>ctrl+shift+` </code>   创建特殊标记 ：</strong></li>
</ol>
<p>无特殊标记      <code>有特殊标记</code></p>
]]></content>
      <categories>
        <category>工具</category>
        <category>Typora</category>
      </categories>
      <tags>
        <tag>Typora</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/26/java%E5%85%AB%E8%82%A1%E6%96%87-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<h2 id="一、理解设计模式"><a href="#一、理解设计模式" class="headerlink" title="一、理解设计模式"></a>一、理解设计模式</h2><h3 id="理解设计模式"><a href="#理解设计模式" class="headerlink" title="理解设计模式"></a>理解设计模式</h3><p>设计模式是软件开发人员经过长时间试错和应用总结出来的，解决特定问题的一系列方法。可以迅速提高代码的<strong>可读性、健壮性、扩展性。</strong></p>
<p>参考链接：<a href="https://tech.meituan.com/2022/03/10/interesting-talk-about-design-patterns.html">https://tech.meituan.com/2022/03/10/interesting-talk-about-design-patterns.html</a></p>
<blockquote>
<p><strong>策略模式</strong>定义了一系列的算法，并将每一个算法封装起来，使它们可以相互替换。策略模式通常包含以下角色：1</p>
<ul>
<li>抽象策略（Strategy）类：定义了一个公共接口，各种不同的算法以不同的方式实现这个接口，环境角色使用这个接口调用不同的算法，一般使用接口或抽象类实现。</li>
<li>具体策略（Concrete Strategy）类：实现了抽象策略定义的接口，提供具体的算法实现。</li>
<li>环境（Context）类：持有一个策略类的引用，最终给客户端调用。</li>
</ul>
</blockquote>
<blockquote>
<p><strong>适配器模式</strong>：将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。适配器模式包含以下主要角色：</p>
<ul>
<li>目标（Target）接口：当前系统业务所期待的接口，它可以是抽象类或接口。</li>
<li>适配者（Adaptee）类：它是被访问和适配的现存组件库中的组件接口。</li>
<li>适配器（Adapter）类：它是一个转换器，通过继承或引用适配者的对象，把适配者接口转换成目标接口，让客户按目标接口的格式访问适配者。</li>
</ul>
</blockquote>
<blockquote>
<p><strong>单例模式</strong>：设计模式属于创建型模式，它提供了一种创建对象的最佳方式。</p>
<ul>
<li>这种模式涉及到一个单一的类，该类负责创建自己的对象，</li>
<li>同时确保只有单个对象被创建。</li>
<li>这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。</li>
</ul>
</blockquote>
<h3 id="七大基本原则（SOLID）："><a href="#七大基本原则（SOLID）：" class="headerlink" title="七大基本原则（SOLID）："></a>七大基本原则（SOLID）：</h3><ol>
<li>单一职责原则 (Single Responsibility Principle)</li>
<li>开放-关闭原则 (Open-Closed Principle)</li>
<li>里氏替换原则 (Liskov Substitution Principle)</li>
<li>依赖倒转原则 (Dependence Inversion Principle)</li>
<li>接口隔离原则 (Interface Segregation Principle)</li>
<li>迪米特法则（Law Of Demeter）</li>
<li>组合/聚合复用原则 (Composite/Aggregate Reuse Principle)</li>
</ol>
<p>参考链接： <a href="https://zhuanlan.zhihu.com/p/24614363">https://zhuanlan.zhihu.com/p/24614363</a></p>
<h3 id="1-单例模式"><a href="#1-单例模式" class="headerlink" title="1.单例模式"></a>1.单例模式</h3><p>单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。</p>
<p>这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。</p>
<p><strong>注意：</strong></p>
<ul>
<li><p>1、单例类只能有一个实例。</p>
</li>
<li><p>2、单例类必须自己创建自己的唯一实例。</p>
</li>
<li><p>3、单例类必须给所有其他对象提供这一实例。</p>
</li>
</ul>
<p><strong>懒汉式(线程不安全)：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Singleton instance;  </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;  </span><br><span class="line">            instance = <span class="keyword">new</span> Singleton();  </span><br><span class="line">        &#125;  </span><br><span class="line">        <span class="keyword">return</span> instance;  </span><br><span class="line">    &#125;  </span><br></pre></td></tr></table></figure>

<p>**懒汉式(线程安全)**：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span></span>&#123;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> instance;</span><br><span class="line">	<span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span></span>&#123;&#125;;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> Singleton <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line">	 	<span class="keyword">if</span>(instance == <span class="keyword">null</span>)&#123;</span><br><span class="line">	 		instance = <span class="keyword">new</span> Singleton();</span><br><span class="line">	 	&#125;</span><br><span class="line">	 	<span class="keyword">return</span> instance;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>饿汉式(线程不安全):</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class Singleton&#123;</span><br><span class="line">	private static final instance &#x3D; new Singleton();</span><br><span class="line">	private singleton()&#123;&#125;;</span><br><span class="line">	public static Singleton getInstance()&#123;</span><br><span class="line">		return instance;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>双检锁/双重校验锁（DCL，即 double-checked locking）</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> instance;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span></span>&#123;&#125;;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(instance == <span class="keyword">null</span>)&#123;</span><br><span class="line">            synchronize(Singleton.class)&#123;</span><br><span class="line">                instance = <span class="keyword">new</span> Singleton();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-代理模式"><a href="#2-代理模式" class="headerlink" title="2.代理模式"></a>2.代理模式</h3><h3 id="3-观察者模式"><a href="#3-观察者模式" class="headerlink" title="3.观察者模式"></a>3.观察者模式</h3><h3 id="4-工厂模式"><a href="#4-工厂模式" class="headerlink" title="4.工厂模式"></a>4.工厂模式</h3><span id="more"></span>]]></content>
      <categories>
        <category>学习</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java-多线程练习</title>
    <url>/2021/03/19/%E5%B0%8F%E7%BB%83%E4%B9%A0/</url>
    <content><![CDATA[<p>两个10G的csv文件（t1.csv, t2.csv），两个csv文件里面表头为：id，name，grade</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">id：      String类型</span><br><span class="line">name：    String类型</span><br><span class="line">grade：   String类型</span><br></pre></td></tr></table></figure>

<p>服务器内存只有1G，找出grade不为空，且grade数字大于90的数据，输出到当前目录下t3.csv文件中。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.BufferedReader;</span><br><span class="line"><span class="keyword">import</span> java.io.BufferedWriter;</span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.FileReader;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: 尹丹</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createDate</span>: 2022/3/31</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@version</span>: 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Reader</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String path;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> BufferedWriter writer;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        File inputFile = <span class="keyword">new</span> File(path);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            BufferedReader reader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> FileReader(inputFile));</span><br><span class="line">            <span class="comment">//跳过表头所在的行</span></span><br><span class="line">            reader.readLine();</span><br><span class="line">            <span class="comment">//按行读取文件</span></span><br><span class="line">            <span class="keyword">while</span> (reader.ready()) &#123;</span><br><span class="line">                String line = reader.readLine();</span><br><span class="line">                String[] splitline = line.split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">                <span class="keyword">double</span> temp = Double.parseDouble(splitline[<span class="number">2</span>]);</span><br><span class="line">                <span class="keyword">if</span> (temp &gt; <span class="number">90</span>) &#123;</span><br><span class="line">                    writer.write(line);</span><br><span class="line">                    writer.newLine();</span><br><span class="line">                    writer.flush();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            reader.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.BufferedWriter;</span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.FileWriter;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: 尹丹</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@createDate</span>: 2022/3/31</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@version</span>: 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DataFilter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        File outputFile = <span class="keyword">new</span> File(<span class="string">&quot;C:\\Users\\Yoon\\Desktop\\t3.csv&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            BufferedWriter bufferedWriter = <span class="keyword">new</span> BufferedWriter(<span class="keyword">new</span> FileWriter(outputFile));</span><br><span class="line">            Thread t1 = <span class="keyword">new</span> Reader(<span class="string">&quot;C:\\Users\\Yoon\\Desktop\\t1.csv&quot;</span>, bufferedWriter);</span><br><span class="line">            Thread t2 = <span class="keyword">new</span> Reader(<span class="string">&quot;C:\\Users\\Yoon\\Desktop\\t2.csv&quot;</span>, bufferedWriter);</span><br><span class="line">            t1.start();</span><br><span class="line">            t2.start();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>学习</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>摄影笔记</title>
    <url>/2022/02/04/%E6%91%84%E5%BD%B1%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="01-了解数码相机"><a href="#01-了解数码相机" class="headerlink" title="01 了解数码相机"></a>01 了解数码相机</h2><h3 id="第1节-数码相机机身简介"><a href="#第1节-数码相机机身简介" class="headerlink" title="第1节 数码相机机身简介"></a>第1节 数码相机机身简介</h3><p><strong>单反相机</strong>工作时，光通过镜头进入机身，光线一分为二，一束光在反光镜上通过对焦机构进入五棱镜，之后再通过五棱镜到目镜里。通过光学取景器，可以取景、构图、对焦。另一束光传递到感应器，用于识别场景、测光和设定白平衡。按下快门时，反光镜抬起，快门帘打开，全部光线落在电子感光器上，被影像处理器处理后传输到储存卡中记录下来。</p>
<span id="more"></span>

<img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202202050340856.png" alt="image-20220205034025473" style="zoom:50%;" />

<p><strong>无反相机</strong>工作时，光线通过镜头落在电子感光元件上，被影像处理器处理后传输到储存卡中记录下来。与单反相机不同的是取景方式，无反相机没有反光镜，所以取景也是通过电子感光元件——传感器取景，图像最终呈现在电子取景器（EVF）或者液晶屏上，这一点就好像数码单反相机使用实时取景一样。</p>
<img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202202050342083.png" alt="image-20220205034254951" style="zoom:50%;" />



<p><strong>传感器尺寸</strong>，又被称为画幅。1934年，柯达公司引入了一次性的胶卷盒，称为135胶卷，1表示一次性，35表示采用了35mm电影胶片。在刚刚进入数码时代的时候，相机厂商们都想做拥有35mm胶片大小传感器的单反相机，这个尺寸被大家称为<strong>35mm全画幅</strong>。</p>
<p>但是大家都遇到一个问题——贵！一旦采用，相机就没几个人能买得起了。从此单反相机中就有了两大传感器尺寸标准——全画幅和APS-C尺寸(23.5mm×15.6mm)。</p>
<h3 id="第2节-镜头简介"><a href="#第2节-镜头简介" class="headerlink" title="第2节 镜头简介"></a>第2节 镜头简介</h3><blockquote>
<p>佳能的EF 70-200mm f/2.8L IS USM II</p>
</blockquote>
<p>1．镜头种类</p>
<p>EF表示EOS相机卡口的镜头。其他的还有EF-S只适用于佳能APS-C画幅EOS相机的镜头；MP-E放大倍率在1倍以上的微距摄影镜头；TS-E移轴镜头。</p>
<p>2．焦距</p>
<p>70-200mm表示这是一个广角端为70mm，长焦端为200mm的变焦镜头。如果只有一个数值那么就是定焦镜头。</p>
<p>3．最大光圈</p>
<p>f/2.8表示这支镜头全焦段的最大光圈是恒定的2.8。有的镜头会有两个数值，分别表示广角端和长焦端的最大光圈。最大光圈表示在这个焦距的时候你可以使用的光圈最大有多大，如果想缩小光圈，自然也是可以的。</p>
<p>4．特性</p>
<p>L表示佳能的专业级镜头，同时镜头前端也会有红圈。IS表示具有防抖功能。USM表示具有超声波马达。II表示这是这个镜头的第二代产品。</p>
<p><strong>总结：光圈越大，单位时间内镜头的通光能力越强，这支镜头往往也越好</strong></p>
<h2 id="02-焦距与取景"><a href="#02-焦距与取景" class="headerlink" title="02 焦距与取景"></a>02 焦距与取景</h2><p> <strong>鱼眼 &lt; 超广角（28mm以下）&lt; 广角 &lt; 微距 &lt; 长焦 &lt; 超长焦（300mm以上）</strong></p>
<p><strong>24mm和28mm</strong></p>
<p>这就是一个标准的广角焦距，主要就是用来拍摄风景。</p>
<p><strong>35mm</strong></p>
<p>有人说这是大师的焦距，也被称为人文眼。简单地说就是拍摄人文最好的焦距。拍摄人文照片的时候需要主体和背景环境的关系，所以小广角的35mm既能够将背景囊括进来，又能突出人与环境的关系，这是拍摄人文的关键</p>
<p><strong>50mm</strong></p>
<p>这被称为标准镜头，拍摄人文、人像都是很好的，也是大师的焦距。</p>
<p><strong>85mm</strong></p>
<p>这是一个拍摄人像的焦距。能有很好的背景虚化效果，很好的画面裁切能力，还能保持和模特之间适当的交流距离。主要用于模特大头照或者特写。</p>
<p><strong>等效焦距</strong></p>
<p>传感器有大有小，会对这些实际焦距取景范围有截取，造成拍摄的视角与实际焦距原本应该有的视角不相同。</p>
<img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202202050410367.png" alt="image-20220205041015149" style="zoom:50%;" />



<p>实际上每个不同尺寸的传感器都有一个系数与之相对应，这个系数乘以实际焦距之后，就是等效焦距了。这个系数就叫<strong>镜头转换系数。</strong></p>
<p>全画幅：<strong>1.0</strong>x55mm=55mm</p>
<p>APS-C：<strong>1.5</strong>x55mm=82.5mm</p>
<h2 id="03-影调"><a href="#03-影调" class="headerlink" title="03 影调"></a>03 影调</h2><h3 id="第1节-什么是影调"><a href="#第1节-什么是影调" class="headerlink" title="第1节 什么是影调"></a>第1节 什么是影调</h3><p>那些本身就明亮的物体应该用高调表现；那些本身就黑的物体应该用低调表现。</p>
<p>本身就是高调的物体：雪、白馒头、白衣服、白纸、棉花……</p>
<p>本身就是低调的物体：煤炭、黑色皮鞋、黑色的衣服、夜晚的天空……</p>
<p><strong>大多数照片都是中间调，少数场景需要用高调或者低调来表现。</strong></p>
<h3 id="第2节-影调的量化"><a href="#第2节-影调的量化" class="headerlink" title="第2节 影调的量化"></a>第2节 影调的量化</h3><h4 id="曝光补偿-gt-gt-gt-gt"><a href="#曝光补偿-gt-gt-gt-gt" class="headerlink" title="曝光补偿&gt;&gt;&gt;&gt;"></a><strong>曝光补偿&gt;&gt;&gt;&gt;</strong></h4><p>其实在相机中有一个非常标准的量化体系——<strong>曝光补偿</strong>。</p>
<p>曝光补偿的意思就是，相机给你的曝光就是中间调的，你拍的东西亮呢，就往亮了补偿补偿。你拍的东西暗呢，就往暗了补偿补偿。中间调就不补偿。</p>
<h4 id="测光系统-gt-gt-gt-gt"><a href="#测光系统-gt-gt-gt-gt" class="headerlink" title="测光系统&gt;&gt;&gt;&gt;"></a><strong>测光系统&gt;&gt;&gt;&gt;</strong></h4><p>相机的测光系统主要可以分为三种：</p>
<p><strong>智能测光</strong></p>
<p>每个厂商叫的名称不同，但是一般都是默认项。推荐使用。</p>
<p><strong>中心重点平均测光</strong></p>
<p>就是重点考虑中心主体的曝光，然后加权其他背景的曝光。这曾经是很多人最常用的测光方式。但是后来的评价测光、矩阵测光、多重测光等更智能的方式出来之后，用的人逐渐少了。所以新手们，我觉得这个测光方式学不学都可以。</p>
<p><strong>点测光</strong></p>
<p>就是对画面中的一点测光，这个点一般很小，画面中1%～3%的面积，越高级的相机测光面积越小。在复杂光线环境的时候拍一个姑娘，最重要的就是保证姑娘脸是曝光正常的，所以对这姑娘的脸点测光，这个曝光参数就足够保证姑娘脸是好的。</p>
<h2 id="04-曝光补偿三要素"><a href="#04-曝光补偿三要素" class="headerlink" title="04 曝光补偿三要素"></a>04 曝光补偿三要素</h2><p>照片的影调=光线强度×<strong>光圈×快门×感光度</strong></p>
<img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202202050428814.png" alt="image-20220205042848707" style="zoom:50%;" />

<p>如果快门速度不变，光圈开大1挡，同时感光度降低1挡得到的照片的明暗程度是相同的，反之亦然。这就是<strong>互易律</strong>。</p>
<h2 id="05-相机模式"><a href="#05-相机模式" class="headerlink" title="05 相机模式"></a>05 相机模式</h2><p>一般来说摄影师的相机都有以下三种模式：</p>
<p><strong>Av、A挡 光圈优先</strong></p>
<p>摄影师设定影调（曝光补偿）和光圈，相机会自动选择合适的快门速度。</p>
<p><strong>Tv、S挡 快门优先</strong></p>
<p>摄影师设定影调（曝光补偿）和快门，相机会自动选择合适的光圈。</p>
<p><strong>M手动（手动控制光圈、快门）</strong></p>
<p>摄影师设定光圈、快门，相机告诉你影调将会是如何。</p>
<p>使用M挡手动曝光情况都是你无法使用相机测光的时候，其实等于你放弃了相机测光。所以请记住，往往在你无法使用相机测光的时候，才用M挡。</p>
<h2 id="06-光线"><a href="#06-光线" class="headerlink" title="06 光线"></a>06 光线</h2><h3 id="第1节-光线的特性"><a href="#第1节-光线的特性" class="headerlink" title="第1节 光线的特性"></a>第1节 光线的特性</h3><p><strong>顺光</strong></p>
<p>其实顺光不应过多地运用在人像摄影中。因为正面直射的光会消除面部的一切影子，使得面部趋于平面化，所以又叫平光。</p>
<p><strong>侧光</strong></p>
<p>侧光一般用在人物摄影的造型上。相比顺光会将人物拍成“大白脸”，侧光能够让人物的面部呈现立体效果。</p>
<p><strong>逆光</strong></p>
<p>逆光是很多摄影师进行创作的用光。使用逆光拍摄的时候，往往会有雾蒙蒙的感觉，并形成暖色调。</p>
<p><strong>色温</strong></p>
<p>蓝色是冷色，但是色温高；红色是暖色，但是色温低。</p>
<p>日光的色温大概是5500K。白纸放到日光下就是白色的。</p>
<p><strong>白平衡</strong></p>
<p>白平衡是相机机内处理的结果。说白了就是相机自己的后期。所以如果你拍摄RAW格式照片的话，可以在计算机中重新定义白平衡，重新调节。理论上是没有画质损失的（尽管实际可能有，但是也非常小，可忽略）。</p>
<blockquote>
<p>所以AWB+RAW拍摄，是一个既方便，又保险的组合。</p>
</blockquote>
<h3 id="第2节-布光方法"><a href="#第2节-布光方法" class="headerlink" title="第2节 布光方法"></a>第2节 布光方法</h3><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202202050444659.png" alt="image-20220205044427503" style="zoom:50%;" />

<p><strong>伦勃朗布光法</strong>有几个特点：</p>
<p>1．四分之三面部对着相机。让人物面向相机，缓慢变换角度，直到看不到一侧的耳朵为止。</p>
<p>2．架设主灯，强度要能使人面部正确曝光，方向为与人物面部方向同一侧45°左右。注意，要在人物面部形成三角形光区（以鼻子阴影、面颊阴影、下眼线为边长，围成的三角形亮区）。</p>
<p>3．架设辅灯。将面部阴影处柔化，并表现出细节。一般会使用4:1或者3:1的光比。</p>
<p>4．架设背景灯，打亮背景。如果有可能从人物斜后方放置一束比较集中的光，打在人物轮廓上，形成轮廓光。如下图所示：</p>
<img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202202050446673.png" alt="image-20220205044609555" style="zoom:50%;" />



<p>伦勃朗布光法是适用于男性的。那么再提供一个适用于女性摄影的布光法——<strong>蝶形布光法</strong>。</p>
<p><strong>蝶形布光法</strong>的名字来源于布光法中的一个特点。类似于伦勃朗布光法中要找三角形光区，蝶形布光法就是要找这个蝶形。使用蝶形布光法的时候，主灯放置在人物正前方，但是处于比较高的位置。这与顶光不同。蝶形布光法的主灯是从上斜射下来的。这样在人物的鼻子下方就会形成一个阴影。随着主灯高度变化，阴影会在鼻子下面形成一个蝴蝶的形状。这时主灯的位置就可以确定了。</p>
<h2 id="07-摄影中的虚实"><a href="#07-摄影中的虚实" class="headerlink" title="07 摄影中的虚实"></a>07 摄影中的虚实</h2><p><strong>前帘同步闪光</strong>就是：</p>
<p>前帘开启之后（也是曝光的开始），就闪光，闪完了之后等曝光时间一到后帘关闭（曝光结束）。这样就是一辆车移动，你拍摄车。开启快门就闪光了，车被闪光灯定在了画面中，然后长曝光继续曝，车往前走拉车线。这样就变成了车在后面，车线在前面的奇葩照片。</p>
<img src="C:/Users/Yoon/AppData/Roaming/Typora/typora-user-images/image-20220205045502246.png" alt="image-20220205045502246" style="zoom:25%;" />



<p><strong>后帘同步闪光</strong>就是：</p>
<p>前帘开启之后（也是曝光的开始），先踏踏实实曝着光。然后闪光灯闪了一下，定格画面，随即后帘关闭（曝光结束）。这样一辆车移动，你拍摄车。开启快门，先拉车线，然后马上快门关闭了，闪光灯突然把车定格住。就变成了车在前面，车线在后面的好画面了。</p>
<img src="C:/Users/Yoon/AppData/Roaming/Typora/typora-user-images/image-20220205045429391.png" alt="image-20220205045429391" style="zoom:25%;" />

<h2 id="08-构图"><a href="#08-构图" class="headerlink" title="08 构图"></a>08 构图</h2><p><strong>居中构图</strong></p>
<p><strong>三分法构图</strong></p>
<p><strong>重复法</strong></p>
<p><strong>引导线</strong></p>
<img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202202050457311.png" alt="image-20220205045729070" style="zoom:25%;" />

<p><strong>三角构图</strong></p>
]]></content>
      <categories>
        <category>兴趣</category>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>摘抄--3月24日</title>
    <url>/2021/03/24/%E6%91%98%E6%8A%84--3%E6%9C%8824%E6%97%A5/</url>
    <content><![CDATA[<p>过去的每一天都不曾消失，它们闪烁在未来的天幕上，成为个人的群星，构成属于你自己的浩瀚银河。</p>
<p>然后，在某一刻，哗啦一声，向你奔涌而来。</p>
<p>我相信，每个人心中，都存在对浩瀚的体验。</p>
]]></content>
      <categories>
        <category>兴趣</category>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>并发/幂等/数据一致性问题</title>
    <url>/2022/02/27/%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h1 id="1、幂等性"><a href="#1、幂等性" class="headerlink" title="1、幂等性"></a>1、幂等性</h1><p>幂等性是数学上的概念：F(F(x))=F(x)，用在接口上就是：多次重复请求，产生效果一致。</p>
<p>比较典型的场景：支付接口，重复支付会导致多次扣钱；订单接口，同一个订单可能会多次创建。如果没有接口幂等性，则会产生数据一致性问题。</p>
<p>在数据库中，常见操作包括：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>： 天然幂等，重复操作产生效果一致;</span><br><span class="line"></span><br><span class="line"><span class="keyword">DELETE</span>： 删除也是幂等,删除同一个多次效果一样;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span>： 非幂等操作,每次新增一条;</span><br><span class="line"></span><br><span class="line">UPDATE： a.直接更新某个值的,幂等;</span><br><span class="line">      ： b.更新累加操作的,非幂等;</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h1 id="2、RestFul规范"><a href="#2、RestFul规范" class="headerlink" title="2、RestFul规范"></a>2、RestFul规范</h1><h3 id="Create-类型的幂等"><a href="#Create-类型的幂等" class="headerlink" title="Create 类型的幂等"></a>Create 类型的幂等</h3><p>创建类型的 API，为了实现幂等性，常见的做法是使用一个 client-side generated deduplication token（客户端生成的唯一ID），在反复重试时使用同一个Token，便于服务端识别重复，如果发现重复，应按创建成功返回。</p>
<h3 id="Update-类型的幂等"><a href="#Update-类型的幂等" class="headerlink" title="Update 类型的幂等"></a>Update 类型的幂等</h3><p>更新类型的 API，通常有唯一ID对需要更新的资源进行标示，以此可以保证幂等。</p>
<p>对于“Delta”语义的操作，有以下几类方式确保幂等性：</p>
<ol>
<li>IncrementBy：基于某个数值增加</li>
<li>SetNewTotal：设置新的总量</li>
<li>使用 Deduplication Token 保证幂等</li>
</ol>
<p>这几种方式各有优缺点，需要根据场景选择合适的方式。</p>
<h3 id="Delete-类型的幂等"><a href="#Delete-类型的幂等" class="headerlink" title="Delete 类型的幂等"></a>Delete 类型的幂等</h3><p>Delete的幂等性问题，往往在于一个对象被删除后，再次试图删除可能会由于数据无法被发现导致出错。这个行为一般来说也没什么问题，虽然严格意义上不幂等，但是也无副作用。</p>
<h3 id="长耗时请求异步化"><a href="#长耗时请求异步化" class="headerlink" title="*** 长耗时请求异步化 ***"></a>*** 长耗时请求异步化 ***</h3><p>如果某个 API 方法需要很长时间才能完成，可以通过：</p>
<ol>
<li>在服务端异步启动任务，并返回 GUID 标示 “长时间运行的操作”资源</li>
<li>客户端通过定时轮询 <em>/polling/{guid}，</em> 获取任务进行的状态。</li>
<li>当任务完成/失败时，客户端可以获取到处理的结果/失败原因。</li>
</ol>
<h1 id="3、Redis分布式锁"><a href="#3、Redis分布式锁" class="headerlink" title="3、Redis分布式锁"></a>3、Redis分布式锁</h1><h2 id="设计方案："><a href="#设计方案：" class="headerlink" title="设计方案："></a><strong>设计方案：</strong></h2><ul>
<li><p>拦截注解 @RedisLock，获取必要的参数</p>
</li>
<li><p>加锁操作</p>
</li>
<li><p>续时操作</p>
</li>
<li><p>结束业务，释放锁</p>
</li>
</ul>
<h2 id="实操"><a href="#实操" class="headerlink" title="实操"></a>实操</h2><h4 id="（1）业务属性枚举设定"><a href="#（1）业务属性枚举设定" class="headerlink" title="（1）业务属性枚举设定"></a>（1）业务属性枚举设定</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">RedisLockTypeEnum</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自定义 key 前缀</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    ONE(<span class="string">&quot;Business1&quot;</span>, <span class="string">&quot;Test1&quot;</span>),</span><br><span class="line">    </span><br><span class="line">    TWO(<span class="string">&quot;Business2&quot;</span>, <span class="string">&quot;Test2&quot;</span>);</span><br><span class="line">    <span class="keyword">private</span> String code;</span><br><span class="line">    <span class="keyword">private</span> String desc;</span><br><span class="line">    RedisLockTypeEnum(String code, String desc) &#123;</span><br><span class="line">        <span class="keyword">this</span>.code = code;</span><br><span class="line">        <span class="keyword">this</span>.desc = desc;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> code;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getDesc</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> desc;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getUniqueKey</span><span class="params">(String key)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> String.format(<span class="string">&quot;%s:%s&quot;</span>, <span class="keyword">this</span>.getCode(), key);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="（2）任务队列保存参数"><a href="#（2）任务队列保存参数" class="headerlink" title="（2）任务队列保存参数"></a><strong>（2）任务队列保存参数</strong></h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisLockDefinitionHolder</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 业务唯一 key</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> String businessKey;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 加锁时间 (秒 s)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Long lockTime;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 上次更新时间（ms）</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Long lastModifyTime;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 保存当前线程</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Thread currentTread;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 总共尝试次数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> tryCount;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 当前尝试次数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> currentCount;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 更新的时间周期（毫秒）,公式 = 加锁时间（转成毫秒） / 3</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Long modifyPeriod;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">RedisLockDefinitionHolder</span><span class="params">(String businessKey, Long lockTime, Long lastModifyTime, Thread currentTread, <span class="keyword">int</span> tryCount)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.businessKey = businessKey;</span><br><span class="line">        <span class="keyword">this</span>.lockTime = lockTime;</span><br><span class="line">        <span class="keyword">this</span>.lastModifyTime = lastModifyTime;</span><br><span class="line">        <span class="keyword">this</span>.currentTread = currentTread;</span><br><span class="line">        <span class="keyword">this</span>.tryCount = tryCount;</span><br><span class="line">        <span class="keyword">this</span>.modifyPeriod = lockTime * <span class="number">1000</span> / <span class="number">3</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="（3）设定被拦截的注解名字"><a href="#（3）设定被拦截的注解名字" class="headerlink" title="（3）设定被拦截的注解名字"></a><strong>（3）设定被拦截的注解名字</strong></h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Retention(RetentionPolicy.RUNTIME)</span></span><br><span class="line"><span class="meta">@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> RedisLockAnnotation &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 特定参数识别，默认取第 0 个下标</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lockFiled</span><span class="params">()</span> <span class="keyword">default</span> 0</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 超时重试次数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">tryCount</span><span class="params">()</span> <span class="keyword">default</span> 3</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自定义加锁类型</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">RedisLockTypeEnum <span class="title">typeEnum</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 释放时间，秒 s 单位</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">long</span> <span class="title">lockTime</span><span class="params">()</span> <span class="keyword">default</span> 30</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="（4）-核心切面拦截的操作"><a href="#（4）-核心切面拦截的操作" class="headerlink" title="（4） 核心切面拦截的操作"></a><strong>（4）</strong> <strong>核心切面拦截的操作</strong></h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@annotation</span> 中的路径表示拦截特定注解</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Pointcut(&quot;@annotation(cn.sevenyuan.demo.aop.lock.RedisLockAnnotation)&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">redisLockPC</span><span class="params">()</span> </span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Around(value = &quot;redisLockPC()&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">around</span><span class="params">(ProceedingJoinPoint pjp)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">    <span class="comment">// 解析参数</span></span><br><span class="line">    Method method = resolveMethod(pjp);</span><br><span class="line">    RedisLockAnnotation annotation = method.getAnnotation(RedisLockAnnotation.class);</span><br><span class="line">    RedisLockTypeEnum typeEnum = annotation.typeEnum();</span><br><span class="line">    Object[] params = pjp.getArgs();</span><br><span class="line">    String ukString = params[annotation.lockFiled()].toString();</span><br><span class="line">    <span class="comment">// 省略很多参数校验和判空</span></span><br><span class="line">    String businessKey = typeEnum.getUniqueKey(ukString);</span><br><span class="line">    String uniqueValue = UUID.randomUUID().toString();</span><br><span class="line">    <span class="comment">// 加锁</span></span><br><span class="line">    Object result = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">boolean</span> isSuccess = redisTemplate.opsForValue().setIfAbsent(businessKey, uniqueValue);</span><br><span class="line">        <span class="keyword">if</span> (!isSuccess) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">&quot;You can&#x27;t do it，because another has get the lock =-=&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        redisTemplate.expire(businessKey, annotation.lockTime(), TimeUnit.SECONDS);</span><br><span class="line">        Thread currentThread = Thread.currentThread();</span><br><span class="line">        <span class="comment">// 将本次 Task 信息加入「延时」队列中</span></span><br><span class="line">        holderList.add(<span class="keyword">new</span> RedisLockDefinitionHolder(businessKey, annotation.lockTime(), System.currentTimeMillis(),</span><br><span class="line">                currentThread, annotation.tryCount()));</span><br><span class="line">        <span class="comment">// 执行业务操作</span></span><br><span class="line">        result = pjp.proceed();</span><br><span class="line">        <span class="comment">// 线程被中断，抛出异常，中断此次请求</span></span><br><span class="line">        <span class="keyword">if</span> (currentThread.isInterrupted()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> InterruptedException(<span class="string">&quot;You had been interrupted =-=&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e ) &#123;</span><br><span class="line">        log.error(<span class="string">&quot;Interrupt exception, rollback transaction&quot;</span>, e);</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">&quot;Interrupt exception, please send request again&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        log.error(<span class="string">&quot;has some error, please check again&quot;</span>, e);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="comment">// 请求结束后，强制删掉 key，释放锁</span></span><br><span class="line">        redisTemplate.delete(businessKey);</span><br><span class="line">        log.info(<span class="string">&quot;release the lock, businessKey is [&quot;</span> + businessKey + <span class="string">&quot;]&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="（5）-延时操作"><a href="#（5）-延时操作" class="headerlink" title="（5） 延时操作"></a><strong>（5） 延时操作</strong></h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 扫描的任务队列</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> ConcurrentLinkedQueue&lt;RedisLockDefinitionHolder&gt; holderList = <span class="keyword">new</span> ConcurrentLinkedQueue();</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 线程池，维护keyAliveTime</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ScheduledExecutorService SCHEDULER = <span class="keyword">new</span> ScheduledThreadPoolExecutor(<span class="number">1</span>,</span><br><span class="line">        <span class="keyword">new</span> BasicThreadFactory.Builder().namingPattern(<span class="string">&quot;redisLock-schedule-pool&quot;</span>).daemon(<span class="keyword">true</span>).build());</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// 两秒执行一次「续时」操作</span></span><br><span class="line">    SCHEDULER.scheduleAtFixedRate(() -&gt; &#123;</span><br><span class="line">        <span class="comment">// 这里记得加 try-catch，否者报错后定时任务将不会再执行=-=</span></span><br><span class="line">        Iterator&lt;RedisLockDefinitionHolder&gt; iterator = holderList.iterator();</span><br><span class="line">        <span class="keyword">while</span> (iterator.hasNext()) &#123;</span><br><span class="line">            RedisLockDefinitionHolder holder = iterator.next();</span><br><span class="line">            <span class="comment">// 判空</span></span><br><span class="line">            <span class="keyword">if</span> (holder == <span class="keyword">null</span>) &#123;</span><br><span class="line">                iterator.remove();</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 判断 key 是否还有效，无效的话进行移除</span></span><br><span class="line">            <span class="keyword">if</span> (redisTemplate.opsForValue().get(holder.getBusinessKey()) == <span class="keyword">null</span>) &#123;</span><br><span class="line">                iterator.remove();</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 超时重试次数，超过时给线程设定中断</span></span><br><span class="line">            <span class="keyword">if</span> (holder.getCurrentCount() &gt; holder.getTryCount()) &#123;</span><br><span class="line">                holder.getCurrentTread().interrupt();</span><br><span class="line">                iterator.remove();</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 判断是否进入最后三分之一时间</span></span><br><span class="line">            <span class="keyword">long</span> curTime = System.currentTimeMillis();</span><br><span class="line">            <span class="keyword">boolean</span> shouldExtend = (holder.getLastModifyTime() + holder.getModifyPeriod()) &lt;= curTime;</span><br><span class="line">            <span class="keyword">if</span> (shouldExtend) &#123;</span><br><span class="line">                holder.setLastModifyTime(curTime);</span><br><span class="line">                redisTemplate.expire(holder.getBusinessKey(), holder.getLockTime(), TimeUnit.SECONDS);</span><br><span class="line">                log.info(<span class="string">&quot;businessKey : [&quot;</span> + holder.getBusinessKey() + <span class="string">&quot;], try count : &quot;</span> + holder.getCurrentCount());</span><br><span class="line">                holder.setCurrentCount(holder.getCurrentCount() + <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, <span class="number">0</span>, <span class="number">2</span>, TimeUnit.SECONDS);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="4、数据库乐观锁与悲观锁"><a href="#4、数据库乐观锁与悲观锁" class="headerlink" title="4、数据库乐观锁与悲观锁"></a>4、数据库乐观锁与悲观锁</h1><h4 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h4><p>总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（<strong>共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程</strong>）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中<code>synchronized</code>和<code>ReentrantLock</code> <code>redis分布式锁</code>等独占锁就是悲观锁思想的实现。</p>
<h4 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h4><p>总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。<strong>乐观锁适用于多读的应用类型，这样可以提高吞吐量</strong>，像数据库提供的类似于<strong>write_condition机制</strong>，其实都是提供的乐观锁。在Java中<code>java.util.concurrent.atomic</code>包下面的原子变量类就是使用了乐观锁的一种实现方式<strong>CAS</strong>实现的。</p>
<h3 id="乐观锁常见的两种实现方式"><a href="#乐观锁常见的两种实现方式" class="headerlink" title="乐观锁常见的两种实现方式"></a>乐观锁常见的两种实现方式</h3><blockquote>
<p><strong>乐观锁一般会使用版本号机制或CAS算法实现。</strong></p>
</blockquote>
<h4 id="1-版本号机制"><a href="#1-版本号机制" class="headerlink" title="1. 版本号机制"></a>1. 版本号机制</h4><p>一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。</p>
<p><strong>举一个简单的例子：</strong> 假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。</p>
<ol>
<li>操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-$50 ）。</li>
<li>在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-$20 ）。</li>
<li>操作员 A 完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。</li>
<li>操作员 B 完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须大于记录当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。</li>
</ol>
<p>这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。</p>
<h4 id="2-CAS算法"><a href="#2-CAS算法" class="headerlink" title="2. CAS算法"></a>2. CAS算法</h4><p>即<strong>compare and swap（比较与交换）</strong>，是一种有名的<strong>无锁算法</strong>。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。<strong>CAS算法</strong>涉及到三个操作数</p>
<ul>
<li>需要读写的内存值 V</li>
<li>进行比较的值 A</li>
<li>拟写入的新值 B</li>
</ul>
<p>当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个<strong>自旋操作</strong>，即<strong>不断的重试</strong>。</p>
<h3 id="乐观锁的缺点"><a href="#乐观锁的缺点" class="headerlink" title="乐观锁的缺点"></a>乐观锁的缺点</h3><blockquote>
<p>ABA 问题是乐观锁一个常见的问题</p>
</blockquote>
<h4 id="1-ABA-问题"><a href="#1-ABA-问题" class="headerlink" title="1 ABA 问题"></a>1 ABA 问题</h4><p>如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 <strong>“ABA”问题。</strong></p>
<p>JDK 1.5 以后的 <code>AtomicStampedReference 类</code>就提供了此种能力，其中的 <code>compareAndSet 方法</code>就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。</p>
<h4 id="2-循环时间长开销大"><a href="#2-循环时间长开销大" class="headerlink" title="2 循环时间长开销大"></a>2 循环时间长开销大</h4><p><strong>自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。</strong> 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。</p>
<h4 id="3-只能保证一个共享变量的原子操作"><a href="#3-只能保证一个共享变量的原子操作" class="headerlink" title="3 只能保证一个共享变量的原子操作"></a>3 只能保证一个共享变量的原子操作</h4><p>CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了<code>AtomicReference类</code>来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用<code>AtomicReference类</code>把多个共享变量合并成一个共享变量来操作。</p>
<h3 id="CAS与synchronized的使用情景"><a href="#CAS与synchronized的使用情景" class="headerlink" title="CAS与synchronized的使用情景"></a>CAS与synchronized的使用情景</h3><blockquote>
<p><strong>简单的来说CAS适用于写比较少的情况下（多读场景，冲突一般较少），synchronized适用于写比较多的情况下（多写场景，冲突一般较多）</strong></p>
</blockquote>
<ol>
<li>对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。</li>
<li>对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。</li>
</ol>
<p>补充： Java并发编程这个领域中synchronized关键字一直都是元老级的角色，很久之前很多人都会称它为 <strong>“重量级锁”</strong> 。但是，在JavaSE 1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的 <strong>偏向锁</strong> 和 <strong>轻量级锁</strong> 以及其它<strong>各种优化</strong>之后变得在某些情况下并不是那么重了。synchronized的底层实现主要依靠 <strong>Lock-Free</strong> 的队列，基本思路是 <strong>自旋后阻塞</strong>，<strong>竞争切换后继续竞争锁</strong>，<strong>稍微牺牲了公平性，但获得了高吞吐量</strong>。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。</p>
<h1 id="5-总结："><a href="#5-总结：" class="headerlink" title="5.总结："></a>5.总结：</h1><p>主要讨论了并发场景读写一致性问题，对于长耗时请求问题，还是不懂怎么解决。</p>
]]></content>
      <categories>
        <category>学习</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>计算广告 - 在线广告概览</title>
    <url>/2022/03/06/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%20(2)/</url>
    <content><![CDATA[<h3 id="1-模型"><a href="#1-模型" class="headerlink" title="1.模型"></a>1.模型</h3><p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202203061001702.png" alt="image-20220306100052375"></p>
<span id="more"></span>

<h3 id="11-3-1-在线分配问题"><a href="#11-3-1-在线分配问题" class="headerlink" title="11.3.1 在线分配问题"></a>11.3.1 在线分配问题</h3><p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202203061117646.png" alt="image-20220306111720187"></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>智慧营销</category>
      </categories>
      <tags>
        <tag>智慧营销</tag>
      </tags>
  </entry>
  <entry>
    <title>计算广告 - 定价机制</title>
    <url>/2022/03/20/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%20(3)/</url>
    <content><![CDATA[<p>在进行广告位拍卖时，广告主会不停地试探广告费用下限，从而影响媒体收益。要想理解市场如何达到稳定状态，需要理解三个概念：纳什均衡、广义第二高价、VCG（Vickrey-Clarke-Groves）定价策略。</p>
<h4 id="1-纳什均衡"><a href="#1-纳什均衡" class="headerlink" title="1.纳什均衡"></a>1.纳什均衡</h4><p>即每个广告主都通过出价得到了最符合自己利益的位置。对某一次位置竞价来说，其对称纳什均衡（symmetric Nashequilibrium）状态可以表示为下式：</p>
<img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202203202316893.png" alt="image-20220320231605798" style="zoom: 67%;" />

<p>注意这里的下标意义有所调整，这里的 νs 指的是排在 s 位置上的广告的点击价值，并非 s 位置带来的点击价值，而 qs 指的是市场向排在 s 位置上的广告收取的费用，即定价，也就是广告主的单次投入。这一均衡状态的意义很容易理解：对于最终位置排名竞价结果中的每一条广告，其收益都比排在其他位置上要高。显然，在这样的状态下，每个广告主都达到了自己最优的状态，整个系统也就随之稳定下来。</p>
<span id="more"></span>

<h4 id="2-广义第二高价"><a href="#2-广义第二高价" class="headerlink" title="2.广义第二高价"></a>2.广义第二高价</h4><p><strong>第二高价</strong>：指的是在只有一个位置的拍卖中，向赢得该位置的广告主收取其下一位广告主的出价。</p>
<p><strong>广义第二高价</strong>：在搜索广告这种有多个位置的拍卖过程中，对赢得每一个位置的广告主，都按照他下一位的广告位置出价来收取费用。 </p>
<p>实际上，第二高价是单位置拍卖时的最优定价策略，然而广义第二高价却不是多位置拍卖时的最优定价策略（最优策略是下面要介绍的 VCG 定价）。虽然并非理论上最优，广义第二高价却有着实现简单、容易向广告主解释等诸多操作中的优点，因此在实际的竞价广告系统中是<strong>最主流的定价策略</strong>。</p>
<h4 id="3-VCG-定价"><a href="#3-VCG-定价" class="headerlink" title="3.VCG 定价"></a>3.VCG 定价</h4><p>是 Vickrey、Clarke 和 Groves 在研究竞价系统均衡状态时得到的一种理论上较为优越的定价策略。其基本思想是：对于赢得了某个位置的广告主，其所付出的成本应该等于他占据这个位置给其他市场参与者带来的价值损害。在这一原则下，VCG的定价策略可以表示为公式 5.3。</p>
<img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202203202325229.png" alt="image-20220320232531146" style="zoom:67%;" />

<p>理论分析表明，VCG 定价策略的优越性体现在如下几个方面：</p>
<p>首先，在这种定价策略的稳定状态下，整个市场是truth-telling的。所谓 truth-telling，可以理解为每个广告主都找到了自己的最优状态。</p>
<p>其次，相对于其他的定价策略，这种定价向广告主收取的费用是最少的。在单广告位拍卖的情形下，VCG定价策略就退化为第二高价策略。</p>
<p>虽然有以上诸多的优点，VCG 定价在竞价广告中却并不是一种主流的方式。这主要是由于：</p>
<ul>
<li><p>逻辑过于复杂，比较难以向广告主解释清楚；</p>
</li>
<li><p>另外在广告主和媒体存在博弈关系的情形下，媒体是否正确地计算了“给其他市场参与者带来的价值损害”也很难验证。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>学习</category>
        <category>智慧营销</category>
      </categories>
      <tags>
        <tag>智慧营销</tag>
      </tags>
  </entry>
  <entry>
    <title>计算广告 - 点击率模型</title>
    <url>/2022/04/03/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%20(4)%20/</url>
    <content><![CDATA[<h3 id="点击率模型的必要性"><a href="#点击率模型的必要性" class="headerlink" title="点击率模型的必要性"></a>点击率模型的必要性</h3><p>不考虑时间、位置等一系列因素，绝对的点击率没有意义。</p>
<p>那能不能再换一个思路，找到一些影响点击率的一些关健因素，对这些因素分别统计？这实际上已经产生了“特征”这样的建模思路了。</p>
<p>比如说，广告位是一个因素，广告本身是一个因素，用户的性别是一个因素，在每个因素上分别统计点击率，从数据充分性上是可行的。</p>
<p>不过这又产生了一个新的问题：我知道了男性用户的平均点击率、广告位S平均点击率、某广告A的平均点击率，那么如何评估某男性用户在广告位S上看到广告A的点击率呢？直觉的方法，是求上面三个点击率的几何平均。不过这里面有一个隐含的假设：<strong>即这三个因素是相互独立的</strong>。然而当特征多起来以后，这样的<strong>独立性假设是很难保证的。</strong></p>
<span id="more"></span>

<h3 id="怎样建立点击率模型"><a href="#怎样建立点击率模型" class="headerlink" title="怎样建立点击率模型"></a>怎样建立点击率模型</h3><p>我们把点击事件 h 看成一个二元取值的随机变量，那么其取值为真（h=1）的概率就是点击率。</p>
<p>因此，点击事件的分布可以写成以点击率 µ为参数的二项分布（binomial distribution）：</p>
<img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202204041125269.png" alt="image-20220404112540712" style="zoom:67%;" />

<p> 而点击率预测模型的作用是在（a，u，c）组合与点击的概率µ之间建立函数关系，这可以表示成对µ（a，u，c）=p（h=1|a，u，c）的概率建模问题。</p>
<h4 id="逻辑回归模型-特征工程"><a href="#逻辑回归模型-特征工程" class="headerlink" title="逻辑回归模型+特征工程"></a>逻辑回归模型+特征工程</h4><p>对µ（a，u，c）=p（h=1|a，u，c）的概率建模问题，可以很自然地想到的基础模型是逻辑回归（Logistic Regression，LR）</p>
<p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202204041210773.png" alt="image-20220404121004573"></p>
<p>其中 x 表示（a，u，c）组合上的特征矢量，即前面介绍过的受众定向的输出及其派生的其他特征；w 为各特征的加权系数，也就是此模型需要优化的参数；从方法上看，LR是利用线性函数来解决非线性目标，也属于广义线性模型。</p>
<h4 id="FM-GBDT融合"><a href="#FM-GBDT融合" class="headerlink" title="FM+GBDT融合"></a>FM+GBDT融合</h4><p>第一步当然也是基于大规模稀疏特征LR。</p>
<p>第二步，为了更好的刻画长尾，自动发现组合特征，采用了FM。在同样的训练时间下，AUC提升，模型泛化性能可控。</p>
<p>第三步：为了更好的fine tuning头部和提升时效性，采用了用gbdt加动态特征的模型。最后呢，把这两个模型简单的做线性融合，由于俩个模型的特征和模型差异性较大，融合后auc也有显著的提升。</p>
]]></content>
      <categories>
        <category>学习</category>
        <category>智慧营销</category>
      </categories>
      <tags>
        <tag>智慧营销</tag>
      </tags>
  </entry>
  <entry>
    <title>计算广告 - 计算广告基础</title>
    <url>/2022/03/06/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/</url>
    <content><![CDATA[<h3 id="1-广告有效性模型"><a href="#1-广告有效性模型" class="headerlink" title="1.广告有效性模型"></a>1.广告有效性模型</h3><p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202202271103448.png" alt="image-20220227110314006"></p>
<span id="more"></span>

<p><strong>曝光</strong>：主要取决于广告位</p>
<p><strong>关注</strong>：不要干扰打断用户行为、符合用户兴趣和需求</p>
<p><strong>理解</strong>：在用户能理解的具体兴趣范围内</p>
<p><strong>接受</strong>：表达信息恰当</p>
<p><strong>保持</strong>：创意设计</p>
<p><strong>决策</strong>：具体的广告策略或技术</p>
<h3 id="2-计算广告核心挑战"><a href="#2-计算广告核心挑战" class="headerlink" title="2.计算广告核心挑战"></a>2.计算广告核心挑战</h3><ul>
<li><p>计算广告的核心问题，是为一系列用户与环境的组合找到最合适的广告投放策略以优化整体广告活动的利润。</p>
</li>
<li><p>优化问题描述：</p>
<p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202202271111882.png" alt="image-20220227111138694"></p>
<p>表达式中的 a、u、c 三个变量，分别代表广告、用户与环境。</p>
</li>
</ul>
<h3 id="3-广告收入分解"><a href="#3-广告收入分解" class="headerlink" title="3.广告收入分解"></a>3.广告收入分解</h3><p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202202271119335.png" alt="image-20220227111957205"></p>
<p>广告点击与广告展现的比率称为 <strong>点击率（Click Through Rate，CTR）</strong>；</p>
<p>点击行为成功以后，将会打开广告主的 <strong>落地页（landing page）</strong>；</p>
<p>落地页成功打开次数与点击次数的比例称为 <strong>到达率</strong>；</p>
<p>如果用户从落地页开始，进一步完成下单等操作，则称为 <strong>转化</strong>；</p>
<p>转化次数与到达次数的比例称为 <strong>转化率（Conversion Rate，CVR）</strong>；</p>
<p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202202271121325.png" alt="image-20220227112106244"></p>
<p>用 <strong>µ</strong> 表示点击率，用 <strong>ν</strong> 表示点击价值（clickvalue），即单次点击为广告产品带来的收益。而这两部分的乘积定量地表示了某次或若干次展示的期望 CPM 值，就是前面提到的 eCPM[4]。</p>
<p>在对多个检索候选进行排序时，是根据 <strong>eCPM</strong> 还是<strong>CTR排序</strong>也是区别广告产品和用户产品的重要策略特征。</p>
<h3 id="4-结算方式"><a href="#4-结算方式" class="headerlink" title="4.结算方式"></a>4.结算方式</h3><p>表 2-1 展示了以上几种结算方式概要的对比。综合来看可以认为，对于效果广告，CPC计费方式最有利于发挥供给方和需求方的长处，因而在市场上被广泛接受；对于品牌广告，由于效果和目的有时不便于直接衡量，可以考虑按照 CPM 的方式计费；而CPS 的计费方式只在一些特定的环境下才比较合理。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202202271125174.png" alt="image-20220227112520031"></p>
<p>在 CPC 或 CPS 结算的广告交易中，由于计费的指标，即点击或转化在广告主的网站上产生，所以并不需要特别的监测服务。因此，可以认为广告监测主要服务的对象是品牌广告主。随着 CPM 广告定向方式越来越复杂，广告监测也从简单的展示和点击记数到频次、人口属性等信息的验证和计量。</p>
]]></content>
      <categories>
        <category>学习</category>
        <category>智慧营销</category>
      </categories>
      <tags>
        <tag>智慧营销</tag>
      </tags>
  </entry>
  <entry>
    <title>中间件</title>
    <url>/2022/01/18/%E9%9D%A2%E8%AF%95/</url>
    <content><![CDATA[<h3 id="主要使用到的技术包括："><a href="#主要使用到的技术包括：" class="headerlink" title="主要使用到的技术包括："></a>主要使用到的技术包括：</h3><h4 id="springboot-spring-cloud-mybatis-redis-ehcache-rabbit-mq-AWS-S3-mysql"><a href="#springboot-spring-cloud-mybatis-redis-ehcache-rabbit-mq-AWS-S3-mysql" class="headerlink" title="springboot + spring cloud + mybatis + redis + ehcache + rabbit mq + AWS S3 + mysql"></a>springboot + spring cloud + mybatis + redis + ehcache + rabbit mq + AWS S3 + mysql</h4><h3 id="ehcache"><a href="#ehcache" class="headerlink" title="ehcache"></a><strong>ehcache</strong></h3><p>EhCache直接在JVM中进行缓存，速度快，效率高。与Redis相比，操作简单、易用、高效，虽然EhCache也提供有缓存共享的方案，但对分布式集群的支持不太好，缓存共享实现麻烦。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Cacheable(value &#x3D; &quot;serviceNameCache&quot;, key &#x3D; &quot;targetClass+methodName+#p0&quot;)</span><br><span class="line">@CachePut 用于新增</span><br><span class="line">@CacheEvict 用于删除</span><br><span class="line">@Caching 用于组合条件</span><br></pre></td></tr></table></figure>



<h3 id="redis-缓存、分布式锁、事务、持久化存储"><a href="#redis-缓存、分布式锁、事务、持久化存储" class="headerlink" title="redis:缓存、分布式锁、事务、持久化存储"></a>redis:缓存、分布式锁、事务、持久化存储</h3><p>redis单线程为什么这么快 ？</p>
<p>redis 常见数据结构以及使用场景分析 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. String：key-value类型 常规key-value缓存应用； 常规计数：微博数，粉丝数等。 </span><br><span class="line"></span><br><span class="line">2. Hash 是一个 string 类型的 field 和 value 的映射表。</span><br><span class="line">   hash 特别适合用于存储对象，后续操作的时候，可以直接仅仅修改这个对象中的某个字段的值。</span><br><span class="line">   比如存储用户信息，商品信息等等</span><br><span class="line"></span><br><span class="line">3. List 的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作</span><br><span class="line">   微博的关注列表，粉丝列表， 消息列表等功能都可以用Redis的 list 结构来实现。</span><br><span class="line"></span><br><span class="line">4. Set 是可以自动排重的。</span><br><span class="line">   Redis可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程</span><br><span class="line"></span><br><span class="line">5. Sorted Set 增加了一个权重参数score，使得集合中的元素能够按score进行有序排列。 </span><br><span class="line">   举例： 在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜</span><br></pre></td></tr></table></figure>

<p>删除机制</p>
<p>哨兵机制</p>
<p>缓存穿透 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">简介：</span><br><span class="line">一般是黑客故意去请求缓存中不存在的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量</span><br><span class="line">请求而崩掉。</span><br><span class="line"></span><br><span class="line">解决办法：</span><br><span class="line">最常见的是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。</span><br><span class="line">另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。</span><br></pre></td></tr></table></figure>

<p>缓存雪崩 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">简介：缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。 解决办法：</span><br><span class="line"></span><br><span class="line">事前：尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略。 </span><br><span class="line"></span><br><span class="line">事中：本地ehcache缓存 + hystrix限流&amp;降级，避免MySQL崩掉 </span><br><span class="line"></span><br><span class="line">事后：利用 redis 持久化机制保存的数据尽快恢复缓存</span><br></pre></td></tr></table></figure>



<p>extends WebSecurityConfigurerAdapter</p>
<p>implements Filter</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">implements</span> <span class="title">BaseEntity</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Long id;</span><br><span class="line">    <span class="keyword">private</span> Group group;</span><br><span class="line">    <span class="keyword">private</span> String role;</span><br><span class="line">    <span class="keyword">private</span> Long creatorId;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> String email;</span><br><span class="line">    <span class="keyword">private</span> String password;</span><br><span class="line">    <span class="keyword">private</span> Status status;</span><br><span class="line">    <span class="keyword">private</span> Date createTime;</span><br><span class="line">    <span class="keyword">private</span> Date updateTime;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@EnableWebSecurity</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WebSecurityConfig</span> <span class="keyword">extends</span> <span class="title">WebSecurityConfigurerAdapter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        System.arraycopy(baseUrls, <span class="number">0</span>, urls, excludeUrls.size(), baseUrls.length);</span><br><span class="line">        http.csrf().disable()</span><br><span class="line">            .authorizeRequests()</span><br><span class="line">            .antMatchers(urls).permitAll()</span><br><span class="line">            .antMatchers(<span class="string">&quot;/api/admin/users&quot;</span>).hasAnyRole(<span class="string">&quot;ADMIN&quot;</span>)</span><br><span class="line">            .anyRequest()</span><br><span class="line">            .authenticated();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 登录和权限校验失败处理</span></span><br><span class="line">        http.exceptionHandling()</span><br><span class="line">            .authenticationEntryPoint((request, response, authException)</span><br><span class="line">                -&gt; &#123;</span><br><span class="line">                Map&lt;String, String&gt; message = <span class="keyword">new</span> HashMap&lt;&gt;(<span class="number">4</span>);</span><br><span class="line">                message.put(<span class="string">&quot;message&quot;</span>, I18nContext.getMessage(<span class="string">&quot;AUTH_ERROR_403&quot;</span>));</span><br><span class="line">                message.put(<span class="string">&quot;url&quot;</span>, ContextConfig.getConf(<span class="string">&quot;WEB_OAUTH_LOGIN_URL&quot;</span>));</span><br><span class="line">                response.setStatus(HttpStatus.UNAUTHORIZED.value());</span><br><span class="line">                MessageUtils.respMsg(response, message);</span><br><span class="line">            &#125;)</span><br><span class="line">            .accessDeniedHandler((request, response, accessDeniedException)</span><br><span class="line">                -&gt; MessageUtils.respStringMsg(HttpStatus.FORBIDDEN));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//add filter</span></span><br><span class="line">        http.addFilterBefore(<span class="keyword">new</span> OauthLoginFilter(sysUserService),</span><br><span class="line">            UsernamePasswordAuthenticationFilter.class);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>







<h3 id="rabbit-mq"><a href="#rabbit-mq" class="headerlink" title="rabbit-mq"></a>rabbit-mq</h3><p>模式</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Direct exchange:routingkey完全匹配</span><br><span class="line">Fanout exchange：订阅模式，exchange绑定的所有队列</span><br><span class="line">Topic exchange：routingkey通配</span><br><span class="line">Headers exchange：不通过routingkey,通过请求头信息</span><br></pre></td></tr></table></figure>



<p>死信队列</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DLX，全称为Dead-Letter-Exchange , 可以称之为死信交换机。当消息在一个队列中变成死信(dead message)之后，它能被重新发送到另一个交换机中，这个交换机就是DLX ，绑定DLX的队列就称之为死信队列。</span><br><span class="line"></span><br><span class="line">消息变成死信，可能是由于以下的原因：</span><br><span class="line"></span><br><span class="line">- 消息被拒绝</span><br><span class="line">- 消息过期</span><br><span class="line">- 队列达到最大长度</span><br><span class="line"></span><br><span class="line">DLX也是一个正常的交换机，和一般的交换机没有区别，它能在任何的队列上被指定，实际上就是设置某一个队列的属性。当这个队列中存在死信时，Rabbitmq就会自动地将这个消息重新发布到设置的DLX上去，进而被路由到另一个队列，即死信队列。</span><br></pre></td></tr></table></figure>





<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Target(ElementType.METHOD)</span></span><br><span class="line"><span class="meta">@Retention(RetentionPolicy.RUNTIME)</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> LogOperation &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 模块信息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">String <span class="title">module</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 操作内容</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">String <span class="title">operation</span><span class="params">()</span> <span class="keyword">default</span> &quot;&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 哪些字段需要被操作日志锁记录</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    String[] fields();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 哪些字段需要联合判断，如时间字段:begin-end</span></span><br><span class="line"><span class="comment">     * 当其中一个字段发生变化即认为两者都发生变化。</span></span><br><span class="line"><span class="comment">     * 说明:unionFields中字段不要在fields中存在。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    String [] unionFields() <span class="keyword">default</span> &#123;&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 操作日志中的操作（） 中的字段</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">String <span class="title">operationField</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 操作者,SpEL表达式，默认从权限工具类获取。</span></span><br><span class="line"><span class="comment">     * hoa-log 可以不用依赖hoa-security模块</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">String <span class="title">operator</span><span class="params">()</span> <span class="keyword">default</span> &quot;@userServiceImpl.<span class="title">getCurrentUser</span><span class="params">()</span>.<span class="title">getId</span><span class="params">()</span>&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 操作前的值,使用 SPEL 表达式，参考如下：</span></span><br><span class="line"><span class="comment">     * #this.getDao().findOne(#p0.id)</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">String <span class="title">originExpression</span><span class="params">()</span> <span class="keyword">default</span> &quot;&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 操作后的值，使用 SPEL 表达式，参考如下：</span></span><br><span class="line"><span class="comment">     * #p0</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">String <span class="title">currentExpression</span><span class="params">()</span> <span class="keyword">default</span> &quot;&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 使用 SPEL 表达式判断在什么情况下记录本次的操作日志</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">String <span class="title">condition</span><span class="params">()</span> <span class="keyword">default</span> &quot;<span class="keyword">true</span>&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="定时任务"><a href="#定时任务" class="headerlink" title="定时任务"></a>定时任务</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Scheduled(cron = &quot;$&#123;app.monitor.task.day&#125;&quot;)</span></span><br><span class="line"><span class="meta">@SchedulerLock(name = &quot;SERVICENAME_SUBSCRIPTION_DAY&quot;, lockAtLeastFor = 30000, lockAtMostFor = 60000)</span></span><br></pre></td></tr></table></figure>



<h3 id="k8s"><a href="#k8s" class="headerlink" title="k8s"></a>k8s</h3><h3 id="openfeign"><a href="#openfeign" class="headerlink" title="openfeign"></a>openfeign</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *  <span class="doctag">@FeignClient</span>:</span></span><br><span class="line"><span class="comment"> *  name/value属性: 这两个的作用是一样的,指定的是调用服务的微服务名称</span></span><br><span class="line"><span class="comment"> *  url : 指定调用服务的全路径,经常用于本地测试</span></span><br><span class="line"><span class="comment"> *  如果同时指定name和url属性: 则以url属性为准,name属性指定的值便当做客户端的名称</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@FeignClient(name = &quot;$&#123;openfeign.serviceName.accountClient&#125;&quot;, url = &quot;$&#123;openfeign.serviceName.accountDomain&#125;&quot;,</span></span><br><span class="line"><span class="meta">        fallbackFactory = FeignHacBackService.class, configuration = FeignConfiguration.class)</span></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">FeignHacService</span> </span>&#123;</span><br><span class="line">    <span class="meta">@RequestMapping(value = &quot;$&#123;openfeign.serviceName.userApi&#125;&quot;, method = RequestMethod.GET)</span></span><br><span class="line">    <span class="function">HacMessage&lt;HacUser&gt; <span class="title">syncUsers</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line">             </span><br></pre></td></tr></table></figure>

<h3 id="spring-cloud"><a href="#spring-cloud" class="headerlink" title="spring cloud"></a>spring cloud</h3>]]></content>
      <categories>
        <category>学习</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>基础语法</title>
    <url>/2022/01/19/java%E5%85%AB%E8%82%A1%E6%96%87-%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h2 id="一、基础语法"><a href="#一、基础语法" class="headerlink" title="一、基础语法"></a>一、基础语法</h2><h3 id="1-面向对象包括哪些特性，如何理解？"><a href="#1-面向对象包括哪些特性，如何理解？" class="headerlink" title="1.面向对象包括哪些特性，如何理解？"></a>1.面向对象包括哪些特性，如何理解？</h3><ul>
<li><p>封装。通过private关键字，将对象的属性和方法封装起来。隐藏一切可隐藏的东西，只对外界提供最简单的编程接口，同时保护了数据。</p>
</li>
<li><p>继承。父类引用指向子类对象，Animal animal = new Cat( ) 即声明的是父类，实际指向的是子类的一个对象。 继承是为了重用父类代码，子类继承父类就拥有了父类的成员。</p>
</li>
<li><p>多态。同一个行为具有不同的表现形式。实现多态需要做两件事：</p>
<p>第一：方法重写（子类继承父类并重写父类中已有的或抽象的方法）</p>
<p>第二：对象造型（用父类引用指向子类对象，这样同样的引用调用同样的方法就会根据子类对象的不同而表现出不同的行为）。</p>
<span id="more"></span></li>
</ul>
<h3 id="2-重载和重写的区别"><a href="#2-重载和重写的区别" class="headerlink" title="2.重载和重写的区别"></a>2.重载和重写的区别</h3><p><strong>重载</strong> : 发生在同一个类中。方法名一样，方法参数类型、个数、顺序不一样。返回值类型和访问权限可以不一致。</p>
<p><strong>重写</strong> ：发生在父子类中，子类重写父类方法。方法名一样，方法返回值小于等于父类，方法访问权限大于等于父类。当父类中方法使用private修饰时，子类不能重写父类中的方法。</p>
<h3 id="3-String、StringBuffer、StingBuilder的区别"><a href="#3-String、StringBuffer、StingBuilder的区别" class="headerlink" title="3.String、StringBuffer、StingBuilder的区别"></a>3.String、StringBuffer、StingBuilder的区别</h3><ul>
<li><p><strong>可变性</strong></p>
<p>String类中使用final关键字字符数组保存字符串，所以String是不可变字符串。</p>
<p>StringBuilder和StringBuffer都继承自AbstractStringBuilder，因此两者都是可变字符串</p>
</li>
<li><p><strong>线程安全性</strong></p>
<p>String可以理解为字符串常量，因此是线程安全的。</p>
<p>StringBuffer对方法或者调用的方法加了同步锁，因此也是线程安全的。</p>
<p>StringBuilder并没有对方法加同步锁，所以是非线程安全的。</p>
</li>
<li><p><strong>性能</strong></p>
<p>String每次都会创建一个新的对象，并将指针指向这个新对象。</p>
<p>StringBuffer每次都是对对象本身进行操作，相同情况下，StringBuilder比StringBuffer的性能提升10%-15%，却要承担线程不安全的风险</p>
</li>
<li><p>使用总结：</p>
<p>对字符串进行少量修改：使用String</p>
<p>多线程操作字符串缓冲区下操作大量数据：StringBuffer</p>
<p>单线程操作字符串缓冲区下操作大量数据：StringBuilder</p>
</li>
</ul>
<h3 id="4-自动装箱与自动拆箱"><a href="#4-自动装箱与自动拆箱" class="headerlink" title="4.自动装箱与自动拆箱"></a>4.自动装箱与自动拆箱</h3><p>自动装箱：将基本数据类型用他们对应的包装数据类型包装起来</p>
<p>自动拆箱：将包装数据类型转化为基本数据类型</p>
<blockquote>
<p>在通过valueOf方法创建Integer对象的时候，如果数值在[-128,127]之间，便返回指向IntegerCache.cache中已经存在的对象的引用；否则创建一个新的Integer对象。</p>
</blockquote>
<h3 id="5-关于final关键字的总结"><a href="#5-关于final关键字的总结" class="headerlink" title="5.关于final关键字的总结"></a>5.关于final关键字的总结</h3><p>final关键字主要用在三个地方：类、方法、变量。</p>
<ul>
<li>当final修饰变量时，一旦变量被初始化，就不可以被随意更改。</li>
<li>当final修饰方法时，这个方法不可以被覆盖重写。</li>
<li>当final修饰类时，该类不可以被继承，类中的方法被隐式地申明为final方法。</li>
</ul>
<p>使用final类的好处如下：第一是把方法锁住，防止继承类修改它的含义；第二是提升性能，在早期的Java版本中，final方法会转化为嵌入方法，不过现在的Java版本已经不靠final来提升方法性能了。</p>
<h3 id="6-Object类的常用方法总结"><a href="#6-Object类的常用方法总结" class="headerlink" title="6.Object类的常用方法总结"></a>6.Object类的常用方法总结</h3><p>Object类是一个特殊的类，它是所有类的父类，主要提供了以下几个方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">- toString() </span><br><span class="line">    </span><br><span class="line">- hashCode()</span><br><span class="line">    </span><br><span class="line">- getClass() <span class="comment">//native方法，用于返回当前运行时对象的Class对象，使用了final关键字修饰，故不允许子类重写。</span></span><br><span class="line">    </span><br><span class="line">- equals() <span class="comment">//用于比较2个对象的内存地址是否相等，String类对该方法进行了重写用户比较字符串的值是否相等。</span></span><br><span class="line">    </span><br><span class="line">- clone() <span class="comment">//naitive方法，用于创建并返回当前对象的一份拷贝。一般情况下，对于任何对象 x，表达式 x.clone() != x 为true，x.clone().getClass()== x.getClass() 为true。Object本身没有实现Cloneable接口，所以不重写clone方法并且进行调用的话会发生CloneNotSupportedException异常。</span></span><br><span class="line">    </span><br><span class="line">- notify() <span class="comment">//native方法，并且不能重写。唤醒一个在此对象监视器上等待的线程(监视器相当于就是锁的概念)。如果有多个线程在等待只会任意唤醒一个。</span></span><br><span class="line"></span><br><span class="line">- notifyAll() <span class="comment">//native方法，并且不能重写。跟notify一样，唯一的区别就是会唤醒在此对象监视器上等待的所有线程，而不是一个线程。</span></span><br><span class="line"></span><br><span class="line">- wait() <span class="comment">//native方法，并且不能重写。暂停线程的执行。注意：sleep方法没有释放锁，而wait方法释放了锁 。timeout是等待时间。</span></span><br><span class="line"></span><br><span class="line">- finalize() <span class="comment">//实例被垃圾回收器回收的时候触发的操作     </span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="7-Java中的异常处理"><a href="#7-Java中的异常处理" class="headerlink" title="7.Java中的异常处理"></a>7.Java中的异常处理</h3><h4 id="7-1-异常分类"><a href="#7-1-异常分类" class="headerlink" title="7.1 异常分类"></a>7.1 异常分类</h4><p>在Java中所有的异常都有一个共同的父类<strong>Throwable</strong>类，Throwable类有两个重要的子类：**Error **和 <strong>Exception</strong>。</p>
<p>Error是程序无法处理的异常，Exception是程序可以处理的异常。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202203192311254.png" alt="image-20220319231142003"></p>
<h4 id="7-2-异常处理"><a href="#7-2-异常处理" class="headerlink" title="7.2 异常处理"></a>7.2 异常处理</h4><p>处理方式：</p>
<ol>
<li>不处理，直接抛出异常</li>
<li>使用 try catch 捕获处理异常</li>
</ol>
<h4 id="7-3-throw-throws区别"><a href="#7-3-throw-throws区别" class="headerlink" title="7.3 throw throws区别"></a>7.3 throw throws区别</h4><h5 id="位置不同："><a href="#位置不同：" class="headerlink" title="位置不同："></a>位置不同：</h5><p>throws: 使用在函数上，后面跟的是异常类，可以跟多个</p>
<p>throw: 使用用在方法内，后面跟的是异常对象，只能跟一个</p>
<h5 id="功能不同："><a href="#功能不同：" class="headerlink" title="功能不同："></a>功能不同：</h5><p>throws: 申明可能抛出的异常，不一定发生，可以进行预处理</p>
<p>throw: 功能执行到此结束，将具体异常对象抛给调用者</p>
<h3 id="8-接口和抽象类的区别是什么"><a href="#8-接口和抽象类的区别是什么" class="headerlink" title="8.接口和抽象类的区别是什么"></a>8.接口和抽象类的区别是什么</h3><ol>
<li><p>接口类的变量必须是final类型，抽象类不一定</p>
</li>
<li><p>接口类的方法默认加了public abstract JDK1.8之后接口类可以具有默认的实现方法</p>
<p>抽象类中可以有非抽象的方法</p>
</li>
<li><p>子类可以继承一个或多个接口，却只能继承一个抽象方法</p>
</li>
<li><p>继承了接口的子类必须实现接口的所有抽象方法，继承了抽象类的子类可以不完全实现，但是不完全实现的子类也会自动转换为抽象类</p>
</li>
</ol>
<h3 id="9-反射"><a href="#9-反射" class="headerlink" title="9.反射"></a>9.反射</h3><p>在 Java 中的反射机制是指<strong>在运行状态中，对于任意一个类都能够知道这个类所有的属性和方法； 并且对于任意一个对象，都能够调用它的任意一个方法</strong>；这种动态获取信息以及动态调用对象方法的功能成为 Java 语言的反射机制。</p>
<h4 id="9-1-编译时类型和运行时类型"><a href="#9-1-编译时类型和运行时类型" class="headerlink" title="9.1 编译时类型和运行时类型"></a>9.1 编译时类型和运行时类型</h4><blockquote>
<p> Person p = new Student （）；</p>
</blockquote>
<p>编译时类型为Person，运行时类型为Student，当程序需要获取运行时的对象属性和方法时，需要用到反射机制</p>
<h4 id="9-2-反射API"><a href="#9-2-反射API" class="headerlink" title="9.2 反射API"></a>9.2 反射API</h4><p>class 类：反射的核心类，用来获取对象的属性和方法等</p>
<p>field 类：反射的基本类，用来表示对象的变量，可以用来获取和修改属性值</p>
<p>method 类：反射的基本类，用来获取对象的方法</p>
<p> constructor 类：java . lang . reflect 类中方法，表示类的构造方法</p>
<h4 id="9-3-获取对象的三种方法"><a href="#9-3-获取对象的三种方法" class="headerlink" title="9.3 获取对象的三种方法"></a>9.3 获取对象的三种方法</h4><p><strong>调用某个对象的 getClass() 方法</strong></p>
<blockquote>
<p>Person p = new Person();</p>
<p>Class clazz = p.getClass();</p>
</blockquote>
<p><strong>调用某个类的 class 属性</strong></p>
<blockquote>
<p>Class clazz = Person.Class;</p>
</blockquote>
<p><strong>使用forName()方法</strong></p>
<blockquote>
<p>Class clazz = Class.forName(“类的全限定名称”);  //最常用的方法</p>
</blockquote>
<h4 id="9-4-操作反射相关的API"><a href="#9-4-操作反射相关的API" class="headerlink" title="9.4 操作反射相关的API"></a>9.4 操作反射相关的API</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//获取 Person 类的 Class 对象</span></span><br><span class="line"> Class clazz=Class.forName(<span class="string">&quot;reflection.Person&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//获取 Person 类的所有方法信息</span></span><br><span class="line"> Method[] method=clazz.getDeclaredMethods();</span><br><span class="line"> </span><br><span class="line"><span class="comment">//获取 Person 类的所有成员属性信息</span></span><br><span class="line"> Field[] field=clazz.getDeclaredFields();</span><br><span class="line"></span><br><span class="line"><span class="comment">//获取 Person 类的所有构造方法信息</span></span><br><span class="line"> Constructor[] constructor=clazz.getDeclaredConstructors();</span><br></pre></td></tr></table></figure>



<h3 id="10-注解"><a href="#10-注解" class="headerlink" title="10.注解"></a>10.注解</h3><p><strong>Annatation</strong>(注解)是一个接口，程序可以通过反射来获取指定程序中元素的 Annotation 对象，然后通过该 Annotation 对象来获取注解中的元数据信息。</p>
<p><strong>@Target 修饰的对象范围</strong> </p>
<p>@Target说明了Annotation所修饰的对象范围： Annotation可被用于 packages、types（类、 接口、枚举、Annotation 类型）、类型成员（方法、构造方法、成员变量、枚举值）、方法参数 和本地变量（如循环变量、catch 参数）。在 Annotation 类型的声明中使用了 target 可更加明晰 其修饰的目标 </p>
<p><strong>@Retention 定义 被保留的时间长短</strong> </p>
<p>Retention 定义了该 Annotation 被保留的时间长短：表示需要在什么级别保存注解信息，用于描 述注解的生命周期（即：被描述的注解在什么范围内有效），取值（RetentionPoicy）由：  SOURCE:在源文件中有效（即源文件保留）  CLASS:在 class 文件中有效（即 class 保留）  RUNTIME:在运行时有效（即运行时保留） </p>
<p><strong>@Documented 描述-javadoc</strong></p>
<p><strong>@ Documented 用于描述其它类型的 annotation</strong> 应该被作为被标注的程序成员的公共 API，</p>
<h3 id="11-浅拷贝与深拷贝"><a href="#11-浅拷贝与深拷贝" class="headerlink" title="11.浅拷贝与深拷贝"></a>11.浅拷贝与深拷贝</h3><p><strong>浅拷贝</strong>：对基本数据类型进行<strong>值传递</strong>，对引用数据类型进行<strong>引用传递</strong></p>
<p><strong>深拷贝</strong>：对基本数据类型进行<strong>值传递</strong>，对引用数据类型，创建一个新的对象，并复制其内容</p>
<p>对 clone() 方法，只能对当前对象进行浅拷贝，引用类型依然是在传递引用。</p>
<p>那么，如何进行一个深拷贝呢？</p>
<p>比较常用的方案有两种：</p>
<ol>
<li>序列化（serialization）这个对象，再反序列化回来，就可以得到这个新的对象，无非就是序列化的规则需要我们自己来写。</li>
<li>继续利用 clone() 方法，既然 clone() 方法，是我们来重写的，实际上我们可以对其内的引用类型的变量，再进行一次 clone()。</li>
</ol>
<h2 id="二、集合框架"><a href="#二、集合框架" class="headerlink" title="二、集合框架"></a>二、集合框架</h2><h3 id="1-List集合"><a href="#1-List集合" class="headerlink" title="1.List集合"></a><strong>1.List集合</strong></h3><p> <strong>ArrayList ：</strong> 数据结构底层是 Object 数组。扩容时，需要将已有数组的数据复制到新的存储空间中。适合随机查找和遍历，不适合插入和删除。</p>
<p><strong>Vector ：</strong> 数据结构底层是 Object 数组。支持线程的同步。<font color = #bbbb>即某一时刻只有一 个线程能够写 Vector，避免多线程同时写而引起的不一致性，</font>但实现同步需要很高的花费，因此， 访问它比访问 ArrayList 慢。</p>
<p><strong>LinkedList ：</strong>数据结构底层是双向链表。很适合数据的动态插入和删除，随机访问和遍历速度比较 慢。另外，他还提供了 List 接口中没有定义的方法，专门用于操作表头和表尾元素，可以当作堆、栈、队列和双向队列使用。</p>
<h3 id="2-Set集合"><a href="#2-Set集合" class="headerlink" title="2.Set集合"></a>2.Set集合</h3><p><strong>HashSet ：</strong> <font color=#bbbb>存储元素的顺序并不是按照存入时的顺序（和 List 显然不 同）</font> 而是按照哈希值来存的所以取数据也是按照哈希值取得。元素的哈希值是通过元素的 hashcode 方法来获取的, HashSet 首先判断两个元素的哈希值，如果哈希值一样，接着会比较 equals 方法。</p>
<p><strong>TreeSet：</strong> </p>
<ol>
<li><p>TreeSet()是使用二叉树的原理对新 add()的对象按照指定的顺序排序（升序、降序），每增 加一个对象都会进行排序，将对象插入的二叉树指定的位置。 </p>
</li>
<li><p>Integer 和 String 对象都可以进行默认的 TreeSet 排序，而自定义类的对象是不可以的，<font color=#bbbb>自定义的类必须实现 Comparable 接口，并且重写相应的 compareTo()函数，</font>才可以正常使 用。 </p>
</li>
<li><p> 在覆写 compareTo()函数时，要返回相应的值才能使 TreeSet 按照一定的规则来排序 </p>
</li>
<li><p>比较此对象与指定对象的顺序。如果该对象小于、等于或大于指定对象，则分别返回负整 数、零或正整数。</p>
</li>
</ol>
<p><strong>LinkedHashSet：</strong> 底层使用 LinkedHashMap 来保存所有元素，它继承与 HashSet，其所有的方法 操作上又与 HashSet 相同，因此 LinkedHashSet 的实现上非常简单，只提供了四个构造方法，并 通过传递一个标识参数，调用父类的构造器，底层构造一个 LinkedHashMap 来实现，在相关操 作上与父类 HashSet 的操作相同，直接调用父类 HashSet 的方法即可</p>
<h3 id="3-Map集合"><a href="#3-Map集合" class="headerlink" title="3.Map集合"></a><strong>3.Map集合</strong></h3><h4 id="1-HashMap-和-Hashtable-的区别"><a href="#1-HashMap-和-Hashtable-的区别" class="headerlink" title="1. HashMap 和 Hashtable 的区别"></a>1. HashMap 和 Hashtable 的区别</h4><ol>
<li><p><strong>线程是否安全：</strong> HashMap 是非线程安全的，HashTable 是线程安全的；HashTable 内部的方法基本都经过 synchronized 修饰。（要保证线程安全的话就使用 ConcurrentHashMap 吧！）； </p>
</li>
<li><p><strong>效率：</strong> 因为线程安全的问题，HashMap 要比 HashTable 效率高一点。另外，HashTable 基本被淘汰，不要在 代码中使用它； </p>
</li>
<li><p><strong>对Null key 和Null value的支持：</strong> HashMap 中，null 可以作为键，这样的键只有一个，可以有一个或多个键 所对应的值为 null。。但是在 HashTable 中 put 进的键值只要有一个 null，直接抛出 NullPointerException。 </p>
</li>
<li><p><strong>初始容量大小和每次扩充容量大小的不同 ：</strong></p>
<p> ①创建时如果不指定容量初始值，Hashtable 默认的初始大小为 11，之后每次扩充，容量变为原来的2n+1。HashMap 默认的初始化大小为16。之后每次扩充，容量变为原来 的2倍。</p>
<p>②创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充 为2的幂次方大小。也就是说 HashMap 总 是使用2的幂作为哈希表的大小,后面会介绍到为什么是2的幂次方。</p>
</li>
<li><p> <strong>底层数据结构：</strong> JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。</p>
</li>
</ol>
<h4 id="2-ConcurrentHashMap-和-Hashtable-的区别"><a href="#2-ConcurrentHashMap-和-Hashtable-的区别" class="headerlink" title="2.ConcurrentHashMap 和 Hashtable 的区别"></a>2.ConcurrentHashMap 和 Hashtable 的区别</h4><p>ConcurrentHashMap 和 Hashtable 的区别主要体现在实现线程安全的方式上不同。 </p>
<ul>
<li><p><strong>底层数据结构：</strong>ConcurrentHashMap 数组+链表/红黑二叉树。Hashtable 采用 数组+链表 的形式</p>
</li>
<li><p><strong>实现线程安全的方式（重要）：</strong></p>
<p>① ConcurrentHashMap 使用 Node 数组+链表+红黑 树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。</p>
<p>② Hashtable(同一把锁) :使用 synchronized 来保证线程安全， 效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。</p>
</li>
</ul>
<h4 id="3-Map数据结构总结"><a href="#3-Map数据结构总结" class="headerlink" title="3.Map数据结构总结"></a>3.Map数据结构总结</h4><p><strong>HashMap：</strong>数组+链表/红黑树，</p>
<p><strong>LinkedHashMap:</strong>  继承自 HashMap，数组+链表/红黑树。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。</p>
<p><strong>HashTable:</strong> 数组+链表组成的，</p>
<p><strong>TreeMap:</strong> 红黑树（自平衡的排序二叉树）</p>
<h4 id="4-HashMap扩容机制"><a href="#4-HashMap扩容机制" class="headerlink" title="4.HashMap扩容机制"></a>4.HashMap扩容机制</h4><p><strong>当前存放新值（<em>注意不是替换已有元素位置时</em>）的时候已有元素的个数大于等于阈值（已有元素等于阈值，下一个存放后必然触发扩容机制）</strong></p>
<p>　　注：</p>
<p>　　（1）扩容一定是放入新值的时候，该新值不是替换以前位置的情况下（说明：put（“name”,”zhangsan”），而map里面原有数据&lt;”name”,”lisi”&gt;，则该存放过程就是替换一个原有值，而不是新增值，则不会扩容）</p>
<p>　　（2）扩容发生在存放后，即是数据存放后（先存放后扩容），判断当前存入对象的个数，如果大于阈值则进行扩容。</p>
<h2 id="三、多线程"><a href="#三、多线程" class="headerlink" title="三、多线程"></a>三、多线程</h2><h3 id="1-多线程的创建方式"><a href="#1-多线程的创建方式" class="headerlink" title="1.多线程的创建方式"></a>1.多线程的创建方式</h3><h4 id="继承-Thread-类"><a href="#继承-Thread-类" class="headerlink" title="继承 Thread 类"></a>继承 Thread 类</h4><ol>
<li><p>定义子类继承Thread类。</p>
</li>
<li><p>子类中重写Thread类中的run方法。</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyThread</span> <span class="keyword">extends</span> <span class="title">Thread</span></span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</span><br><span class="line">	</span><br><span class="line">	&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>创建Thread子类对象，即创建了线程对象。 </li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">MyThread mt = <span class="keyword">new</span> MyThread();</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>调用线程对象start方法：启动线程，调用run方法。</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">mt.start();</span><br></pre></td></tr></table></figure>

<p> 注意点：</p>
<ol>
<li> 如果自己<strong>手动调</strong>用run()方法，那么就只是<strong>普通方法，没有启动多线程模式</strong>。</li>
<li>  run()方法由JVM调用，什么时候调用，执行的过程控制都有操作系统的CPU 调度决定</li>
<li> 想要启动多线程，必须调用start方法。 </li>
<li> 一个线程对象只能调用一次start()方法启动，如果重复调用了，则将抛出以上 的异常“IllegalThreadStateException”。</li>
</ol>
<h4 id="实现-runnable-、callable-接口"><a href="#实现-runnable-、callable-接口" class="headerlink" title="实现 runnable 、callable 接口"></a>实现 runnable 、callable 接口</h4><ol>
<li><p>定义子类，实现Runnable接口。</p>
</li>
<li><p>子类中重写Runnable接口中的run方法。</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestRunnable</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><p><strong>通过Thread类含参构造器创建线程对象。</strong> </p>
</li>
<li><p>将Runnable接口的子类对象作为实际参数传递给Thread类的构造器中。 </p>
</li>
<li><p>调用Thread类的start方法：开启线程，调用Runnable子类接口的run方法。</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">TestRunnable test = <span class="keyword">new</span> TestRunnable();</span><br><span class="line"><span class="comment">//含参构造器,开启线程</span></span><br><span class="line">Thread(test.<span class="string">&quot;threadName&quot;</span>).start();</span><br></pre></td></tr></table></figure>



<h5 id="-通过实现方式创建线程的好处"><a href="#-通过实现方式创建线程的好处" class="headerlink" title="** 通过实现方式创建线程的好处 **"></a>** 通过实现方式创建线程的好处 **</h5><p>​        避免了单继承的局限性 </p>
<p>​        多个线程可以共享同一个接口实现类的对象，非常适合多个相同线 程来处理同一份资源。</p>
<h5 id="-runnable和callable的区别"><a href="#-runnable和callable的区别" class="headerlink" title="** runnable和callable的区别 **"></a>** runnable和callable的区别 **</h5><p>与使用Runnable相比， Callable功能更强大些 </p>
<ul>
<li><p>相比run()方法，可以借助FutureTask类，比如获取返回结果</p>
</li>
<li><p>方法可以抛出异常 </p>
</li>
<li><p>支持泛型的返回值 </p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//通过实现callable创建线程</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyCallable</span> <span class="keyword">implements</span> <span class="title">Callable</span>&lt;<span class="title">String</span>&gt; </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">call</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 1.创建callable对象</span></span><br><span class="line">        Callable&lt;String&gt; myCallable = <span class="keyword">new</span> MyCallable();</span><br><span class="line">        <span class="comment">// 2.由上面的callable对象创建一个FutureTask对象</span></span><br><span class="line">        FutureTask&lt;String&gt; oneTask = <span class="keyword">new</span> FutureTask&lt;String&gt;(myCallable);</span><br><span class="line">        <span class="comment">// 3.由FutureTask创建一个Thread对象</span></span><br><span class="line">        Thread t = <span class="keyword">new</span> Thread(oneTask);</span><br><span class="line">        <span class="comment">// 4.开启线程</span></span><br><span class="line">        t.start();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="创建线程池"><a href="#创建线程池" class="headerlink" title="创建线程池"></a>创建线程池</h4><p> 背景：<strong>经常创建和销毁、使用</strong>量特别大的资源，比如并发情况下的线程， <strong>对性能影响很大</strong>。 </p>
<p> 思路：提前创建好多个线程，放入线程池中，使用时直接获取，使用完放回池中。可以避免频繁创建销毁、实现重复利用。</p>
<p> 好处： </p>
<p>​         提高响应速度（减少了创建新线程的时间） </p>
<p>​         降低资源消耗（重复利用线程池中线程，不需要每次都创建） </p>
<p>​         便于线程管理 ，参数如下：</p>
<p>​                 corePoolSize：核心池的大小 </p>
<p>​                 maximumPoolSize：最大线程数 </p>
<p>​                 keepAliveTime：线程没有任务时最多保持多长时间后会终止</p>
<h3 id="2-线程池的创建方式"><a href="#2-线程池的创建方式" class="headerlink" title="2.线程池的创建方式"></a>2.线程池的创建方式</h3><p>java中提供了线程池创建的<strong>顶级接口：ExcutorService</strong>。ThreadPoolExcutor实现了ExcutorService，Excutors创建线程池返回一个ExcutorService对象。</p>
<p><a href="https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html">https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html</a></p>
<blockquote>
<p>【强制要求】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。</p>
<p>说明：Executors 返回的线程池对象的弊端如下：</p>
<p>1） FixedThreadPool 和 SingleThreadPool：允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。</p>
<p>2）CachedThreadPool：允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。</p>
</blockquote>
<h5 id="-通过-ThreadPoolExcutor-创建"><a href="#-通过-ThreadPoolExcutor-创建" class="headerlink" title=" 通过 ThreadPoolExcutor 创建"></a><strong> 通过 ThreadPoolExcutor 创建</strong></h5><p>​    最原始的创建线程池的方式，它包含了 7 个参数可供设置。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutor</span><span class="params">(<span class="keyword">int</span> corePoolSize,//核心线程数，线程池中始终存活的线程数。</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">int</span> maximumPoolSize,//最大线程数</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">long</span> keepAliveTime,//最大线程存活时间</span></span></span><br><span class="line"><span class="function"><span class="params">                          TimeUnit unit,//最大线程存活时间单位</span></span></span><br><span class="line"><span class="function"><span class="params">                          BlockingQueue&lt;Runnable&gt; workQueue,//阻塞队列，用来存储线程池等待执行的任务</span></span></span><br><span class="line"><span class="function"><span class="params">                          ThreadFactory threadFactory,//线程工厂，主要用来创建线程，默认为正常优先级、非守护线程</span></span></span><br><span class="line"><span class="function"><span class="params">                          RejectedExecutionHandler handler//拒绝策略，拒绝处理任务时的策略，系统提供了 <span class="number">4</span> 种可选</span></span></span><br><span class="line"><span class="function"><span class="params">                         )</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 省略...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>使用实例：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">myThreadPoolExecutor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 创建线程池</span></span><br><span class="line">    ThreadPoolExecutor threadPool = <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">5</span>, <span class="number">10</span>, <span class="number">100</span>, 													TimeUnit.SECONDS, <span class="keyword">new</span> LinkedBlockingQueue&lt;&gt;(<span class="number">10</span>));</span><br><span class="line">    <span class="comment">// 执行任务</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> index = i;</span><br><span class="line">        threadPool.execute(() -&gt; &#123;</span><br><span class="line">            System.out.println(index + <span class="string">&quot; 被执行,线程名:&quot;</span> + 						 											Thread.currentThread().getName());</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h5 id="-通过-Excutors-创建"><a href="#-通过-Excutors-创建" class="headerlink" title=" 通过 Excutors 创建"></a><strong> 通过 Excutors 创建</strong></h5><ol>
<li>Executors.newFixedThreadPool：创建一个固定大小的线程池，可控制并发的线程数，超出的线程会在队列中等待；</li>
<li>Executors.newCachedThreadPool：创建一个可缓存的线程池，若线程数超过处理所需，缓存一段时间后会回收，若线程数不够，则新建线程；</li>
<li>Executors.newSingleThreadExecutor：创建单个线程数的线程池，它可以保证先进先出的执行顺序；</li>
<li>Executors.newScheduledThreadPool：创建一个可以执行延迟任务的线程池；</li>
<li>Executors.newSingleThreadScheduledExecutor：创建一个单线程的可以执行延迟任务的线程池；</li>
<li>Executors.newWorkStealingPool：创建一个抢占式执行的线程池（任务执行顺序不确定）</li>
</ol>
<p>使用实例：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">fixedThreadPool</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 创建 2 个数据级的线程池</span></span><br><span class="line">    ExecutorService threadPool = Executors.newFixedThreadPool(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建任务</span></span><br><span class="line">    Runnable runnable = <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;任务被执行,线程:&quot;</span> + Thread.currentThread().getName());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 线程池执行任务(一次添加 4 个任务)</span></span><br><span class="line">    <span class="comment">// 执行任务的方法有两种:submit 和 execute</span></span><br><span class="line">    threadPool.submit(runnable);  <span class="comment">// 执行方式 1:submit</span></span><br><span class="line">    threadPool.execute(runnable); <span class="comment">// 执行方式 2:execute</span></span><br><span class="line">    threadPool.execute(runnable);</span><br><span class="line">    threadPool.execute(runnable);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h3 id="3-线程的分类"><a href="#3-线程的分类" class="headerlink" title="3.线程的分类"></a>3.线程的分类</h3><p>java中的线程分为两类，一个是<strong>守护线程</strong>，一个是<strong>用户线程</strong>。</p>
<ul>
<li>守护线程是用来服务用户线程的，通过在调用start()前，设置**thread.setDaemon(true)**，可以将用户线程转化为守护线程</li>
<li>java的垃圾回收线程就是一个典型的守护线程。</li>
<li>若jvm中都是守护线程，则当前jvm将退出。</li>
</ul>
<h3 id="4-Thread类相关的方法"><a href="#4-Thread类相关的方法" class="headerlink" title="4.Thread类相关的方法"></a>4.Thread类相关的方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">start</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">run();</span><br><span class="line"></span><br><span class="line"><span class="function">String <span class="title">getName</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">setName</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回当前线程</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> Thread <span class="title">currentThread</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 线程让步</span></span><br><span class="line"><span class="comment">//    暂停当前正在执行的线程，把执行机会让给优先级相同或更高的线程</span></span><br><span class="line"><span class="comment">//    若队列中没有同优先级的线程，忽略此方法</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">yield</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 当某个程序执行调用其他线程的join方法时，调用线程将阻塞,直至被调用线程执行完毕</span></span><br><span class="line"><span class="comment">//    优先级较低的线程也可以获得执行</span></span><br><span class="line">join();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 当前线程休眠，执行其他线程，到达设定时间后，线程重新排队执行</span></span><br><span class="line"><span class="comment">//    抛出InterruptedException异常</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sleep</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 判断线程是否还活着</span></span><br><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">isAlive</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 强制结束线程，不推荐使用</span></span><br><span class="line">stop();</span><br></pre></td></tr></table></figure>



<h3 id="5-线程的调度"><a href="#5-线程的调度" class="headerlink" title="5.线程的调度"></a>5.线程的调度</h3><ul>
<li>相同优先级的线程组成先进先出队列，使用<strong>时间片</strong>的调度策略；</li>
<li>不同优先级的线程使用优先调度的<strong>抢占式</strong>策略（高优先级的线程抢占CPU）；</li>
</ul>
<h3 id="6-线程的生命周期"><a href="#6-线程的生命周期" class="headerlink" title="6.线程的生命周期"></a>6.线程的生命周期</h3><p>创建 —&gt; 就绪 —&gt; 运行 —&gt; 阻塞 —&gt; 死亡</p>
<p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202204071333072.png" alt="image-20220407133326412"></p>
<h3 id="7-线程的同步"><a href="#7-线程的同步" class="headerlink" title="7.线程的同步"></a>7.线程的同步</h3><p>同步机制：在《Thinking In Java》中说，对于并发任务，我们需要某种方式来防止两个任务访问共享资源。防止这种冲突的方法就是，在某个任务访问资源时，为其加上锁，直至任务完成。 当资源被解锁时，其他任务才能访问这个资源。</p>
<h4 id="synchronized-同步锁"><a href="#synchronized-同步锁" class="headerlink" title="synchronized 同步锁"></a>synchronized 同步锁</h4><p>首先，我们需要清楚两个概念：</p>
<blockquote>
<p>类锁：所有对象实例共用一个锁</p>
<p>对象锁：一个对象一个锁，多个对象多个锁</p>
</blockquote>
<ul>
<li>任何对象都可以作为锁的对象。所有对象都具有唯一的锁（监视器）</li>
<li>当 Synchronized 修饰静态方法时，锁住的是类对象。</li>
<li>当 Synchronized 修饰实例方法时，锁住的是实例对象。</li>
<li>当 Synchronized 修饰代码块时，可以锁住指定对象。</li>
</ul>
<h4 id="ReentrantLock同步锁"><a href="#ReentrantLock同步锁" class="headerlink" title="ReentrantLock同步锁"></a>ReentrantLock同步锁</h4><p>ReentantLock 继承接口 Lock 并实现了接口中定义的方法，他是一种可重入锁，除了能完 成 synchronized 所能完成的所有工作外，还提供了诸如<font color=#bbbb> 可响应中断锁、可轮询锁请求、定时锁等 避免多线程死锁</font>的方法。</p>
<h5 id="ReetrantLock实现"><a href="#ReetrantLock实现" class="headerlink" title="ReetrantLock实现"></a>ReetrantLock实现</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyService</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line"> 	<span class="keyword">private</span> Lock lock = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line">	<span class="comment">// Lock lock=new ReentrantLock(true);//公平锁</span></span><br><span class="line">	<span class="keyword">private</span> Condition condition=lock.newCondition();<span class="comment">//创建 Condition</span></span><br><span class="line">    </span><br><span class="line"> 	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line"> 		<span class="keyword">try</span> &#123;</span><br><span class="line"> 				lock.lock();<span class="comment">// lock 加锁</span></span><br><span class="line">            </span><br><span class="line">				<span class="comment">// 1：通过创建 Condition 对象来使线程 wait，必须先执行 lock.lock 方法获得锁</span></span><br><span class="line"> 				condition.await();</span><br><span class="line">				<span class="comment">// 2：signal 方法唤醒</span></span><br><span class="line">				condition.signal();</span><br><span class="line"> 			</span><br><span class="line"> 		&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line"> 				e.printStackTrace();</span><br><span class="line"> 		&#125; <span class="keyword">finally</span>&#123;</span><br><span class="line"> 				lock.unlock();</span><br><span class="line"> 		&#125;</span><br><span class="line"> 	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="Condition-类和-Object-类锁方法区别区别"><a href="#Condition-类和-Object-类锁方法区别区别" class="headerlink" title="Condition 类和 Object 类锁方法区别区别"></a>Condition 类和 Object 类锁方法区别区别</h5><ol>
<li>Condition 类的 awiat 方法和 Object 类的 wait 方法等效</li>
<li>Condition 类的 signal 方法和 Object 类的 notify 方法等效 </li>
<li>Condition 类的 signalAll 方法和 Object 类的 notifyAll 方法等效 </li>
<li>ReentrantLock 类可以唤醒指定条件的线程，而 object 的唤醒是随机的</li>
</ol>
<h4 id="比较ReentrantLock-与-synchronized"><a href="#比较ReentrantLock-与-synchronized" class="headerlink" title="比较ReentrantLock 与 synchronized"></a>比较ReentrantLock 与 synchronized</h4><ol>
<li>ReentrantLock 通过方法 lock()与 unlock()来进行加锁与解锁操作，与 synchronized 会 被 JVM 自动解锁机制不同，<font color=#bbbb>ReentrantLock 加锁后需要手动进行解锁</font>。为了避免程序出 现异常而无法正常解锁的情况，使用 ReentrantLock 必须在 finally 控制块中进行解锁操作。</li>
<li>synchronized 依赖于 JVM 而 ReenTrantLock 依赖于 API。ReenTrantLock 是 JDK 层面实现的（也就 是 API 层面，需要 lock() 和 unlock 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看 它是如何实现的。 </li>
<li>ReenTrantLock增加了一些高级功能。主要来说主要有三点：<font color=#bbbb>①等待可中断；②可实现公平锁； ③可实现选择性通知（锁可以绑定多个条件）</font></li>
<li>两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时 这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。</li>
</ol>
<h3 id="8-线程间的通信"><a href="#8-线程间的通信" class="headerlink" title="8.线程间的通信"></a>8.线程间的通信</h3><h4 id="wait-、notify-和notifyAll-的区别"><a href="#wait-、notify-和notifyAll-的区别" class="headerlink" title="wait() 、notify() 和notifyAll() 的区别"></a>wait() 、notify() 和notifyAll() 的区别</h4><p> wait()：令当前线程挂起并放弃CPU、同步资源并等待，使别的线程可访问并修改共享资源，而当 前线程排队等候其他线程调用notify()或notifyAll()方法唤醒，唤醒后等待重新获得对监视器的所有 权后才能继续执行。 </p>
<p> notify()：唤醒正在排队等待同步资源的线程中优先级最高者结束等待 </p>
<p> notifyAll ()：唤醒正在排队等待资源的所有线程结束等待. </p>
<p> <strong>这三个方法只有在synchronized方法或synchronized代码块中才能使用</strong>，否则会报 java.lang.IllegalMonitorStateException异常。 </p>
<p> 因为这三个方法必须有锁对象调用，而任意对象都可以作为synchronized的同步锁， 因此这三个方法只能在Object类中声明。</p>
<h4 id="小练习：银行取钱问题"><a href="#小练习：银行取钱问题" class="headerlink" title="小练习：银行取钱问题"></a>小练习：银行取钱问题</h4><p>1.定义一个Account类 </p>
<p>​        1）该Account类封装了账户编号（String）和余额（double）两个属性 </p>
<p>​        2）设置相应属性的getter和setter方法 </p>
<p>​        3）提供无参和有两个参数的构造器 </p>
<p>​        4）系统根据账号判断与用户是否匹配，需提供hashCode()和equals()方法的重写 </p>
<p>2.提供两个取钱的线程类：小明、小明’s wife </p>
<p>​        1）提供了Account类的account属性和double类的取款额的属性 </p>
<p>​        2）提供带线程名的构造器 </p>
<p>​        3）run()方法中提供取钱的操作 </p>
<p>3.在主类中创建线程进行测试。考虑线程安全问题。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Account</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String accountId;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">double</span> balance; </span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Boolean <span class="title">equals</span><span class="params">(Account b)</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.accountId==b.accountId;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Withdrawer</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Account account;</span><br><span class="line">    <span class="keyword">private</span> Double money;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Run</span><span class="params">()</span></span>&#123;</span><br><span class="line">        synchronize(account)&#123;</span><br><span class="line">            account.setBalance(account.getBalance()-money);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">test</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		Account account = <span class="keyword">new</span> Account(<span class="string">&quot;1234567&quot;</span>, <span class="number">10000</span>);</span><br><span class="line">		Withdrawer t1 = <span class="keyword">new</span> Withdrawer( account, <span class="number">8000</span>);</span><br><span class="line">		Withdrawer t2 = <span class="keyword">new</span> Withdrawer( account, <span class="number">2800</span>);</span><br><span class="line">		Thread(t1,<span class="string">&quot;小明&quot;</span>).start();</span><br><span class="line">		Thread(t2,<span class="string">&quot;小明的妻子&quot;</span>).start();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="9-CyclicBarrier、CountDownLatch、Semaphore-的用法"><a href="#9-CyclicBarrier、CountDownLatch、Semaphore-的用法" class="headerlink" title="9.CyclicBarrier、CountDownLatch、Semaphore 的用法"></a>9.CyclicBarrier、CountDownLatch、Semaphore 的用法</h3><h4 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h4><p>CountDownLatch 类位于JUC 包下，利用它可以实现类似计数器的功能。</p>
<p>比如有 一个任务 A，它要等待其他 4 个任务执行完毕之后才能执行，此时就可以利用 CountDownLatch 来实现这种功能了。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> CountDownLatch latch = <span class="keyword">new</span> CountDownLatch(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">new</span> Thread()&#123;<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	System.out.println(<span class="string">&quot;子线程&quot;</span>+Thread.currentThread().getName()+<span class="string">&quot;正在执行&quot;</span>);</span><br><span class="line"> 	Thread.sleep(<span class="number">3000</span>);</span><br><span class="line"> 	System.out.println(<span class="string">&quot;子线程&quot;</span>+Thread.currentThread().getName()+<span class="string">&quot;执行完毕&quot;</span>);</span><br><span class="line"> 	latch.countDown();</span><br><span class="line">&#125;;&#125;.start();</span><br><span class="line"></span><br><span class="line"><span class="keyword">new</span> Thread()&#123; <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	System.out.println(<span class="string">&quot;子线程&quot;</span>+Thread.currentThread().getName()+<span class="string">&quot;正在执行&quot;</span>);</span><br><span class="line">	Thread.sleep(<span class="number">3000</span>);</span><br><span class="line"> 	System.out.println(<span class="string">&quot;子线程&quot;</span>+Thread.currentThread().getName()+<span class="string">&quot;执行完毕&quot;</span>);</span><br><span class="line"> 	latch.countDown();</span><br><span class="line">&#125;;&#125;.start();</span><br><span class="line"></span><br><span class="line">System.out.println(<span class="string">&quot;等待 2 个子线程执行完毕...&quot;</span>);</span><br><span class="line">latch.await();</span><br><span class="line">System.out.println(<span class="string">&quot;2 个子线程已经执行完毕&quot;</span>);</span><br><span class="line">System.out.println(<span class="string">&quot;继续执行主线程&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="CyclicBarrier"><a href="#CyclicBarrier" class="headerlink" title="CyclicBarrier"></a>CyclicBarrier</h4><p>字面意思回环栅栏，通过它可以实现让一组线程等待至某个状态之后再全部同时执行。</p>
<p>叫做回环 是因为当所有等待线程都被释放以后，CyclicBarrier 可以被重用。</p>
<p>我们暂且把这个状态就叫做 barrier，当调用 await()方法之后，线程就处于 barrier 了。</p>
<p> <strong>CyclicBarrier 中最重要的方法就是 await 方法，它有 2 个重载版本：</strong> </p>
<ol>
<li>public int await()：用来挂起当前线程，直至所有线程都到达 barrier 状态再同时执行后续任 务； </li>
<li>public int await(long timeout, TimeUnit unit)：让这些线程等待至一定的时间，如果还有 线程没有到达 barrier 状态就直接让到达 barrier 的线程执行后续任务。</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">int</span> N = <span class="number">4</span>;</span><br><span class="line">   CyclicBarrier barrier = <span class="keyword">new</span> CyclicBarrier(N);</span><br><span class="line">   <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;N;i++)</span><br><span class="line">      <span class="keyword">new</span> Writer(barrier).start();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Writer</span> <span class="keyword">extends</span> <span class="title">Thread</span></span>&#123;</span><br><span class="line">      <span class="keyword">private</span> CyclicBarrier cyclicBarrier;</span><br><span class="line">      <span class="function"><span class="keyword">public</span> <span class="title">Writer</span><span class="params">(CyclicBarrier cyclicBarrier)</span> </span>&#123;</span><br><span class="line">           <span class="keyword">this</span>.cyclicBarrier = cyclicBarrier;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           <span class="keyword">try</span> &#123;</span><br><span class="line">                  Thread.sleep(<span class="number">5000</span>); <span class="comment">//以睡眠来模拟线程需要预定写入数据操作</span></span><br><span class="line">                  System.out.println(<span class="string">&quot;线程&quot;</span>+Thread.currentThread().getName()+<span class="string">&quot;写入数据完                                       毕，等待其他线程写入完毕&quot;</span>);</span><br><span class="line"> 				  cyclicBarrier.await();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                     e.printStackTrace();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (BrokenBarrierException e)&#123;</span><br><span class="line">                     e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">          System.out.println(<span class="string">&quot;所有线程写入完毕，继续处理其他任务，比如数据操作&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h4><p>Semaphore 翻译成字面意思为 信号量，Semaphore 可以控制同时访问的线程个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。 Semaphore 类中比较重要的几个方法： </p>
<ol>
<li><p>public void acquire(): 用来获取一个许可，若无许可能够获得，则会一直等待，直到获得许 可。 </p>
</li>
<li><p>public void acquire(int permits):获取 permits 个许可 </p>
</li>
<li><p>public void release() { } :释放许可。注意，在释放许可之前，必须先获获得许可。 </p>
</li>
<li><p>public void release(int permits) { }:释放 permits 个许可</p>
<p>上面 4 个方法都会被阻塞，如果想立即得到执行结果，可以使用下面几个方法</p>
</li>
<li><p>public boolean tryAcquire():尝试获取一个许可，若获取成功，则立即返回 true，若获取失 败，则立即返回 false </p>
</li>
<li><p>public boolean tryAcquire(long timeout, TimeUnit unit):尝试获取一个许可，若在指定的 时间内获取成功，则立即返回 true，否则则立即返回 false </p>
</li>
<li><p> public boolean tryAcquire(int permits):尝试获取 permits 个许可，若获取成功，则立即返 回 true，若获取失败，则立即返回 false </p>
</li>
<li><p>public boolean tryAcquire(int permits, long timeout, TimeUnit unit): 尝试获取 permits 个许可，若在指定的时间内获取成功，则立即返回 true，否则则立即返回 false </p>
</li>
<li><p>还可以通过 availablePermits()方法得到可用的许可数目。</p>
</li>
</ol>
<p>例子：若一个工厂有 5 台机器，但是有 8 个工人，一台机器同时只能被一个工人使用，只有使用完 了，其他工人才能继续使用。那么我们就可以通过 Semaphore 来实现：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="keyword">int</span> N = <span class="number">8</span>; <span class="comment">//工人数</span></span><br><span class="line">Semaphore semaphore = <span class="keyword">new</span> Semaphore(<span class="number">5</span>); <span class="comment">//机器数目</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;N;i++)</span><br><span class="line"><span class="keyword">new</span> Worker(i,semaphore).start();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Worker</span> <span class="keyword">extends</span> <span class="title">Thread</span></span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> num;</span><br><span class="line"><span class="keyword">private</span> Semaphore semaphore;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Worker</span><span class="params">(<span class="keyword">int</span> num,Semaphore semaphore)</span></span>&#123;</span><br><span class="line"><span class="keyword">this</span>.num = num;</span><br><span class="line"><span class="keyword">this</span>.semaphore = semaphore;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">semaphore.acquire();</span><br><span class="line">System.out.println(<span class="string">&quot;工人&quot;</span>+<span class="keyword">this</span>.num+<span class="string">&quot;占用一个机器在生产...&quot;</span>);</span><br><span class="line">Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">System.out.println(<span class="string">&quot;工人&quot;</span>+<span class="keyword">this</span>.num+<span class="string">&quot;释放出机器&quot;</span>);</span><br><span class="line">semaphore.release();</span><br><span class="line">&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> CountDownLatch 和 CyclicBarrier 都能够实现线程之间的等待，只不过它们侧重点不 同；</p>
<p>CountDownLatch 一般用于某个线程 A 等待若干个其他线程执行完任务之后，它才执行；而 CyclicBarrier 一般用于一组线程互相等待至某个状态，然后这一组线程再同时 执行；</p>
<p>另外，CountDownLatch 是不能够重用的，而 CyclicBarrier 是可以重用的。  Semaphore 其实和锁有点类似，它一般用于控制对某组资源的访问权限。</p>
<h3 id="10-如何解决CAS的ABA问题"><a href="#10-如何解决CAS的ABA问题" class="headerlink" title="10.如何解决CAS的ABA问题"></a>10.如何解决CAS的ABA问题</h3><p>CAS（compare and swap）的原理是拿期望的值A和原本的内存值V作比较，如果相同则更新成新的值B。</p>
<h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><p>JDK的atomic包里提供了一个类<strong>AtomicStampedReference</strong>来解决ABA问题。其实就是版本号机制。</p>
<p>如果当前引用 == 预期引用，并且当前标志等于预期标志，则以原子方式将该引用和该标志的值设置为给定的更新值。</p>
<p>源码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *expectedReference - 该引用的预期值</span></span><br><span class="line"><span class="comment"> *newReference - 该引用的新值</span></span><br><span class="line"><span class="comment"> *expectedStamp - 该标志的预期值</span></span><br><span class="line"><span class="comment"> *newStamp - 该标志的新值</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">compareAndSet</span><span class="params">(V   expectedReference,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 V   newReference,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">int</span> expectedStamp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">int</span> newStamp)</span> </span>&#123;</span><br><span class="line">        Pair&lt;V&gt; current = pair;</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">            expectedReference == current.reference &amp;&amp;</span><br><span class="line">            expectedStamp == current.stamp &amp;&amp;</span><br><span class="line">            ((newReference == current.reference &amp;&amp;</span><br><span class="line">              newStamp == current.stamp) ||</span><br><span class="line">             casPair(current, Pair.of(newReference, newStamp)));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h4 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> AtomicStampedReference&lt;Integer&gt; atomicStampedRef =</span><br><span class="line">        <span class="keyword">new</span> AtomicStampedReference&lt;Integer&gt;(<span class="number">100</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    Thread refT1 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                TimeUnit.SECONDS.sleep(<span class="number">1</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            atomicStampedRef.compareAndSet(<span class="number">100</span>, <span class="number">101</span>,</span><br><span class="line">                    atomicStampedRef.getStamp(), atomicStampedRef.getStamp() + <span class="number">1</span>);</span><br><span class="line">            log(<span class="string">&quot;thread refT1:&quot;</span> + atomicStampedRef.getReference());</span><br><span class="line">            atomicStampedRef.compareAndSet(<span class="number">101</span>, <span class="number">100</span>,</span><br><span class="line">                    atomicStampedRef.getStamp(), atomicStampedRef.getStamp() + <span class="number">1</span>);</span><br><span class="line">            log(<span class="string">&quot;thread refT1:&quot;</span> + atomicStampedRef.getReference());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    Thread refT2 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">int</span> stamp = atomicStampedRef.getStamp();</span><br><span class="line">            log(<span class="string">&quot;before sleep : stamp = &quot;</span> + stamp);    <span class="comment">// stamp = 0</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                TimeUnit.SECONDS.sleep(<span class="number">2</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            log(<span class="string">&quot;after sleep : stamp = &quot;</span> + atomicStampedRef.getStamp());<span class="comment">//stamp = 1</span></span><br><span class="line">            <span class="keyword">boolean</span> c3 = atomicStampedRef.compareAndSet(<span class="number">100</span>, <span class="number">101</span>, stamp, stamp + <span class="number">1</span>);</span><br><span class="line">            log(<span class="string">&quot;thread refT2:&quot;</span> + atomicStampedRef.getReference() + <span class="string">&quot;,c3 is &quot;</span> + c3);        <span class="comment">//true</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    refT1.start();</span><br><span class="line">    refT2.start();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">log</span><span class="params">(String logString)</span> </span>&#123;</span><br><span class="line">    System.out.println(logString);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="10-指令重排序："><a href="#10-指令重排序：" class="headerlink" title="10.指令重排序："></a>10.指令重排序：</h3><p><strong>简单来说，就是指你在程序中写的代码，在执行时并不一定按照写的顺序。</strong></p>
<p>在Java中，JVM能够根据处理器特性（CPU多级缓存系统、多核处理器等）适当对机器指令进行重排序，最大限度发挥机器性能。</p>
<p>参考链接： <a href="https://zhuanlan.zhihu.com/p/138819184">https://zhuanlan.zhihu.com/p/138819184</a></p>
<h3 id="11-session和cookie的区别"><a href="#11-session和cookie的区别" class="headerlink" title="11.session和cookie的区别"></a>11.session和cookie的区别</h3><p>cookie是客户端的，session是服务端的。</p>
<p>cookie存储于客户端，记录web服务器的信息，每次上网时都会先查看对应的cookie信息，比如购物时，使用cookie记录购物车信息。 </p>
<p>session是记录客户机的信息，SessionID是session的唯一标识，使用session可以记录客户端的请求等。</p>
<h2 id="四、IO流"><a href="#四、IO流" class="headerlink" title="四、IO流"></a>四、IO流</h2><h2 id="五、JVM"><a href="#五、JVM" class="headerlink" title="五、JVM"></a>五、JVM</h2><p>主要分为六大块：</p>
<p><strong>①Java内存区域、②JVM内存管理、③虚拟机垃圾收集器、④虚拟机垃圾算法、⑤JVM调优、⑥Java类加载机制</strong></p>
<h3 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h3><p>这里所说的线程指程序执行过程中的一个线程实体。</p>
<p>JVM 允许一个应用并发执行多个线程。 Hotspot JVM 中的 Java 线程与原生操作系统线程有直接的映射关系。</p>
<p><font color=#bbbb>当线程本地存储、缓 冲区分配、同步对象、栈、程序计数器等准备好以后，就会创建一个操作系统原生线程。</font></p>
<p>Java 线程结束，原生线程随之被回收。操作系统负责调度所有线程，并把它们分配到任何可用的 CPU 上。当原生线程初始化完毕，就会调用 Java 线程的 run() 方法。当线程结束时, 会释放原生线程和 Java 线程的所有资源。</p>
<p>Hotspot JVM 后台运行的系统线程主要有下面几个： </p>
<table>
<thead>
<tr>
<th>虚拟机线程 （VM thread）</th>
<th>这个线程等待 JVM 到达安全点操作出现。这些操作必须要在独立的线程里执行，因为当 堆修改无法进行时，线程都需要 JVM 位于安全点。这些操作的类型有：stop-theworld 垃圾回收、线程栈 dump、线程暂停、线程偏向锁（biased locking）解除。</th>
</tr>
</thead>
<tbody><tr>
<td><strong>周期性任务线程</strong></td>
<td>这线程负责定时器事件（也就是中断），用来调度周期性操作的执行。</td>
</tr>
<tr>
<td><strong>GC 线程</strong></td>
<td>这些线程支持 JVM 中不同的垃圾回收活动。</td>
</tr>
<tr>
<td><strong>编译器线程</strong></td>
<td>这些线程在运行时将字节码动态编译成本地平台相关的机器码。</td>
</tr>
<tr>
<td><strong>信号分发线程</strong></td>
<td>这个线程接收发送到 JVM 的信号并调用适当的 JVM 方法处理。</td>
</tr>
</tbody></table>
<h3 id="内存区域"><a href="#内存区域" class="headerlink" title="内存区域"></a>内存区域</h3><p>JVM 内存区域主要分为</p>
<ul>
<li><p>线程私有区域：<code>程序计数器</code>、<code>虚拟机栈</code>、<code>本地方法栈</code></p>
</li>
<li><p>线程共享区域：<code>JAVA 堆</code>、<code>方法区</code></p>
</li>
<li><p>直接内存：<code>不受JVM GC管理</code></p>
</li>
</ul>
<p><strong>线程私有数据区域</strong> 生命周期与线程相同, <font color=#bbbb>依赖用户线程的启动/结束，而创建/销毁(在 Hotspot VM 内</font>, 每个线程都与操作系统的本地线程直接映射, 因此这部分内存区域的存/否跟随本地线程的 生/死对应)。</p>
<p><strong>线程共享区域</strong> <font color=#bbbb>随虚拟机的启动/关闭而创建/销毁。</font></p>
<p><strong>直接内存</strong> <font color=#bbbb>并不是 JVM 运行时数据区的一部分</font>, 但也会被频繁的使用: 例如 NIO 提 供了基于 Channel 与 Buffer 的 IO 方式, 它可以<font color=#bbbb>使用 Native 函数库直接分配堆外内存</font>, 然后使用 DirectByteBuffer 对象作为这块内存的引用进行操作, 这样就避免了在 Java 堆和 Native 堆中来回复制数据, 因此在一些场景中可以显著提高性能。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202204182259266.png" alt="image-20220418225937866"></p>
<h4 id="程序计数器-线程私有"><a href="#程序计数器-线程私有" class="headerlink" title="程序计数器(线程私有)"></a>程序计数器(线程私有)</h4><p>一块较小的内存空间, <font color=#bbbb>是当前线程所执行的字节码的行号指示器</font>，每条线程都要有一个独立的程序计数器，这类内存也称为“线程私有”的内存。 </p>
<p>正在执行 java 方法的话，计数器记录的是虚拟机字节码指令的地址（当前指令的地址）。如果还是 Native 方法，则为空。 这个内存区域是唯一一个在虚拟机中没有规定任何 OutOfMemoryError 情况的区域。</p>
<h4 id="虚拟机栈-线程私有"><a href="#虚拟机栈-线程私有" class="headerlink" title="虚拟机栈(线程私有)"></a>虚拟机栈(线程私有)</h4><p>是描述java方法执行的内存模型，每个方法在执行的同时都会创建一个栈帧（Stack Frame） 用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成 的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。</p>
<img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202204192159839.png" alt="image-20220419215913693" style="zoom:75%;" />

<h4 id="本地方法栈-线程私有"><a href="#本地方法栈-线程私有" class="headerlink" title="本地方法栈(线程私有)"></a>本地方法栈(线程私有)</h4><blockquote>
<p>Native本地方法：</p>
<p>1.JVM的实现，为了与操作系统底层进行交互，就使用了本地方法。<br>2.JVM自己的代码，有一部分使用C实现的，这些代码的使用也需要使用本地方法。</p>
</blockquote>
<p>本地方法区和 Java Stack 作用类似, 区别是虚拟机栈为执行 Java 方法服务, 而本地方法栈则为 Native 方法服务, 如果一个 VM 实现使用 C-linkage 模型来支持 Native 调用, 那么该栈将会是一个 C 栈，但 HotSpot VM 直接就把本地方法栈和虚拟机栈合二为一。</p>
<h4 id="堆（Heap-线程共享）"><a href="#堆（Heap-线程共享）" class="headerlink" title="堆（Heap-线程共享）"></a>堆（Heap-线程共享）</h4><p><strong>又称运行时数据区。</strong>是被线程共享的一块内存区域，创建的对象和数组都保存在 Java 堆内存中，也是垃圾收集器进行 垃圾收集的最重要的内存区域。由于现代 VM 采用分代收集算法, 因此 Java 堆从 GC 的角度还可以 细分为: <font color=#bbbb>新生代【Eden 区、From Survivor 区、 To Survivor 区】和老年代。</font></p>
<h4 id="方法区-永久代（线程共享）"><a href="#方法区-永久代（线程共享）" class="headerlink" title="方法区/永久代（线程共享）"></a>方法区/永久代（线程共享）</h4><p>即我们常说的永久代(Permanent Generation), 用于存储被 JVM 加载的类信息、常量、静 态变量、即时编译器编译后的代码等数据. </p>
<p><font color=#bbbb>HotSpot VM把GC分代收集扩展至方法区, 即使用Java 堆的永久代来实现方法区</font>, 这样 HotSpot 的垃圾收集器就可以像管理 Java 堆一样管理这部分内存, 而不必为方法区开发专门的内存管理器(永久代的内存回收的主要目标是针对常量池的回收和类型 的卸载, 因此收益一般很小)。 </p>
<p>运行时常量池（Runtime Constant Pool）是方法区的一部分。Class 文件中除了有类的版 本、字段、方法、接口等描述等信息外，还有一项信息是常量池 ，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加 载后存放到方法区的运行时常量池中。</p>
<p> Java 虚拟机对 Class 文件的每一部分（自然也包括常量 池）的格式都有严格的规定，每一个字节用于存储哪种数据都必须符合规范上的要求，这样才会 被虚拟机认可、装载和执行。</p>
<h3 id="运行时内存"><a href="#运行时内存" class="headerlink" title="运行时内存"></a>运行时内存</h3><p>Java 堆从 GC 的角度还可以细分为: 新生代【Eden 区、From Survivor 区、 To Survivor 区】和老年 代。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202204192353112.png" alt="image-20220419235356742"></p>
<h4 id="新生代"><a href="#新生代" class="headerlink" title="新生代"></a>新生代</h4><p>是用来存放新生的对象。一般占据堆的 1/3 空间。由于频繁创建对象，所以新生代会频繁触发 MinorGC 进行垃圾回收。</p>
<p> <strong>- 伊甸园（Eden）：</strong>这是对象最初诞生的区域，并且对大多数对象来说，这里是它们唯一存在过的区域。 </p>
<p> <strong>- 幸存者乐园（SurvivorFrom）：</strong>伊甸园幸存对象会被挪到这里。 上一次 GC 的幸存者，作为这一次 GC 的被扫描者。</p>
<p> <strong>- 幸存者乐园（SurvivorTo）：</strong>保留了一次 MinorGC 过程中的幸存者。</p>
<hr>
<h4 id="MinorGC-的过程（复制-gt-清空-gt-互换）"><a href="#MinorGC-的过程（复制-gt-清空-gt-互换）" class="headerlink" title="MinorGC 的过程（复制-&gt;清空-&gt;互换）"></a><strong>MinorGC 的过程（复制-&gt;清空-&gt;互换）</strong></h4><p> MinorGC 采用复制算法。</p>
<p><strong>1：Eden、SurvivorFrom 复制到 SurvivorTo，年龄+1</strong> </p>
<p>首先，把 Eden 和 SurvivorFrom 区域中存活的对象复制到 SurvivorTo 区域（如果有对象的年 龄以及达到了老年的标准，则赋值到老年代区），同时把这些对象的年龄+1（如果 SurvivorTo 不 够位置了就放到老年区）；</p>
<p><strong>2：清空 Eden、SurvivorFrom</strong> </p>
<p>然后，清空 Eden 和 SurvivorFrom 中的对象； </p>
<p><strong>3：SurvivorTo 和 SurvivorFrom互换</strong> </p>
<p>最后，SurvivorTo 和 SurvivorFrom互换，原 SurvivorTo 成为下一次 GC 时的 SurvivorFrom区。</p>
<blockquote>
<p> 从年轻代空间（包括 Eden 和 Survivor 区域）回收内存被称为 Minor GC。 Major GC 是清理永久代。Full GC 是清理整个堆空间—包括年轻代和永久代。</p>
</blockquote>
<hr>
<h4 id="老年代"><a href="#老年代" class="headerlink" title="老年代"></a>老年代</h4><p>主要存放应用程序中生命周期长的内存对象。 </p>
<p>老年代的对象比较稳定，所以 MajorGC 不会频繁执行。在进行 MajorGC 前一般都先进行 了一次 MinorGC，使得有新生代的对象晋身入老年代，导致空间不够用时才触发。当无法找到足 够大的连续空间分配给新创建的较大对象时也会提前触发一次 MajorGC 进行垃圾回收腾出空间。 </p>
<p>MajorGC 采用 <font color=#bbbb>标记清除算法：</font>首先扫描一次所有老年代，标记出存活的对象，然后回收没 有标记的对象。MajorGC 的耗时比较长，因为要扫描再回收。MajorGC 会产生内存碎片，为了减 少内存损耗，我们一般需要进行合并或者标记出来方便下次直接分配。当老年代也满了装不下的 时候，就会抛出 OOM（Out of Memory）异常。</p>
<h3 id="垃圾回收与算法"><a href="#垃圾回收与算法" class="headerlink" title="垃圾回收与算法"></a>垃圾回收与算法</h3><p>主要理清以下几点：GC要做的三件事、如何确定垃圾、垃圾收集算法、垃圾收集器、参数。</p>
<h4 id="如何确定垃圾-or-如何判断对象是否死亡"><a href="#如何确定垃圾-or-如何判断对象是否死亡" class="headerlink" title="如何确定垃圾 or 如何判断对象是否死亡"></a>如何确定垃圾 or 如何判断对象是否死亡</h4><ul>
<li><p><strong>引用计数法</strong></p>
<p>在 Java 中，引用和对象是有关联的。如果要操作对象则必须用引用进行。因此，很显然一个简单 的办法是通过引用计数来判断一个对象是否可以回收。简单说，即一个对象如果没有任何与之关 联的引用，即他们的引用计数都不为 0，则说明对象不太可能再被用到，那么这个对象就是可回收 对象.</p>
</li>
<li><p><strong>可达性分析</strong> </p>
<p>为了解决引用计数法的循环引用问题，Java 使用了可达性分析的方法。通过一系列的“GC roots” 对象作为起点搜索。如果在“GC roots”和一个对象之间没有可达路径，则称该对象是不可达的。 </p>
<p> 要注意的是，不可达对象不等价于可回收对象，不可达对象变为可回收对象至少要经过两次标记 过程。两次标记后仍然是可回收对象，则将面临回收。</p>
</li>
</ul>
<hr>
<h4 id="垃圾收集算法"><a href="#垃圾收集算法" class="headerlink" title="垃圾收集算法"></a>垃圾收集算法</h4><h5 id="标记清除算法（Mark-Sweep）"><a href="#标记清除算法（Mark-Sweep）" class="headerlink" title="标记清除算法（Mark-Sweep）"></a>标记清除算法（Mark-Sweep）</h5><p>最基础的垃圾回收算法，分为两个阶段，标注和清除。</p>
<p><font color=#bbbb>标记阶段</font>标记出所有需要回收的对象，<font color=#bbbb>清除阶段</font>回收被标记的对象所占用的空间。如图 </p>
<p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202204252315734.png" alt="image-20220425231546970"></p>
<p>从图中我们就可以发现，该算法最大的问题是<font color=#bbbb>内存碎片化严重</font>，后续可能发生大对象不能找到可利用空间的问题。</p>
<hr>
<h5 id="复制算法（copying）"><a href="#复制算法（copying）" class="headerlink" title="复制算法（copying）"></a>复制算法（copying）</h5><p>为了解决 Mark-Sweep 算法内存碎片化的缺陷而被提出的算法。按内存容量将内存划分为等大小 的两块。每次只使用其中一块，当这一块内存满后将尚存活的对象复制到另一块上去，把已使用 的内存清掉，如图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202204252326499.png" alt="image-20220425232619309"></p>
<p>这种算法虽然实现简单，内存效率高，不易产生碎片，但是最大的问题是可用内存被压缩到了原 本的一半。且存活对象增多的话，Copying 算法的效率会大大降低。</p>
<hr>
<h5 id="标记整理算法-Mark-Compact"><a href="#标记整理算法-Mark-Compact" class="headerlink" title="标记整理算法(Mark-Compact)"></a>标记整理算法(Mark-Compact)</h5><p>结合了以上两个算法，为了避免缺陷而提出。标记阶段和 Mark-Sweep 算法相同，标记后不是清理对象，而是将存活对象移向内存的一端。然后清除端边界外的对象。如图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202204252346612.png" alt="image-20220425234615442"></p>
<hr>
<h5 id="分代收集算法"><a href="#分代收集算法" class="headerlink" title="分代收集算法"></a>分代收集算法</h5><p>分代收集法是目前大部分 JVM 所采用的方法，其核心思想是根据对象存活的不同生命周期将内存 划分为不同的域，一般情况下将 GC 堆划分为老生代(Tenured/Old Generation)和新生代(Young Generation)。老生代的特点是每次垃圾回收时只有少量对象需要被回收，新生代的特点是每次垃 圾回收时都有大量垃圾需要被回收，因此可以根据不同区域选择不同的算法。</p>
<h6 id="新生代与复制算法"><a href="#新生代与复制算法" class="headerlink" title="新生代与复制算法"></a>新生代与复制算法</h6><p>每次垃圾收集都能发现大批对象已死, 只有少量存活. 因此选用复制算法, 只需要付出少量 存活对象的复制成本就可以完成收集.</p>
<p>但通常并不是按照 1：1 来划分新生代。一般将新生代 划分为一块较大的 Eden 空间和两个较小的 Survivor 空间(From Space, To Space)，每次使用 Eden 空间和其中的一块 Survivor 空间，当进行回收时，将该两块空间中还存活的对象复制到另 一块 Survivor 空间中。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202204252348919.png" alt="image-20220425234855761"></p>
<h6 id="老年代与标记复制算法"><a href="#老年代与标记复制算法" class="headerlink" title="老年代与标记复制算法"></a>老年代与标记复制算法</h6><p>因为对象存活率高、没有额外空间对它进行分配担保, 就必须采用“标记—清理”或“标 记—整理”算法来进行回收, 不必进行内存复制, 且直接腾出空闲内存.</p>
<ol>
<li>JAVA 虚拟机提到过的处于方法区的永生代(Permanet Generation)，它用来存储 class 类， 常量，方法描述等。对永生代的回收主要包括废弃常量和无用的类。 </li>
<li>对象的内存分配主要在新生代的 Eden Space 和 Survivor Space 的 From Space(Survivor 目 前存放对象的那一块)，少数情况会直接分配到老生代。 </li>
<li>当新生代的 Eden Space 和 From Space 空间不足时就会发生一次 GC，进行 GC 后，Eden Space 和 From Space 区的存活对象会被挪到 To Space，然后将 Eden Space 和 From Space 进行清理。</li>
<li>如果 To Space 无法足够存储某个对象，则将这个对象存储到老生代。 </li>
<li>在进行 GC 后，使用的便是 Eden Space 和 To Space 了，如此反复循环。 </li>
<li>当对象在 Survivor 区躲过一次 GC 后，其年龄就会+1。<font color=#bbbb>默认情况下年龄到达 15 的对象会被 移到老生代中。</font></li>
</ol>
<hr>
<h5 id="分区收集算法"><a href="#分区收集算法" class="headerlink" title="分区收集算法"></a>分区收集算法</h5><p>分区算法则将整个堆空间划分为连续的不同小区间, 每个小区间独立使用, 独立回收. 这样做的 好处是可以控制一次回收多少个小区间 , 根据目标停顿时间, 每次合理地回收若干个小区间(而不是 整个堆), 从而减少一次 GC 所产生的停顿。</p>
<hr>
<h4 id="常见的垃圾回收器有那些？"><a href="#常见的垃圾回收器有那些？" class="headerlink" title="常见的垃圾回收器有那些？"></a>常见的垃圾回收器有那些？</h4><h5 id="Serial-垃圾收集器"><a href="#Serial-垃圾收集器" class="headerlink" title="Serial 垃圾收集器"></a>Serial 垃圾收集器</h5><p>（单线程、复制算法） </p>
<p>Serial 是最基本垃圾收集器，使用复制算法，曾经是JDK1.3.1 之前新生代唯一的垃圾 收集器。Serial 是一个单线程的收集器，它不但只会使用一个 CPU 或一条线程去完成垃圾收集工 作，并且在进行垃圾收集的同时，必须暂停其他所有的工作线程，直到垃圾收集结束。 Serial 垃圾收集器虽然在收集垃圾过程中需要暂停所有其他的工作线程，但是它简单高效，对于限 定单个 CPU 环境来说，没有线程交互的开销，可以获得最高的单线程垃圾收集效率，因此 Serial 垃圾收集器依然是 java 虚拟机运行在 Client 模式下默认的新生代垃圾收集器。</p>
<h5 id="ParNew-垃圾收集器"><a href="#ParNew-垃圾收集器" class="headerlink" title="ParNew 垃圾收集器"></a>ParNew 垃圾收集器</h5><p>（Serial+多线程） </p>
<p>ParNew 垃圾收集器其实是 Serial 收集器的多线程版本，也使用复制算法，除了使用多线程进行垃圾收集之外，其余的行为和 Serial 收集器完全一样，ParNew 垃圾收集器在垃圾收集过程中同样也要暂停所有其他的工作线程。</p>
<p>ParNew 收集器默认开启和 CPU 数目相同的线程数，可以通过 -XX : ParallelGCThreads 参数来限 制垃圾收集器的线程数。【Parallel：平行的】 ParNew 虽然是除了多线程外和Serial 收集器几乎完全一样，但是 ParNew 垃圾收集器是很多 java 虚拟机运行在 Server 模式下新生代的默认垃圾收集器。</p>
<h5 id="Parallel-Scavenge-收集器"><a href="#Parallel-Scavenge-收集器" class="headerlink" title="Parallel Scavenge 收集器"></a>Parallel Scavenge 收集器</h5><p>（多线程复制算法、高效） </p>
<p>Parallel Scavenge 收集器也是一个新生代垃圾收集器，同样使用复制算法，也是一个多线程的垃圾收集器，它重点关注的是程序达到一个可控制的吞吐量（Thoughput，CPU 用于运行用户代码 的时间/CPU 总消耗时间，即吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间)）， 高吞吐量可以最高效率地利用 CPU 时间，尽快地完成程序的运算任务，主要适用于在后台运算而 不需要太多交互的任务。自适应调节策略也是 ParallelScavenge 收集器与 ParNew 收集器的一个 重要区别。</p>
<h5 id="Serial-Old-收集器"><a href="#Serial-Old-收集器" class="headerlink" title="Serial Old 收集器"></a>Serial Old 收集器</h5><p>（单线程标记整理算法 ） </p>
<p>Serial Old 是 Serial 垃圾收集器年老代版本，它同样是个单线程的收集器，使用标记-整理算法， 这个收集器也主要是运行在 Client 默认的 java 虚拟机默认的年老代垃圾收集器。 在 Server 模式下，主要有两个用途： </p>
<ol>
<li>在 JDK1.5 之前版本中与新生代的 Parallel Scavenge 收集器搭配使用。 </li>
<li>作为年老代中使用 CMS 收集器的后备垃圾收集方案。</li>
</ol>
<h5 id="Parallel-Old-收集器"><a href="#Parallel-Old-收集器" class="headerlink" title="Parallel Old 收集器"></a>Parallel Old 收集器</h5><p>（多线程标记整理算法） </p>
<p>Parallel Old 收集器是Parallel Scavenge的年老代版本，使用多线程的标记-整理算法，在 JDK1.6 才开始提供。 在 JDK1.6 之前，新生代使用 Parallel Scavenge 收集器只能搭配年老代的 Serial Old 收集器，只 能保证新生代的吞吐量优先，无法保证整体的吞吐量，Parallel Old 正是为了在年老代同样提供吞 吐量优先的垃圾收集器，如果系统对吞吐量要求比较高，可以优先考虑新生代 Parallel Scavenge 和年老代 Parallel Old 收集器的搭配策略。</p>
<hr>
<p>强引用、软引用、弱引用、虚引用</p>
<p>如何判断一个常量是废弃常量 </p>
<p>如何判断一个类是无用的类 </p>
<h4 id=""><a href="#" class="headerlink" title=""></a></h4><p>介绍一下CMS,G1收集器。 </p>
<p>Minor GC 和 Full GC 有什么不同呢？</p>
<h3 id="Java-对象的创建过程"><a href="#Java-对象的创建过程" class="headerlink" title="Java 对象的创建过程"></a>Java 对象的创建过程</h3><p>五步，建议能默写出来并且要知道每一步虚拟机做了什么</p>
<p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202204242116345.png" alt="image-20220424211620812"></p>
<p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202204242118004.png" alt="image-20220424211820839"></p>
<h3 id="对象的访问定位的两种方式（句柄和直接指针两种方式）"><a href="#对象的访问定位的两种方式（句柄和直接指针两种方式）" class="headerlink" title="对象的访问定位的两种方式（句柄和直接指针两种方式）"></a>对象的访问定位的两种方式（句柄和直接指针两种方式）</h3><h3 id="拓展问题-String类和常量池"><a href="#拓展问题-String类和常量池" class="headerlink" title="拓展问题: String类和常量池"></a>拓展问题: String类和常量池</h3><h3 id="8种基本类型的包装类和常量池"><a href="#8种基本类型的包装类和常量池" class="headerlink" title="8种基本类型的包装类和常量池"></a>8种基本类型的包装类和常量池</h3><p> HotSpot为什么要分为新生代和老年代？ </p>
<h3 id="java类加载机制"><a href="#java类加载机制" class="headerlink" title="java类加载机制"></a>java类加载机制</h3><h2 id="二、Spring"><a href="#二、Spring" class="headerlink" title="二、Spring"></a>二、Spring</h2><h3 id="１-Bean的生命周期"><a href="#１-Bean的生命周期" class="headerlink" title="１.Bean的生命周期"></a>１.Bean的生命周期</h3><p>创建、</p>
<p>IOC注入、</p>
<p>getBeanName、</p>
<p>BeanNameFactory、</p>
<p>ApplicationContextAware、</p>
<p>PostConstructBeforeInitiation、</p>
<p>init、</p>
<p>PostConstructAfterInitiation、</p>
<p>destroy</p>
<h3 id="２-SpringMVC的工作原理？"><a href="#２-SpringMVC的工作原理？" class="headerlink" title="２.SpringMVC的工作原理？"></a>２.SpringMVC的工作原理？</h3><ul>
<li>用户向服务器发送请求，通过server.xml文件，请求被前端控制器DispatchServlet捕获；</li>
<li>DispatchServlet对URL进行解析，得到请求资源标识符（URI），通过HandlerMapping找到合适的处理器HandlerExcutionChain;</li>
<li>根据得到的处理器，DispatchServlet选择合适的适配器handlerAdapter处理请求；</li>
<li>handler处理完请求后，返回一个ModelAndView对象给DispatchServlet；</li>
<li>DispatchServlet将此对象通过ViewResolver进行处理，并得到渲染视图；</li>
<li>最后将Model中的参数进行解析，最终呈现出完整的视图返回给客户端；</li>
</ul>
<h3 id="３-常用注解有哪些？"><a href="#３-常用注解有哪些？" class="headerlink" title="３.常用注解有哪些？"></a>３.常用注解有哪些？</h3><h3 id="４-谈谈你对Spring的理解"><a href="#４-谈谈你对Spring的理解" class="headerlink" title="４.谈谈你对Spring的理解"></a>４.谈谈你对Spring的理解</h3><p>Spring是一个开源框架，为简化企业级应用开发而生，Spring是一个IOC和AOP容器框架</p>
<h3 id="５-Spring容器的主要核心是："><a href="#５-Spring容器的主要核心是：" class="headerlink" title="５.Spring容器的主要核心是："></a>５.Spring容器的主要核心是：</h3><p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202202050318374.png" alt="Spring的设计模式"></p>
<h2 id="三、SQL"><a href="#三、SQL" class="headerlink" title="三、SQL"></a>三、SQL</h2><h3 id="mysql和oracle的区别"><a href="#mysql和oracle的区别" class="headerlink" title="mysql和oracle的区别"></a>mysql和oracle的区别</h3><h3 id="innoDB和MyIsam的区别"><a href="#innoDB和MyIsam的区别" class="headerlink" title="innoDB和MyIsam的区别"></a>innoDB和MyIsam的区别</h3><h3 id="慢查询的原因"><a href="#慢查询的原因" class="headerlink" title="慢查询的原因"></a>慢查询的原因</h3><h3 id="行级锁表级锁"><a href="#行级锁表级锁" class="headerlink" title="行级锁表级锁"></a>行级锁表级锁</h3><h3 id="1-sql注入是什么？-和-的区别是什么"><a href="#1-sql注入是什么？-和-的区别是什么" class="headerlink" title="1.sql注入是什么？#{}和${}的区别是什么?"></a>1.sql注入是什么？#{}和${}的区别是什么?</h3><p>sql注入是指通过web表单输入恶意sql语句，激发数据库漏洞，而不是按设计者意图去执行sql语句。举例：select * from def_user where username=” <u>admin “  or  “a”=”a</u> “恒成立；</p>
<p>#{}是通过预编译处理，如select * from user where username=?,sql语义不会发生改变，在很大程度上可以防止sql注入</p>
<p>${}是字符串替换。在处理时，将 它替换成变量的值，不安全。</p>
<h3 id="2-MySQL性能优化有哪些？"><a href="#2-MySQL性能优化有哪些？" class="headerlink" title="2.MySQL性能优化有哪些？"></a>2.MySQL性能优化有哪些？</h3><ul>
<li>使用limit1</li>
<li>选择正确的数据库引擎</li>
<li>用not exists代替not in</li>
<li>对操作符进行优化，尽量不采用索引的操作符</li>
</ul>
<h2 id="四、Mybatis"><a href="#四、Mybatis" class="headerlink" title="四、Mybatis"></a>四、Mybatis</h2><h3 id="1、什么是-Mybatis？"><a href="#1、什么是-Mybatis？" class="headerlink" title="1、什么是 Mybatis？"></a>1、什么是 Mybatis？</h3><p>（1） Mybatis 是一个半 ORM（对象关系映射）框架，它内部封装了 JDBC，开<br>发时只需要关注 SQL 语句本身，不需要花费精力去处理加载驱动、创建连接、<br>创建 statement 等繁杂的过程。程序员直接编写原生态 sql，可以严格控制<br>sql 执行性能，灵活度高。<br>（2） MyBatis 可以使用 XML 或注解来配置和映射原生信息，将 POJO 映射成<br>数据库中的记录，避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果<br>集。<br>（3） 通过 xml 文件或注解的方式将要执行的各种 statement 配置起来，并通<br>过 java 对象和 statement 中 sql 的动态参数进行映射生成最终执行的 sql<br>语句，最后由 mybatis 框架执行 sql 并将结果映射为 java 对象并返回。<br>（从执行 sql 到返回 result 的过程）。</p>
<h2 id="五、Redis"><a href="#五、Redis" class="headerlink" title="五、Redis"></a>五、Redis</h2><p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202202050319649.png"></p>
<h2 id="六、RabbitMQ"><a href="#六、RabbitMQ" class="headerlink" title="六、RabbitMQ"></a>六、RabbitMQ</h2><h3 id="1、什么是rabbitmq？"><a href="#1、什么是rabbitmq？" class="headerlink" title="1、什么是rabbitmq？"></a>1、什么是rabbitmq？</h3><p><strong>答：</strong></p>
<p>采用AMQP高级消息队列协议的一种消息队列技术,最大的特点就是消费并不需要确保提供方存在,实现了服务之间的高度解耦。</p>
<h3 id="2、为什么要使用rabbitmq？"><a href="#2、为什么要使用rabbitmq？" class="headerlink" title="2、为什么要使用rabbitmq？"></a>2、为什么要使用rabbitmq？</h3><p><strong>答：</strong> 1、在分布式系统下具备异步,削峰,负载均衡等一系列高级功能；</p>
<p>2、拥有持久化的机制，进程消息，队列中的信息也可以保存下来。</p>
<p>3、实现消费者和生产者之间的解耦。</p>
<p>4、对于高并发场景下，利用消息队列可以使得同步访问变为串行访问达到一定量的限流，利于数据库的操作。</p>
<p>5、可以使用消息队列达到异步下单的效果，排队中，后台进行逻辑下单。</p>
<h3 id="4、如何确保消息正确地发送至RabbitMQ？如何确保消息接收方消费了消息？"><a href="#4、如何确保消息正确地发送至RabbitMQ？如何确保消息接收方消费了消息？" class="headerlink" title="4、如何确保消息正确地发送至RabbitMQ？如何确保消息接收方消费了消息？"></a>4、如何确保消息正确地发送至RabbitMQ？如何确保消息接收方消费了消息？</h3><p>答：<br>发送方确认模式<br>1.将信道设置成confirm模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的ID。<br>2.一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 ID）。<br>3.如果 RabbitMQ发生内部错误从而导致消息丢失，会发送一条nack（notacknowledged，未确认）消息。发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。<br>接收方确认机制<br>接收方消息确认机制<br>消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ才能安全地把消息从队列中删除。这里并没有用到超时机制，RabbitMQ仅通过Consumer的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，RabbitMQ给了Consumer足够长的时间来处理消息。保证数据的最终一致性；</p>
<h3 id="5-如何避免消息重复投递或重复消费？"><a href="#5-如何避免消息重复投递或重复消费？" class="headerlink" title="5.如何避免消息重复投递或重复消费？"></a>5.如何避免消息重复投递或重复消费？</h3><p><strong>答：</strong></p>
<p>在消息生产时，MQ内部针对每条生产者发送的消息生成一个inner-msg-id，作为去重的依据（消息投递失败并重传），避免重复的消息进入队列；</p>
<p>在消息消费时，要求消息体中必须要有一个 bizId（对于同一业务全局唯一，如支付ID、订单ID、帖子ID 等）作为去重的依据，避免同一条消息被重复消费。</p>
<h3 id="6-死信队列"><a href="#6-死信队列" class="headerlink" title="6.死信队列"></a>6.死信队列</h3><p>一个消息是有死亡状态的，它会被发送到一个指定的队列中，这个队列是一个普通的队列，根据他的功能，我们叫他死信队列。</p>
<h3 id="8、消息怎么路由？"><a href="#8、消息怎么路由？" class="headerlink" title="8、消息怎么路由？"></a>8、消息怎么路由？</h3><p>答：<br>消息提供方-&gt;路由-&gt;一至多个队列<br>消息发布到交换器时，消息将拥有一个路由键（routing key），在消息创建时设定。<br>通过队列路由键，可以把队列绑定到交换器上。<br>消息到达交换器后，RabbitMQ 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；<br>常用的交换器主要分为一下三种<br>1.fanout：如果交换器收到消息，将会广播到所有绑定的队列上<br>2.direct：如果路由键完全匹配，消息就被投递到相应的队列<br>3.topic：可以使来自不同源头的消息能够到达同一个队列。 使用topic交换器时，可以使用通配符</p>
<h3 id="七、ehcache"><a href="#七、ehcache" class="headerlink" title="七、ehcache"></a>七、ehcache</h3><p>ehcache直接在jvm虚拟机中缓存，速度快，效率高；但是缓存共享麻烦，集群分布式应用不方便。</p>
<p>Spring Cache 是 Spring 提供的一整套的缓存解决方案。虽然它本身并没有提供缓存的实现，但是它提供了一整套的接口和代码规范、配置、注解等，这样它就可以整合各种缓存方案了，比如 Redis、Ehcache，我们也就不用关心操作缓存的细节。</p>
<p>Spring 提供了四个注解来声明缓存规则。@Cacheable，@CachePut，@CacheEvict，@Caching。</p>
<h3 id="八、简历说明"><a href="#八、简历说明" class="headerlink" title="八、简历说明"></a>八、简历说明</h3><p>独立的模块设计+使用count判断是否存在，改为limit 1</p>
]]></content>
      <categories>
        <category>学习</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>实践知识整理</title>
    <url>/2021/08/03/%E5%AE%9E%E4%B9%A0%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<h1 id="知识内容"><a href="#知识内容" class="headerlink" title="知识内容"></a>知识内容</h1><h2 id="WebServer"><a href="#WebServer" class="headerlink" title="WebServer"></a>WebServer</h2><h3 id="什么是HTTP请求头-响应头"><a href="#什么是HTTP请求头-响应头" class="headerlink" title="什么是HTTP请求头/响应头"></a>什么是HTTP请求头/响应头</h3><p>1)请求(客户端-&gt;服务端[request])<br>     GET(请求的方式)     /newcoder/hello.html(请求的目标资源) HTTP/1.1(请求采用的协议和版本号)<br>     Accept: <em>/</em>(客户端能接收的资源类型)<br>     Accept-Language: en-us(客户端接收的语言类型)<br>     Connection: Keep-Alive(维护客户端和服务端的连接关系)<br>     Host: localhost:8080(连接的目标主机和端口号)<br>     Referer: <a href="http://localhost/links.asp(%E5%91%8A%E8%AF%89%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%88%91%E6%9D%A5%E8%87%AA%E4%BA%8E%E5%93%AA%E9%87%8C)">http://localhost/links.asp(告诉服务器我来自于哪里)</a><br>     User-Agent: Mozilla/4.0(客户端版本号的名字)<br>     Accept-Encoding: gzip, deflate(客户端能接收的压缩数据的类型)<br>     If-Modified-Since: Tue, 11 Jul     2000 18:23:51 GMT(缓存时间)<br>     Cookie(客户端暂存服务端的信息)<br>     Date: Tue, 11 Jul 2000     18:23:51 GMT(客户端请求服务端的时间)  </p>
<span id="more"></span>

<p>2)响应(服务端-&gt;客户端[response])<br>​        HTTP/1.1(响应采用的协议和版本号) 200(状态码) OK(描述信息)<br>​     Location:     <a href="https://link.zhihu.com/?target=http://www.baidu.com">http://www.baidu.com</a>(服务端需要客户端访问的页面路径)<br>​     Server:apache     tomcat(服务端的Web服务端名)<br>​     Content-Encoding:     gzip(服务端能够发送压缩编码类型)<br>​     Content-Length: 80(服务端发送的压缩数据的长度)<br>​     Content-Language: zh-cn(服务端发送的语言类型)<br>​     Content-Type:     text/html; charset=GB2312(服务端发送的类型及采用的编码方式)<br>​     Last-Modified:     Tue, 11 Jul 2000 18:23:51 GMT(服务端对该资源最后修改的时间)<br>​     Refresh:     1;url=<a href="https://link.zhihu.com/?target=http://www.it315.org">http://www.it315.org</a>(服务端要求客户端1秒钟后，刷新，然后访问指定的页面路径)<br>​     Content-Disposition: attachment;     filename=aaa.zip(服务端要求客户端以下载文件的方式打开该文件)<br>​     Transfer-Encoding:     chunked(分块传递数据到客户端）<br>​     Set-Cookie:SS=Q0=5Lb_nQ;     path=/search(服务端发送到客户端的暂存数据)<br>​     Expires:     -1//3种(服务端禁止客户端缓存页面数据)<br>​     Cache-Control:     no-cache(服务端禁止客户端缓存页面数据)<br>​     Pragma: no-cache(服务端禁止客户端缓存页面数据)<br>​     Connection: close(1.0)/(1.1)Keep-Alive(维护客户端和服务端的连接关系)  </p>
<h2 id="Lambda表达式"><a href="#Lambda表达式" class="headerlink" title="Lambda表达式"></a>Lambda表达式</h2><h3 id="1-匿名内部类"><a href="#1-匿名内部类" class="headerlink" title="1.匿名内部类"></a>1.匿名内部类</h3><p>匿名内部类也就是没有名字的内部类，正因为没有名字，所以匿名内部类只能使用一次，它通常用来简化代码编写</p>
<p>但使用匿名内部类还有个前提条件：<strong>必须继承一个父类或实现一个接口</strong></p>
<h4 id="实例1-不使用匿名内部类来实现抽象方法"><a href="#实例1-不使用匿名内部类来实现抽象方法" class="headerlink" title="实例1:不使用匿名内部类来实现抽象方法"></a>实例1:不使用匿名内部类来实现抽象方法</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">eat</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Child</span> <span class="keyword">extends</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eat</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;eat something&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Person p = <span class="keyword">new</span> Child();</span><br><span class="line">        p.eat();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>运行结果：</strong> eat something</p>
<p>可以看到，我们用Child继承了Person类，然后实现了Child的一个实例，将其向上转型为Person类的引用</p>
<p>但是，如果此处的Child类只使用一次，那么将其编写为独立的一个类岂不是很麻烦？</p>
<p>这个时候就引入了匿名内部类</p>
<h4 id="实例2：匿名内部类的基本实现"><a href="#实例2：匿名内部类的基本实现" class="headerlink" title="实例2：匿名内部类的基本实现"></a>实例2：匿名内部类的基本实现</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">eat</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Person p = <span class="keyword">new</span> Person() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eat</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;eat something&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        p.eat();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>运行结果：</strong> eat something</p>
<p>可以看到，我们直接将抽象类Person中的方法在大括号中实现了</p>
<p>这样便可以省略一个类的书写,并且，匿名内部类还能用于接口上</p>
<h4 id="实例3：在接口上使用匿名内部类"><a href="#实例3：在接口上使用匿名内部类" class="headerlink" title="实例3：在接口上使用匿名内部类"></a>实例3：在接口上使用匿名内部类</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eat</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Person p = <span class="keyword">new</span> Person() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eat</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;eat something&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        p.eat();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>运行结果：</strong> eat something</p>
<p>由上面的例子可以看出，<strong>只要一个类是抽象的或是一个接口</strong>，那么其子类中的方法都可以使用匿名内部类来实现</p>
<h3 id="2-Lambda表达式"><a href="#2-Lambda表达式" class="headerlink" title="2.Lambda表达式"></a>2.Lambda表达式</h3><p>对于单方法接口，即一个接口只定义了一种方法，我们可以只写出方法定义：</p>
<p>即简化匿名内部类的方式，<strong>其核心是一个接口实现类的覆盖重写，返回一个接口对象</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Person p = <span class="keyword">new</span> Person() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eat</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;eat something&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line">p.eat();</span><br><span class="line"></span><br><span class="line"><span class="comment">//简化后</span></span><br><span class="line">Person p = ()-&gt;System.out.println(<span class="string">&quot;eat something&quot;</span>);</span><br><span class="line">p.eat();</span><br></pre></td></tr></table></figure>

<h3 id="3-联系与区别"><a href="#3-联系与区别" class="headerlink" title="3.联系与区别"></a>3.联系与区别</h3><ul>
<li>匿名内部类可以为任意接口创建实例——不管接口包含多少个抽象方法，只要匿名内部类实现所有的抽象方法即可；但 Lambda 表达式只能为函数式接口创建实例。</li>
<li>匿名内部类可以为抽象类甚至普通类创建实例；但 Lambda 表达式只能为函数式接口创建实例。</li>
<li>匿名内部类实现的抽象方法的方法体允许调用接口中定义的默认方法；但 Lambda 表达式的代码块不允许调用接口中定义的默认方法。</li>
</ul>
<h2 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h2><h3 id="图谱"><a href="#图谱" class="headerlink" title="图谱"></a>图谱</h3><p><img src="https://img-blog.csdn.net/20131213145346421?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd3p5XzE5ODg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></p>
<h3 id="Data-Manipulation-Language"><a href="#Data-Manipulation-Language" class="headerlink" title="Data Manipulation Language"></a>Data Manipulation Language</h3><h4 id="连接词："><a href="#连接词：" class="headerlink" title="连接词："></a>连接词：</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">Table</span> <span class="keyword">where</span></span><br><span class="line"><span class="keyword">column</span> <span class="keyword">like</span> <span class="string">&#x27;name_%&#x27;</span></span><br><span class="line"><span class="keyword">column</span> <span class="keyword">between</span> <span class="string">&#x27;100&#x27;</span> <span class="keyword">and</span> <span class="string">&#x27;150&#x27;</span></span><br><span class="line"><span class="keyword">column</span> <span class="keyword">is</span> <span class="keyword">null</span></span><br><span class="line"><span class="keyword">in</span> (column1,column2...)</span><br></pre></td></tr></table></figure>

<h4 id="通配符："><a href="#通配符：" class="headerlink" title="通配符："></a>通配符：</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">%:任意字符</span></span><br><span class="line"><span class="string">_:任意单个字符</span></span><br><span class="line">[ ]<span class="string">:指定范围</span> <span class="string">([a-f])</span> <span class="string">或集合</span> <span class="string">([abcdef])</span> <span class="string">中的任何单个字符</span></span><br><span class="line">[<span class="string">^</span>]<span class="string">:不属于指定范围</span> <span class="string">([a-f])</span> <span class="string">或集合</span> <span class="string">([abcdef])</span> <span class="string">的任何单个字符</span></span><br><span class="line"><span class="string">escape</span> <span class="string">&#x27;\&#x27;：转义,select * from table where name like &#x27;</span><span class="string">user\_&#x27;</span> <span class="string">escape</span> <span class="string">&#x27;\&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="限定词"><a href="#限定词" class="headerlink" title="限定词:"></a>限定词:</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">distinct:唯一值</span></span><br><span class="line"><span class="string">order</span> <span class="string">by：排序规则，desc/asc</span></span><br><span class="line"><span class="string">group</span> <span class="string">by:分组.having</span> <span class="string">group_conditon</span></span><br><span class="line"><span class="string">limit</span> <span class="string">nums:限制个数</span></span><br><span class="line"><span class="string">offset</span> <span class="string">nums:从第几个开始</span></span><br><span class="line"><span class="string">Is</span> <span class="string">Not/Is</span> <span class="literal">NULL</span><span class="string">:判空</span></span><br></pre></td></tr></table></figure>

<h4 id="多表查询："><a href="#多表查询：" class="headerlink" title="多表查询："></a>多表查询：</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">table</span> A </span><br><span class="line"><span class="keyword">inner</span><span class="operator">/</span><span class="keyword">left</span><span class="operator">/</span><span class="keyword">right</span><span class="operator">/</span><span class="keyword">full</span> </span><br><span class="line"><span class="keyword">outer</span> <span class="keyword">join</span> <span class="keyword">Table</span> B </span><br><span class="line"><span class="keyword">on</span> conditions</span><br></pre></td></tr></table></figure>

<h4 id="函数："><a href="#函数：" class="headerlink" title="函数："></a>函数：</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">单行函数:</span><br><span class="line">    字符函数、数值函数、日期函数、转换函数、通用函数</span><br><span class="line">组合函数:</span><br><span class="line">     count、min、max、avg、sum</span><br></pre></td></tr></table></figure>

<h3 id="Data-Define-Language"><a href="#Data-Define-Language" class="headerlink" title="Data Define Language"></a>Data Define Language</h3><h4 id="库的管理"><a href="#库的管理" class="headerlink" title="库的管理"></a>库的管理</h4><p>用于定义数据库的三级结构，包括外模式、概念模式、内模式及其相互之间的映像，定义数据的完整性、安全控制等约束</p>
<h4 id="表的管理"><a href="#表的管理" class="headerlink" title="表的管理"></a>表的管理</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">create table if not exits MyTable&#123;</span><br><span class="line">    column1 DATATYPE TABLECONSTRAINT <span class="keyword">DEFAULT</span> default_value,</span><br><span class="line">    column2 DATATYPE TABLECONSTRAINT <span class="keyword">DEFAULT</span> default_value,</span><br><span class="line">&#125;</span><br><span class="line">DATATYPE:</span><br><span class="line">    <span class="type">Integer</span>,<span class="type">boolean</span></span><br><span class="line">TABLECONSTRAINT:</span><br><span class="line">    <span class="keyword">primary</span> keys,autoincrement,<span class="keyword">unique</span>,<span class="keyword">not</span> <span class="keyword">null</span>,<span class="keyword">check</span>,<span class="keyword">foreign</span>      key</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> MyTable</span><br><span class="line">① <span class="keyword">add</span> <span class="keyword">column</span> datatype tableconstraint <span class="keyword">default</span> default_value</span><br><span class="line">② <span class="keyword">drop</span> column_to_be_deleted</span><br><span class="line">③ rename <span class="keyword">to</span> new_table_name</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> if <span class="keyword">exists</span> MyTable</span><br></pre></td></tr></table></figure>

<h3 id="Data-Control-Language"><a href="#Data-Control-Language" class="headerlink" title="Data Control Language"></a>Data Control Language</h3><p>数据库控制语言：授权，角色控制等</p>
<ul>
<li><p>GRANT – 为用户赋予访问权限</p>
</li>
<li><p>REVOKE – 撤回授权权限</p>
</li>
</ul>
<h3 id="Transaction-Control-Language"><a href="#Transaction-Control-Language" class="headerlink" title="Transaction Control Language"></a>Transaction Control Language</h3><p>事务的概念：要么全部执行，要么全部不执行。<br>​事务的acid属性：atomicity、consistency、isolation、durability<br>​事务的创建：隐式事务、显示事务。事务具有明显的开启和结束标记。</p>
<h1 id="工具使用"><a href="#工具使用" class="headerlink" title="工具使用"></a>工具使用</h1><h2 id="1-GitFlow"><a href="#1-GitFlow" class="headerlink" title="1. GitFlow"></a>1. GitFlow</h2><p>可以在idea里面直接看到流程：<strong>提交需要反复确认，然后进行拉取</strong></p>
<p><img src="assets/image-20210818173247374.png" alt="image-20210818173247374"></p>
<table>
<thead>
<tr>
<th align="left">name</th>
<th align="left">Function</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>master</strong></td>
<td align="left">存放随时可供生产环境中的部署的代码</td>
</tr>
<tr>
<td align="left"><strong>develop</strong></td>
<td align="left">存放当前最新开发成果的分支，当代码足够稳定时可以合并到master分支上去。</td>
</tr>
<tr>
<td align="left"><strong>feature</strong></td>
<td align="left">开发新功能使用，最终合并到develop分支或抛弃掉</td>
</tr>
<tr>
<td align="left"><strong>release</strong></td>
<td align="left">做小的缺陷修正、准备发布版本所需的各项说明信息</td>
</tr>
<tr>
<td align="left"><strong>hotfix</strong></td>
<td align="left">代码的紧急修复工作</td>
</tr>
</tbody></table>
<p>查看Git工作区、暂存区的变更情况（可以知道哪些没有commit、哪些没有被Git追踪）：<code>git status</code></p>
<p>拉取远程最新的变更到本地：<code>git fetch</code></p>
<p>切换分支：<code>git checkout 分支名</code></p>
<p>将代码还原到某个版本(包括工作目录)：<code>git reset --hard 版本号</code></p>
<p>查看Git的提交(commit)记录：<code>git log</code></p>
<p>将代码还原到某个版本后，后悔了，想重新回去，但在提交记录已经找不到了。<code>git reset --hard</code> 把<code>reset 之后的 commit</code>都给抹杀掉了。找到最近的执行Git命令：<code>git reflog</code></p>
<p>还原到某个版本了，现在我为了稳健，不想再原来的分支上修改了，再<strong>新建一个分支</strong>吧（<code>-b</code> 参数把当前分支切换到了要创建的分支上）：<code>git checkout -b 分支名</code></p>
<p>我们把上一次还是”相对稳健“的分支合并到我新建的分支上：<code>git merge 分支</code></p>
<p>突然想看看现在有多少个分支：<code>git branch -a</code></p>
<p>新增几个文件了，随手<code>git add</code>一下吧</p>
<p>改得差不多了，随手<code>git commit -m</code>一下吧，最好还是<strong>写好备注</strong>，不然以后等改多了，你都不知道你改了什么啦。</p>
<p>改完了，提交到远程吧：<code>git push</code></p>
<p>想把远程分支最新的代码给拉下来，然后合并到本地上。我们可以用<code>git fetch</code>和<code>git merge</code>来实现，也可以通过<code>git pull</code>来实现。一般我用的都是<code>git fetch</code>+<code>git merge</code>，这样会更加<strong>可控</strong>一些</p>
<p>有的时候，本地分支在master分支，然后忘了切其他的分支去修改，直接在master改了，然后也push到远程了。等你发现的时候，你会真的想骂自己。</p>
<p>咋办？最简单的办法其实我们还是可以<code>git reset --hard</code>到对应的版本，然后将其修改或者复原，再强制提交到<code>master</code>分支：<code>git push -u origin/master -f</code></p>
<h2 id="2-idea-插件"><a href="#2-idea-插件" class="headerlink" title="2. idea 插件"></a>2. idea 插件</h2><h3 id="2-1-RestfulToolkit—RESTful服务开发"><a href="#2-1-RestfulToolkit—RESTful服务开发" class="headerlink" title="2.1 RestfulToolkit—RESTful服务开发"></a>2.1 RestfulToolkit—RESTful服务开发</h3><ul>
<li>2.1.1 根据 URL 直接跳转到对应的方法定义 ( Ctrl \ or Ctrl Alt N );</li>
<li>2.1.2 提供了一个 Services tree 的显示窗口;</li>
<li>2.1.3 一个简单的 http 请求工具;</li>
<li>2.1.4 在请求方法上添加了有用功能: 复制生成 URL;复制方法参数…</li>
<li>2.1.5 其他功能: java 类上添加 Convert to JSON 功能，格式化 json 数据 ( Windows: Ctrl + Enter; Mac: Command + Enter )。</li>
</ul>
<h3 id="2-2-快捷键"><a href="#2-2-快捷键" class="headerlink" title="2.2 快捷键"></a>2.2 快捷键</h3><p><code>Ctrl+Shift+Enter</code>   完善整条语句、分号、if语句等</p>
<p><code>Ctrl+W</code>   扩大选取范围</p>
<p><code>Ctrl+F8 </code>  打断点</p>
<p><code>Shift+F9</code>   debug</p>
<p><code>F7 F8 F9</code>   进入方法、下一步、下个断点</p>
<p>ctrl+T 直接拉取git更新</p>
<p>ctrl+alt+shift+C  copy reference</p>
<h1 id="用户评级-项目"><a href="#用户评级-项目" class="headerlink" title="用户评级 项目"></a>用户评级 项目</h1><h2 id="PageInfo"><a href="#PageInfo" class="headerlink" title="PageInfo"></a>PageInfo</h2><figure class="highlight"><table><tr><td class="code"><pre><span class="line">Request URL: </span><br><span class="line">/api/audiences?orderColumn=createTime&amp;orderType=desc&amp;page=1&amp;pagesize=30&amp;readState=READ_SUCCESS</span><br></pre></td></tr></table></figure>

<p>读取过程 : PageInterceptor.class</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">PageInfo page = <span class="keyword">new</span> PageInfo();</span><br><span class="line">            page.setCurrent(<span class="keyword">this</span>.getIntValue(request, <span class="string">&quot;page&quot;</span>, <span class="number">1</span>));</span><br><span class="line">            page.setPagesize(<span class="keyword">this</span>.getIntValue(request, <span class="string">&quot;pagesize&quot;</span>, annotation.size()));</span><br><span class="line">            String orderColumn = request.getParameter(<span class="string">&quot;orderColumn&quot;</span>);</span><br></pre></td></tr></table></figure>

<h2 id="项目组件"><a href="#项目组件" class="headerlink" title="项目组件"></a>项目组件</h2><ul>
<li><p>parent : crius</p>
</li>
<li><p>被dependencyManagement管理版本号的组件 :  </p>
<p>opencv、log4j、reflections 、 lombok 、compress 、commons-jcs-core 、kryo 、httpclient 、mapstruct 、aws-java-sdk-s3 、com.amazonaws 、jmespath-java 、commons-collections 、spring-cloud-dependencies 、dependencies </p>
</li>
<li><p>har-manager模块组件：</p>
<p>spring-cloud-starter-openfeign 、spring-cloud-starter-netflix-hystrix 、spring-boot-starter-cache 、ehcache、crius-spring-boot-starter 、mybatis 、crius-oss-amazon-s3-spring-boot-starter 、crius-oss-azure-storage-spring-boot-starter 、jmespath-java 、commons-collections、spring-boot-starter-actuator 、spring-boot-starter-rabbitmq 、spring-cloud-starter-alibaba-nacos-config</p>
</li>
</ul>
<h2 id="Oauth授权"><a href="#Oauth授权" class="headerlink" title="Oauth授权"></a>Oauth授权</h2><p>1.网关拦截</p>
<p>由devops平台上的网关决定redirect地址，Oauth进行授权鉴权，如没有权限，用户拿着token去访问第三方平台</p>
<p>注：微服务技术解决方案下的，网关至少需要具备图示基本功能。</p>
<ol>
<li>网关作为单点入口，完成统一的请求管理</li>
<li>免去客户端直接对接众多微服务的复杂性，采用单点入口，实现路由转发，从而实现服务调用</li>
<li>服务对于整个系统来讲，是不稳定的，那么网关，需要进行限流熔断，保持系统的稳定与分区容错性</li>
<li>对于服务调用的链路，网关有职责进行记录，日志监控，保证整个系统，在监控下工作</li>
<li>系统可能不仅仅是由自有客户端调用，很多时候，系统开放能力API给外部，因此网关需要安全认证，来保证安全</li>
</ol>
<p>2.Security授权</p>
<p>Security通过authLoginFilter同步hac用户信息</p>
<h2 id="Maven依赖管理"><a href="#Maven依赖管理" class="headerlink" title="Maven依赖管理"></a>Maven依赖管理</h2><ul>
<li><p>父pom需要添加<code>&lt;packaging&gt;pom&lt;/packaging&gt;</code>。</p>
</li>
<li><p>父pom需要用<code>&lt;modules&gt;&lt;module&gt;子module名&lt;/module&gt;&lt;/modules&gt;</code>注明子module有哪些。</p>
</li>
<li><p>父pom声明依赖时<code>&lt;dependencies&gt;</code>外要嵌套<code>&lt;dependencyManagement&gt;</code>才能被子pom继承到，我就是忘了这点。</p>
</li>
<li><p>子pom需要通过<code>&lt;parent&gt;&lt;/parent&gt;</code>指定父项目，声明依赖时就默认会用父pom中的版本了。</p>
</li>
</ul>
<h2 id="项目创建顺序"><a href="#项目创建顺序" class="headerlink" title="项目创建顺序"></a>项目创建顺序</h2><p>业务  - &gt;  授权  - &gt;  性能优化</p>
<h2 id="DDD"><a href="#DDD" class="headerlink" title="DDD"></a>DDD</h2><ul>
<li>entity\dao\mapper\vo写在repository中</li>
<li>service\特有的entity写在特定的module中</li>
</ul>
<h2 id="MyBatis枚举类映射"><a href="#MyBatis枚举类映射" class="headerlink" title="MyBatis枚举类映射"></a>MyBatis枚举类映射</h2><p><strong>mybatis默认的枚举类型处理器 :</strong></p>
<ul>
<li><p>EnumTypeHandler<br>mybatis的默认枚举类型处理器，将枚举类型的name持久化到数据库；</p>
</li>
<li><p>EnumOrdinalTypeHandler<br>mybatis原生支持的另一种枚举类型处理器，将枚举类型的索引序号持久化到数据库，需要全局配置或者在需要的字段上单独配置；</p>
</li>
</ul>
<p><strong>mybatis配置全局默认枚举类型处理器 :  defaultEnumTypeHandler</strong></p>
<ul>
<li>mybatis在3.4.5及之后版本中，新增了一个指定全局默认枚举类型处理器的配置项 :  <strong>default-enum-type-handler</strong><br>在mybatis-config.xml中添加如下配置即可使自定义处理器全局生效，解决了之前新增枚举都需要单独配置的烦恼；</li>
</ul>
<p><img src="assets/image-20210910184840551.png" alt="image-20210910184840551"></p>
<p><img src="assets/image-20210910184912954.png" alt="image-20210910184912954"></p>
<h2 id="使用TypeHandler将List集合数据存入数据库"><a href="#使用TypeHandler将List集合数据存入数据库" class="headerlink" title="使用TypeHandler将List集合数据存入数据库"></a>使用TypeHandler将List集合数据存入数据库</h2><p><a href="https://www.dtmao.cc/news_show_785309.shtml">https://www.dtmao.cc/news_show_785309.shtml</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@MappedJdbcTypes(value=JdbcType.VARCHAR)</span></span><br><span class="line"><span class="meta">@MappedTypes(List.class)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ListToVarchar</span> <span class="keyword">implements</span> <span class="title">TypeHandler</span>&lt;<span class="title">List</span>&lt;<span class="title">String</span>&gt;&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 遍历List类型的入参，转换为JSON格式，使用Statement对象插入数据库</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setParameter</span><span class="params">(PreparedStatement ps, <span class="keyword">int</span> i, List&lt;String&gt; objectList, JdbcType jdbcType)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(objectList.isEmpty())&#123;</span><br><span class="line">            ps.setString(i,<span class="keyword">null</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        String s = JSON.toJSONString(objectList);</span><br><span class="line">        ps.setString(i,s);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取String类型的结果，使用parseObject将json对象转换为java对象</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;String&gt; <span class="title">getResult</span><span class="params">(ResultSet resultSet, String s)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> JSON.parseObject(resultSet.getString(s),<span class="keyword">new</span> TypeReference&lt;List&lt;String&gt;&gt;() &#123;&#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取String类型的结果，使用parseObject将json对象转换为java对象</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;String&gt; <span class="title">getResult</span><span class="params">(ResultSet resultSet, <span class="keyword">int</span> i)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        String s = resultSet.getString(i);</span><br><span class="line">        <span class="keyword">return</span>  JSON.parseObject(s,<span class="keyword">new</span> TypeReference&lt;List&lt;String&gt;&gt;() &#123;&#125;);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取String类型的结果，使用parseObject将json对象转换为java对象</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;String&gt; <span class="title">getResult</span><span class="params">(CallableStatement callableStatement, <span class="keyword">int</span> i)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        String s = callableStatement.getString(i);</span><br><span class="line">        <span class="keyword">return</span> JSON.parseObject(s,<span class="keyword">new</span> TypeReference&lt;List&lt;String&gt;&gt;() &#123;&#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="开发避坑"><a href="#开发避坑" class="headerlink" title="开发避坑"></a>开发避坑</h1><h2 id="1-判空"><a href="#1-判空" class="headerlink" title="1.判空"></a>1.判空</h2><ul>
<li><p>Constant.equals(Variables);</p>
</li>
<li><p>Java中判断list为空(CollectionUtils.isEmpty)等同于 (list==null&amp;&amp;list.isEmpty())</p>
</li>
</ul>
<h2 id="2-typeHandler匹配问题"><a href="#2-typeHandler匹配问题" class="headerlink" title="2.typeHandler匹配问题"></a>2.typeHandler匹配问题</h2><ul>
<li>使用typeHandler去数据库中查询匹配时，注意序列化和反序列化的问题，需要二者hashcode完全一致，所以最好还是从数据库中找出json，映射为实体对象，在判断是否匹配</li>
<li>错误示例： select语句中，即使数据库中json内容一致，但仍旧不能匹配</li>
<li><img src="assets/image-20211116161549936.png" alt="image-20211116161549936"></li>
</ul>
<h1 id="隐私条款项目"><a href="#隐私条款项目" class="headerlink" title="隐私条款项目"></a>隐私条款项目</h1><h2 id="1-定时任务"><a href="#1-定时任务" class="headerlink" title="1.定时任务"></a>1.定时任务</h2><p><strong>- @SchedulerLock注解：为方法加上锁。</strong></p>
<p>name属性（锁的名称）必须指定，每次只能执行一个具有相同名字的任务。</p>
<p><strong>- lockAtMostFor属性，指定执行节点死亡时应该保留锁的时间。</strong></p>
<p>设置锁的最大持有时间,为了解决如果持有锁的节点挂了,无法释放锁,其他节点无法进行下一次任务。设置了最大持有时间，当持有时间到了自动释放锁，不影响下一次执行。</p>
<p><strong>- lockAtLeastFor属性，指定保留锁的最短时间。</strong></p>
<p>主要目的是在任务非常短的且节点之间存在时钟差异的情况下防止多个节点执行。这个属性是锁的持有时间。设置了多少就一定会持有多长时间，在此期间，下一次任务执行时，其他节点包括它本身是不会执行任务的。</p>
<h2 id="2-隐私条款模板"><a href="#2-隐私条款模板" class="headerlink" title="2.隐私条款模板"></a>2.隐私条款模板</h2><p>接口文档</p>
<ul>
<li>查看模板   GET     /api/templates</li>
<li>新建模板   POST    /api/templates</li>
<li>编辑模板  PATCH  /api/templates/{templateId}</li>
<li>删除模板  DELETE    /api/templates/{templateId}</li>
</ul>
<h2 id="3-校验"><a href="#3-校验" class="headerlink" title="3.校验"></a>3.校验</h2><ul>
<li>@Unique   name字段一致，表示绑定在一起校验<img src="assets/image-20211104145855450.png" alt="image-20211104145855450"></li>
</ul>
<h2 id="4-特殊用法"><a href="#4-特殊用法" class="headerlink" title="4.特殊用法"></a>4.特殊用法</h2><ul>
<li>```java<br>/**<ul>
<li>则在路径中悄悄接收projectIds</li>
<li>/<br>@JsonIgnore<br>private List<Long> projectIds;<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- 通过一系列Id查找</span><br><span class="line">  </span><br><span class="line">  &#96;&#96;&#96;xml</span><br><span class="line">  &lt;select id&#x3D;&quot;getClauses&quot; resultType&#x3D;&quot;long&quot;&gt;</span><br><span class="line">      select id from def_privacy_clause where project_id in</span><br><span class="line">      &lt;foreach collection&#x3D;&quot;list&quot; item&#x3D;&quot;id&quot; open&#x3D;&quot;(&quot; close&#x3D;&quot;)&quot; separator&#x3D;&quot;,&quot;&gt;</span><br><span class="line">          #&#123;id&#125;</span><br><span class="line">      &lt;&#x2F;foreach&gt;</span><br><span class="line">  &lt;&#x2F;select&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h2 id="3-部署踩坑"><a href="#3-部署踩坑" class="headerlink" title="3.部署踩坑"></a>3.部署踩坑</h2><h4 id="1-消息已发，计算端没有日志"><a href="#1-消息已发，计算端没有日志" class="headerlink" title="(1)消息已发，计算端没有日志"></a>(1)消息已发，计算端没有日志</h4><ul>
<li><p>检查MQ配置</p>
</li>
<li><p>检查消费者</p>
</li>
<li><p>计算端磁盘已满</p>
</li>
</ul>
]]></content>
      <categories>
        <category>学习</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>数据管理与分析 - 基础知识</title>
    <url>/2022/04/09/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E4%B8%8E%E5%88%86%E6%9E%90(1)/</url>
    <content><![CDATA[<h1 id="数据库分类"><a href="#数据库分类" class="headerlink" title="数据库分类"></a>数据库分类</h1><h4 id="关系型数据库"><a href="#关系型数据库" class="headerlink" title="关系型数据库"></a>关系型数据库</h4><p>存储的格式可以直观地反映实体间的关系。SQL表达能力很强。</p>
<h4 id="非关系型数据库"><a href="#非关系型数据库" class="headerlink" title="非关系型数据库"></a>非关系型数据库</h4><p>（1）键值对存储（key-value）：代表软件Redis，它的优点能够进行数据的快速查询，而缺点是需要存储数据之间的关系。</p>
<p>（2）列存储：代表软件Hbase，它的优点是对数据能快速查询，数据存储的扩展性强。而缺点是数据库的功能有局限性。</p>
<p>（3）文档数据库存储：代表软件MongoDB，它的优点是对数据结构要求不特别的严格。而缺点是查询性的性能不好，同时缺少一种统一查询语言。</p>
<p>（4）图形数据库存储：代表软件InfoGrid，它的优点可以方便的利用图结构相关算法进行计算。而缺点是要想得到结果必须进行整个图的计算，而且遇到不适合的数据模型时，图形数据库很难使用。</p>
<span id="more"></span>

<h4 id="数据库的需求变化"><a href="#数据库的需求变化" class="headerlink" title="数据库的需求变化"></a>数据库的需求变化</h4><p>数据量和负载激增</p>
<ul>
<li>扩展性变得更重要</li>
<li>性价比变得更重要</li>
</ul>
<p>云计算的普及</p>
<ul>
<li>易用性变得更重要</li>
</ul>
<h4 id="关系型数据库的查询执行过程"><a href="#关系型数据库的查询执行过程" class="headerlink" title="关系型数据库的查询执行过程"></a>关系型数据库的查询执行过程</h4><p>SQL –&gt; AST（解析树）–&gt; <font color=#bbbb>PLANS（查询计划）–&gt; BEST PLAN –&gt; 执行 –&gt; RESULTS</font></p>
<h5 id="一、语法解析器和预处理器"><a href="#一、语法解析器和预处理器" class="headerlink" title="一、语法解析器和预处理器"></a>一、语法解析器和预处理器</h5><p>1.MySQL解析器通过关键字将SQL语句进行解析，并生成对应的解析树；</p>
<p>2.MySQL解析器将使用MySQL语法规则验证和解析查询，eg：验证是否使用错误的关键字、使用关键字的顺序是否正确、验证引号是否前后匹配等；</p>
<p>3.预处理器根据一些MySQL规则进行进一步检查解析树是否合法，eg：检查数据表和数据列是否存在，解析名字和别名是否有歧义；</p>
<p>4.下一步预处理器验证用户权限，查看用户是否有操作权限，通常很快；</p>
<h5 id="二、查询优化器"><a href="#二、查询优化器" class="headerlink" title="二、查询优化器"></a>二、查询优化器</h5><p>1.优化器的作用就是找到最好的执行计划；</p>
<p>2.语法树被认为是合法后，优化器将MySQL语句转换为执行计划，一条查询可以有多种执行方式，最后都返回相同的结果；</p>
<p>3.生成执行计划过程</p>
<p>4.MySQL使用基于成本的优化器（CBO cost-based optimizer），会预测一个查询使用某种执行计划的成本，选择其中成本最小的一个；</p>
<p>5.导致MySQL优化器选择非最优执行计划的原因</p>
<p>6.MySQL可以处理的优化类型</p>
<h5 id="三、EXAMPLE"><a href="#三、EXAMPLE" class="headerlink" title="三、EXAMPLE:"></a>三、EXAMPLE:</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> <span class="operator">&lt;</span>select_list<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">FROM</span> <span class="operator">&lt;</span>left_table<span class="operator">&gt;</span></span><br><span class="line"><span class="operator">&lt;</span>join_type<span class="operator">&gt;</span> <span class="keyword">JOIN</span> <span class="operator">&lt;</span>right_table<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">ON</span> <span class="operator">&lt;</span>join_condition<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">WHERE</span> <span class="operator">&lt;</span>where_condition<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="operator">&lt;</span>group_by_list<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">HAVING</span> <span class="operator">&lt;</span>having_condition<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="operator">&lt;</span>order_by_condition<span class="operator">&gt;</span></span><br><span class="line">LIMIT <span class="operator">&lt;</span>limit_number<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<h6 id="SQL的执行过程："><a href="#SQL的执行过程：" class="headerlink" title="SQL的执行过程："></a>SQL的执行过程：</h6><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># <span class="keyword">FROM</span> ：作笛卡尔积</span><br><span class="line"># <span class="keyword">WHERE</span>：过滤</span><br><span class="line"># <span class="keyword">GROUP</span> <span class="keyword">BY</span>：分组</span><br><span class="line"># <span class="keyword">HAVING</span>：过滤</span><br><span class="line"># <span class="keyword">SELECT</span>：列表</span><br><span class="line"># 执行 <span class="keyword">DISTINCT</span> 子句</span><br><span class="line"># 执行 <span class="keyword">ORDER</span> <span class="keyword">BY</span> 子句</span><br></pre></td></tr></table></figure>

<p>每个步骤都会产生一个虚拟表，该虚拟表被用作下一个步骤的输入。这些虚拟表对调用者（客户端应用程序或者外部查询）不可用。只是最后一步生成的表才会返回给调用者。</p>
<h5 id="四、B-树"><a href="#四、B-树" class="headerlink" title="四、B+树"></a>四、B+树</h5><p>B+树是B树的一种变形形式，B+树上的叶子结点存储关键字以及相应记录的地址，叶子结点以上各层作为索引使用。一棵m阶的B+树定义如下: </p>
<p>(1)每个结点至多有m个子女；</p>
<p>(2)除根结点外，每个结点至少有和∟m/2」个子女，根结点至少有两个子女；</p>
<p>(3)有k个子女的结点必有k个关键字。</p>
<p>B+树的查找与B树不同，当索引部分某个结点的关键字与所查的关键字相等时，并不停止查找，应继续沿着这个关键字左边的指针向下，一直查到该关键字所在的叶子结点为止。</p>
<h5 id="五、列存数据库中的查询计划如何执行"><a href="#五、列存数据库中的查询计划如何执行" class="headerlink" title="五、列存数据库中的查询计划如何执行"></a>五、列存数据库中的查询计划如何执行</h5><p><a href="https://draveness.me/whys-the-design-olap-column-oriented/">https://draveness.me/whys-the-design-olap-column-oriented/</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>数据管理与分析</category>
      </categories>
      <tags>
        <tag>数据管理与分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据管理与分析 - 事务</title>
    <url>/2022/04/16/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E4%B8%8E%E5%88%86%E6%9E%90(2)/</url>
    <content><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h3 id="OLTP-vs-OLAP"><a href="#OLTP-vs-OLAP" class="headerlink" title="OLTP vs OLAP"></a>OLTP vs OLAP</h3><p><strong>1、基本含义不同：</strong><font color=#bbbb>OLTP，即联机事务处理（on-line transaction processing）是传统的关系型数据库的主要应用</font>，主要是基本的、日常的事务处理，记录即时的增、删、改、查，比如在银行存取一笔款，就是一个事务交易。<font color=#bbbb>OLAP，即联机分析处理（On-Line Analytical Processing），是数据仓库的核心部心</font>，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。典型的应用就是复杂的动态报表系统。<br><strong>2、实时性要求不同：</strong>OLTP实时性要求高，OLTP 数据库旨在使事务应用程序仅写入所需的数据，以便尽快处理单个事务。OLAP的实时性要求不是很高，很多应用顶多是每天更新一下数据。<br><strong>3、数据量不同：</strong>OLTP数据量不是很大，一般只读/写数十条记录，处理简单的事务。OLAP数据量大，因为OLAP支持的是动态查询，所以用户也许要通过将很多数据的统计后才能得到想要知道的信息，例如时间序列分析等等，所以处理的数据量很大。<br><strong>4、用户和系统的面向性不同：</strong>OLTP是面向顾客的,用于事务和查询处理。OLAP是面向市场的,用于数据分析。<br><strong>5、数据库设计不同：</strong>OLTP采用实体-联系ER模型和面向应用的数据库设计。OLAP采用星型或雪花模型和面向主题的数据库设计。</p>
<span id="more"></span>

<h3 id="OLTP面对的问题"><a href="#OLTP面对的问题" class="headerlink" title="OLTP面对的问题"></a>OLTP面对的问题</h3><ul>
<li><p>硬件失效    – 宕机/停电     – 硬件损坏       – 灾难</p>
</li>
<li><p>软件错误    – Bug   – 恶意攻击</p>
</li>
<li><p>并发问题    – 多个用户同时更新数据出现异常</p>
</li>
</ul>
<h3 id="ACID"><a href="#ACID" class="headerlink" title="ACID"></a>ACID</h3><p>原子性（Atomicity）：要么未开始，要么全部完成，不存在中间状态</p>
<p>一致性（Consistency）：事务的执行不会破坏数据的正确性，即符合约束。</p>
<p>隔离性（Isolation）：多个事务不会互相破坏。常见于并发问题。</p>
<p>持久性（Durability）：一旦提交成功，对数据的修改不会丢失</p>
<h3 id="undolog、redolog、binlog"><a href="#undolog、redolog、binlog" class="headerlink" title="undolog、redolog、binlog"></a>undolog、redolog、binlog</h3><h4 id="Undo日志的规则"><a href="#Undo日志的规则" class="headerlink" title="Undo日志的规则"></a>Undo日志的规则</h4><p>(1) 每一次对数据的改动都需要记录日志。</p>
<p>(2) <strong>日志记录必须在数据之前到达磁盘</strong>。(write ahead logging: WAL)</p>
<p>(3) 事务结束<strong>之前</strong>，所有的数据和日志必须到达磁盘。（保证持久性）</p>
<p>例如：update column A value = value * 2; update column B value = value * 2;</p>
<p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202204161518546.png" alt="image-20220416151835467"></p>
<h4 id="Redo日志的规则"><a href="#Redo日志的规则" class="headerlink" title="Redo日志的规则"></a>Redo日志的规则</h4><p>(1) 每一次对数据的改动都需要记录日志。</p>
<p>(2) <strong>事务提交之前所有的日志必须到达磁盘</strong>。(write ahead logging: WAL)</p>
<p>(3) 事务提交<strong>之后</strong>才能将数据写到磁盘。</p>
<p>(4) 数据到达磁盘后，需在日志中记录END。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202204161525145.png" alt="image-20220416152543073"></p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p><strong>undolog</strong>    用来保证事务回滚和MVCC功能。</p>
<p><strong>redolog</strong>     用来保证事务的持久性、在系统崩溃的时候能保证数据恢复。</p>
<p><strong>binlog</strong>        用于记录数据库执行的写入性操作(不包括查询)信息的二进制日志。是 MySQL的逻辑日志。</p>
<p>更多详细信息：<a href="https://segmentfault.com/a/1190000023827696">https://segmentfault.com/a/1190000023827696</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>数据管理与分析</category>
      </categories>
      <tags>
        <tag>数据管理与分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据管理与分析 - 事务的隔离级别</title>
    <url>/2022/04/16/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E4%B8%8E%E5%88%86%E6%9E%90(3)/</url>
    <content><![CDATA[<p>数据库遵循的是两段锁协议，将事务分成两个阶段，加锁阶段和解锁阶段（所以叫两段锁）</p>
<ul>
<li>加锁阶段：在该阶段可以进行加锁操作。在对任何数据进行读操作之前要申请并获得S锁（共享锁，其它事务可以继续加共享锁，但不能加排它锁），在进行写操作之前要申请并获得X锁（排它锁，其它事务不能再获得任何锁）。加锁不成功，则事务进入等待状态，直到加锁成功才继续执行。</li>
<li>解锁阶段：当事务释放了一个封锁以后，事务进入解锁阶段，在该阶段只能进行解锁操作不能再进行加锁操作。</li>
</ul>
<h3 id="事务的异常等级"><a href="#事务的异常等级" class="headerlink" title="事务的异常等级"></a>事务的异常等级</h3><p>事务的隔离级别是指：多个读写操作达到一定的隔离性要求。最高隔离级别是<font color=#bbbb>冲突可串行化</font>。</p>
<blockquote>
<p>串行化就是把同一个事务要做的读写操作按先后顺序排到一块。并发事务可以调整成串行化的话，就称为冲突可串行化。</p>
</blockquote>
<hr>
<p>例. 先导解释：r1(A)，其中r代read表读操作，1代表事务1，A代表A类数据。w2(B)，w代表write写操作，2代表事务2，B代表数据B。</p>
<p>​        <font style="background:#D1EEEE">r1(A)w1(A)</font><font style="background:#FF83FA">r2(A)w2(A)</font><font style="background:#C0FF3E">r1(B)w1(B)</font><font style="background:yellow">r2(B)w2(B)</font>  总共8个操作，2个事务并发执行。</p>
<p>在操作不冲突的情况下，变换可得：</p>
<p>​        <font style="background:#D1EEEE">r1(A)w1(A)r1(B)w1(B)</font><font style="background:#FF83FA">r2(A)w2(A)r2(B)w2(B)</font> </p>
<p>这就相当于执行了串行操作T1事务，T2事务。于是，这就是冲突可串行化。</p>
<hr>
<p>如果不满足冲突可串行化，则会产生以下异常：</p>
<h4 id="脏写"><a href="#脏写" class="headerlink" title="脏写"></a>脏写</h4><p>T1在T2<strong>提交前修改</strong>同一数据</p>
<h4 id="脏读"><a href="#脏读" class="headerlink" title="脏读"></a>脏读</h4><p>T1在T2<strong>提交前读取</strong>T1修改的数据</p>
<table>
<thead>
<tr>
<th>T1</th>
<th align="left">T2</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td align="left">开始事务</td>
</tr>
<tr>
<td>开始事务</td>
<td align="left"></td>
</tr>
<tr>
<td></td>
<td align="left">查询账户余额为2000</td>
</tr>
<tr>
<td></td>
<td align="left">取款1000，余额1000</td>
</tr>
<tr>
<td><font color=#bbbb>查询账余额为1000（产生脏读）</font></td>
<td align="left"></td>
</tr>
<tr>
<td></td>
<td align="left">取款异常，事务回滚，余额变更为2000</td>
</tr>
<tr>
<td>收入2000，余额为3000</td>
<td align="left"></td>
</tr>
<tr>
<td>提交事务</td>
<td align="left"></td>
</tr>
<tr>
<td>备注：按正确逻辑，应为4000</td>
<td align="left"></td>
</tr>
</tbody></table>
<h4 id="不可重复读"><a href="#不可重复读" class="headerlink" title="不可重复读"></a>不可重复读</h4><p>T1在T2修改并<strong>提交前读取</strong>了同一数据项，且有<strong>可能再次读取</strong>同一数据项</p>
<table>
<thead>
<tr>
<th>T1</th>
<th align="left">T2</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td align="left">开始事务</td>
</tr>
<tr>
<td>开始事务</td>
<td align="left"></td>
</tr>
<tr>
<td>查询账户余额为2000</td>
<td align="left"></td>
</tr>
<tr>
<td>其他操作…</td>
<td align="left"></td>
</tr>
<tr>
<td></td>
<td align="left">取款1000，余额1000</td>
</tr>
<tr>
<td></td>
<td align="left">提交事务</td>
</tr>
<tr>
<td><font color=#bbbb>第二次查询余额为1000（不可重复读）</font></td>
<td align="left"></td>
</tr>
<tr>
<td>备注：按正确逻辑，事务T1两次数据应该一致</td>
<td align="left"></td>
</tr>
</tbody></table>
<h4 id="幻读"><a href="#幻读" class="headerlink" title="幻读"></a>幻读</h4><p>Transaction T1 reads a set of data items satisfying some. Transaction T2 then creates data items that satisfy T1s and commits. If T1 then repeats its read with the same , it gets a set of data items different from the first read.</p>
<table>
<thead>
<tr>
<th>T1</th>
<th>T2</th>
</tr>
</thead>
<tbody><tr>
<td>select * where dept =”Acct”<br />//find(“sue”,”Acct”) and (“Tim”,”Acct”)</td>
<td></td>
</tr>
<tr>
<td></td>
<td>insert (“Joe”,”Acct”) and commit</td>
</tr>
<tr>
<td>select * where dept =”Acct”<br />//find(“sue”,”Acct”) and (“Tim”,”Acct”) and<br />//<font color=red>(“Joe”,”Acct”)</font></td>
<td></td>
</tr>
</tbody></table>
<h3 id="事物的隔离级别"><a href="#事物的隔离级别" class="headerlink" title="事物的隔离级别"></a>事物的隔离级别</h3><p>防止产生不同等级的异常 对应 不同的隔离级别，但是都必须满足不产生脏写</p>
<table>
<thead>
<tr>
<th>隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
</tr>
</thead>
<tbody><tr>
<td>read un-committed</td>
<td>可能产生</td>
<td>可能产生</td>
<td>可能产生</td>
</tr>
<tr>
<td>read committed</td>
<td>/</td>
<td>可能产生</td>
<td>可能产生</td>
</tr>
<tr>
<td>repeatable read</td>
<td>/</td>
<td>/</td>
<td>可能产生</td>
</tr>
<tr>
<td>serializable</td>
<td>/</td>
<td>/</td>
<td>/</td>
</tr>
</tbody></table>
<p>隔离级别越高，提供的隔离性保障越强，并发能力也就越弱，实现代价很大，所以很多关系型数据库仅能做到RC级别，MySQL的默认隔离级别就是RC。</p>
<h3 id="分布式系统的并发控制与一致性协议"><a href="#分布式系统的并发控制与一致性协议" class="headerlink" title="分布式系统的并发控制与一致性协议"></a>分布式系统的并发控制与一致性协议</h3><h4 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h4><p>Ø 保证并发事务的多个操作之间不相互影响（事务的写入对并发事务的可见性） </p>
<p>Ø 对  <em><u>并发事务间相互影响</u></em>  的约束 </p>
<p>Ø 以 <strong>隔离级别</strong> 作为衡量标准</p>
<h4 id="一致性协议"><a href="#一致性协议" class="headerlink" title="一致性协议"></a>一致性协议</h4><p>Ø 保持多个副本数据的一致，即要求多副本上事务执行顺序是 一致的（事务的写入以何种顺序可见）</p>
<p>Ø 对  <u><em>事务顺序</em></u>  的约束</p>
<p>Ø 以 <strong>一致性级别</strong> 作为衡量标准</p>
<hr>
<p><strong>一个仅保证可串行化的系统在多副本环境下是正确的吗？</strong></p>
<p>Ø 可串行化系统只保证一个串行的顺序，而对于具体的顺序并未加以限制 </p>
<p>Ø 而分布式场景下，缺乏一个同步时钟，因此不同节点上操作顺序发生时 间错乱，该现象称为“<strong>time travel</strong>”</p>
<p>Ø time travel主要由主从数据库异步复制引起。</p>
<p>总结：没有任何一致性保证的隔离保证并不是特别有用，分布式系统中需要 两者结合共同保证数据库状态的正确性</p>
<p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202204232154703.png" alt="image-20220423215407034"></p>
<hr>
<p>更多实践内容参考 <a href="https://tech.meituan.com/2014/08/20/innodb-lock.html">https://tech.meituan.com/2014/08/20/innodb-lock.html</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>数据管理与分析</category>
      </categories>
      <tags>
        <tag>数据管理与分析</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes学习</title>
    <url>/2022/05/03/%E4%BB%80%E4%B9%88%E6%98%AFK8s/</url>
    <content><![CDATA[<h1 id="什么是K8s"><a href="#什么是K8s" class="headerlink" title="什么是K8s"></a>什么是K8s</h1><h2 id="k8s解决的问题"><a href="#k8s解决的问题" class="headerlink" title="k8s解决的问题"></a>k8s解决的问题</h2><p><img src="https://cdn.jsdelivr.net/gh/yoon286/Pic@main/img/202205031835022.png" alt="image-20220503183514807"></p>
<p>让我们回顾一下为什么 Kubernetes 如此有用。</p>
<span id="more"></span>

<p><strong>传统部署时代：</strong></p>
<p>早期，各个组织机构在物理服务器上运行应用程序。无法为物理服务器中的应用程序定义资源边界，这会导致资源分配问题。</p>
<p> 例如，如果在物理服务器上运行多个应用程序，则可能会出现一个应用程序占用大部分资源的情况， 结果可能导致其他应用程序的性能下降。</p>
<p><strong>虚拟化部署时代：</strong></p>
<p>作为解决方案，引入了虚拟化。虚拟化技术允许你在单个物理服务器的 CPU 上运行多个虚拟机（VM）。</p>
<p><strong>容器部署时代：</strong></p>
<p>容器类似于 VM，但是它们具有被放宽的隔离属性，可以在应用程序之间共享操作系统（OS）。 因此，容器被认为是轻量级的。容器与 VM 类似，具有自己的文件系统、CPU、内存、进程空间等。</p>
<h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><ul>
<li>敏捷应用程序的创建和部署：与使用 VM 镜像相比，提高了容器镜像创建的简便性和效率。</li>
<li>持续开发、集成和部署：通过快速简单的回滚（由于镜像不可变性），支持可靠且频繁的 容器镜像构建和部署。</li>
<li>松散耦合、分布式、弹性、解放的微服务：应用程序被分解成较小的独立部分， 并且可以动态部署和管理 - 而不是在一台大型单机上整体运行。z</li>
</ul>
<h2 id="K8s的特点"><a href="#K8s的特点" class="headerlink" title="K8s的特点"></a>K8s的特点</h2><ul>
<li><p><strong>服务发现和负载均衡</strong></p>
<p>Kubernetes 可以使用 DNS 名称或自己的 IP 地址公开容器，如果进入容器的流量很大， Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。</p>
</li>
<li><p><strong>存储编排</strong></p>
<p>Kubernetes 允许你自动挂载你选择的存储系统，例如本地存储、公共云提供商等。</p>
</li>
<li><p><strong>自动部署和回滚</strong></p>
<p>你可以使用 Kubernetes 描述已部署容器的所需状态，它可以以受控的速率将实际状态 更改为期望状态。例如，你可以自动化 Kubernetes 来为你的部署创建新容器， 删除现有容器并将它们的所有资源用于新容器。</p>
</li>
<li><p><strong>自动完成装箱计算</strong></p>
<p>Kubernetes 允许你指定每个容器所需 CPU 和内存（RAM）。 当容器指定了资源请求时，Kubernetes 可以做出更好的决策来管理容器的资源。</p>
</li>
<li><p><strong>自我修复</strong></p>
<p>Kubernetes 重新启动失败的容器、替换容器、杀死不响应用户定义的 运行状况检查的容器，并且在准备好服务之前不将其通告给客户端。</p>
</li>
<li><p><strong>密钥与配置管理</strong></p>
<p>Kubernetes 允许你存储和管理敏感信息，例如密码、OAuth 令牌和 ssh 密钥。 你可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置中暴露密钥。</p>
</li>
</ul>
<h3 id="Main-Components"><a href="#Main-Components" class="headerlink" title="Main Components"></a>Main Components</h3><p>左侧是一个官方提供的名为 <code>kubectl</code> 的 CLI （Command Line Interface）工具，用于使用 K8S 开放的 API 来管理集群和操作对象等。</p>
<p>Master 是一种角色（Role），表示在这个 Node 上包含着管理集群的一些必要组件。</p>
<p>Node 是工作节点 (worker Node) </p>
<p>K8s 系统是一套专注容器应用管理的集群系统，它的组件一般按功能分别部署在主控节点（master node）和计算节点(agent node)。对于主控节点，主要包含有 etcd 集群，controller manager 组件，scheduler 组件，api-server 组件。对于计算节点，主要包含 Pod、Service、ConfigMap、Volume、kubelet-proxy 组件。</p>
<p>容器的引入让原来主机仅可以部署 3-4 个进程的系统，现在可以充分利用容器进程隔离的技术在主机上部署 20-40 个进程系统，并且各自还不受影响。这就是容器应用的最大好处。</p>
<p>Kubernetes 是用于自动部署，扩展和管理容器化应用程序的开源系统，一般被 DevOps 团队用来解决在 CI/CD（也就是持续集成、持续发布）场景下遇到的工具链没法统一，构建过程没法标准化等痛点。</p>
<h2 id="文稿："><a href="#文稿：" class="headerlink" title="文稿："></a>文稿：</h2><p>2022年5月4日 下午 2:23|3小时36分钟54秒</p>
<p>说话人 1 02:22<br>So, in this part I’m going to explain what Kubernetes is we’re going to start off with the definition to see what official definition is and what it does, then we’re going to look at the problem solution case study of Kobe’s.</p>
<p>说话人 1 02:43<br> Kubernetes  is an open source container orchestration framework Which was originally developed by Google so on the foundation it manages containers be docker containers or from some other technology?Which basically means that commodities helps you manage applications that are made up of hundreds or maybe thousands of containers?And it helps you manage them in different environments.Like physical machines virtual machines or cloud environments or even hybrid deployment environment.So what problems does Kubernetes solve an what are the tasks of the container orchestration tool actually?So to go through this kernel logically the rise of microservices cause increased usage of container technologies because the containers actually offered the perfect host for.Small independent applications like Microservices and the rise of containers in the microservice technology actually resulted in applications that they’re now comprised of hundreds or sometimes maybe.Even thousands of containers now managing those loads of containers across multiple environments using scripts and self made tools can be really complex and sometimes even impossible.</p>
<p>说话人 1 04:08<br>So that’s specific scenario actually caused the need for having container orchestration technologies, So what those orchestration tools like Kubernetes do is actually guarantee following features.One is high availability in simple words high availability means that the application has no down time so it’s always accessible by the users a second one is scalability.Which means that application has a high performance it loads fast and the users have a very?High response rates from the application and the third one is disaster recovery, which basically means that if an infrastructure has some problems like data is lossed or the servers explode or something bad happens with the service center.The infrastructure has to have some kind of mechanism to pick up the data and to restore it to the latest state so that application doesn’t actually lose any data and the containerized application can run from the latest state.After the recovery and all of these are functionalities that container orchestration technologies like Kubernetes offer.</p>
<p>说话人 1 05:23<br>So, in this video I want to give you an overview of the most basic fundamental components of Kubernetes.But just enough to actually get you started using Kubernetes in practice, either as a dev OPS engineer.Or, a software developer now communities has tons of components, but most of the time you’re going to be working with just a handful of them.So I’m going to build a case of a simple JavaScript application with a simple database.And I’m going to show you step by step?How each component of Kubernetes actually helps you to deploy your application.And what is the role of each of those components.</p>
<p>说话人 1 06:07<br>So let’s start with the basic setup of a worker node or in Kubernetes terms on node.Which is a simple server a physical or virtual machine and the basic components or the smallest unit of Kubernetes is a pod So what part is is basically an abstraction over a container?So if you’re familiar with Docker containers or container images.So basically what part does is it creates this running environment or a layer on top of the container and the reason is because Kubernetes wants to.Abstract way the container runtime or container technologies so that you can replace them.If you want, too, and also because you don’t have to directly work with Docker or whatever.Container technology use in a Kubernetes so you only interact with carbonated layer.So we have an application part which is our own application and that will maybe use a database pod with its?Own container and this is also an important concept here.Part is usually meant to run.One application container inside of it, you can run multiple containers inside one.But usually it’s only the case.If you have one main application container in the helper container or some side service that has to run inside of that pod and uses it.This is nothing special.We just have one server and 2 containers running on it.With the abstraction layer on top of it.</p>
<p>说话人 1 07:38<br>So now let’s see how they communicate with each other in carbonated world.Securities offers out of the box of virtual network, which means that each pod gets its own IP address.Not the container the pod gets the IP address in each pod can communicate with each other using that IP address, which is an internal IP address.Obviously it’s not the public one so my application.Container can communicate with database using the IP address.</p>
<p>说话人 1 08:07<br>However, pod components in communities also an important concept are ephemeral, which means that they can die very easily.And when that happens for example, if I lose a database container because the container crashed because the application crashed inside or because the nodes.The server that I’m running them on.Raynard resources the pod will die in a new one will get created in its place.And when that happens, it will get assigned a new IP address, which obviously is inconvenient if you are.Communicating with the database using the IP address because now you have to adjust it every time pod restarts.And because of that another component of Kubernetes called service is used.So service is basically a static IP address or permanent IP address that can be attached.So to say to each pot.So my app will have its own service and database part will have its own service.And the good thing here is that the life cycles of service and the pod are not connected so even if the pod dies.The service and its IP address will stay so you don’t have to.</p>
<p>说话人 1 09:25<br>Change that endpoint anymore, so now obviously you would want your application to be accessible through a browser right and for this you would have to create an external service so external services.A service that opens the communication from external sources, but obviously you wouldn’t want your database to be open to the public requests and for that you would create something called an internal service.So this is a type of service that you specify when creating one.However, if you notice.The URL of the external service is not very practical so basically what you have.Is an HTTP protocol with a node IP address so off the node not the service and the port number of the service, which is good for test purposes.If you want to test something very fast.But not for the end product, so usually you would want your URL to look like this, if you want to talk to your application with a secure protocol and a domain name and for that there is another component of Kubernetes called?Increase so instead of service, the request goes first to Ingress and it does the forwarding then to the service so now we saw some of the very basic components of Kubernetes as you see this is a very simple setup.We just have one server.In a couple of containers running and some services nothing really special.Kubernetes advantages or the actual cool features really come forward.But we’re going to get there step by step, so let’s continue.So as we said parts communicate with each other using a service so my application will have a database endpoint.Let’s say called Mongo.Db service that it uses to communicate with the database.But where do you configure usually this database URL or endpoints usually you would do it in application properties file or as some kind of external environmental variable, but usually it’s inside of the built.Image of the application so for example, if the endpoints of the service or service name in this case changed to Mongo.Db you would have to adjust that URL in the application, so usually you would have to.Rebuild the application with the new version and you have to push it to the repository and now you’ll have to pull that gnu image in your pod and restart the whole thing so a little bit tedious for.A small change like database URL so for that purpose.</p>
<p>说话人 1 12:11<br>Kubernetes has a component called config map.So what it does is it’s basically your external configuration to your application so config map.Would usually contain configuration data like URLs of database or some other services.That use and in Kubernetes.You just connect it to the pod, so that part actually gets the data that config map.Contains and now if you change the name of the service.The endpoint of the service, you just adjust the config map and that’s it.You have to build a new image and have to go through this whole cycle now part.</p>
<p>说话人 1 12:48<br>Of the external configuration can also be database username and password right, which may also change in the application deployment process, but putting a password or other credentials in a config map.In a plain text format would be insecure, even though it’s an external configuration so for this purpose.</p>
<p>说话人 1 13:10<br>Kubernetes has another component called secret, so secret is just like config map.But the difference is that it’s used to store secret data credentials.For example, an it’s stored, not in a plain text format.Of course, but in base 64 encoded format so secret would contain things like.Credentials and of course I mean, database user.You could also put in config map.But what’s important is the passwords certificates.Things that you don’t want other people to have access to would go in the secret.And just like config map you just connect it to your part so that part can actually see those data and read from the secret.You can actually use the data from config map or secret inside of your application pod.</p>
<p>说话人 1 13:58<br>Using for example, environmental variables or even as a properties file so now to review.We’ve actually looked at almost all mostly used communities basic components.We’ve looked at the pod.We’ve seen how services are used?What is inggris component useful for and we’ve also seen external configuration using config map and secrets.</p>
<p>说话人 1 14:27<br>So now let’s see another very important concept generally which is data storage and how it works in Kubernetes.So we have this database pod that our application uses an it has some data.We generate some data with this setup that you see.</p>
<p>说话人 1 14:42<br>Now if the database container or the pod gets restarted.The data would be gone and that’s problematic, and inconvenient, obviously because.Do you want your database data or log data to be persisted reliably long term?And the way you can do it in communities is using another component of Kubernetes called volumes.And how it works is that it basically attaches a physical storage on a hard drive to your pot and that storage could be either on a local machine, meaning on the same server node where the pod is running.Or it could be on the remote storage, meaning outside of the cabinets cluster.It could be a cloud storage or could be your own premise storage, which is not part of the Kubernetes cluster so you just have an external reference on it.So now when the database pod, or container gets restarted all the data will be there persisted.It’s important to understand the distinction between the Kubernetes cluster and all of its components and the storage.Regardless of whether it’s a local or remote storage think of a storage as an external hard drive plugged in into the carbonated cluster because the point is communities clustered explicitly doesn’t manage.Any data persistence, which means that you as a quantities user or an administrator are responsible for backing up the data replicating and managing, it and making sure that it’s kept on a proper hardware.Etc because it’s not taking care of Kubernetes.</p>
<p>说话人 1 16:24<br>So now let’s see everything is running perfectly and a user can access our application through a browser.And with this set up what happens if my application pod dies right crushes or I have to restart the pod because I built knew container image.Basically, I would have a downtime where a user can reach my application, which is obviously a very bad thing if it happens.In production and this is exactly the advantage of distributed systems and containers.So instead of relying on just one application pod.In one database pod, etc.We are replicating everything on multiple servers, so we would have another node.Where a replica or clone of our application would run?Which will also be connected to the service so remember previously we said the services like and persistent static IP address.With the DNS name so that you don’t have to constantly adjust the endpoint when pod dies, but service is also a load balancer, which means that the service will actually catch the request and forward it to whichever party is least busy.So it has both of these functionalities, but in order to create the second replica of my application pod.You wouldn’t create a second pod, but instead you will define a blueprint for in my application pod.And specify how many replicas of that pod.You would like to run and that component or that blueprint is called deployment, which is another component of communities and in practice, you would not be working with pulse or you will not be creating.</p>
<p>说话人 1 18:11<br>Parts you would be creating deployements because there, you can specify how many replicas and you can also scale up or scale down.Number of replicas of parts that you need so with pod.We said that part is a layer of abstraction on top of containers and employment is another abstraction on top of pots, which makes it more convenient to interact with the parts.Replicate them and do some other configuration so in practice, you would mostly work with deployments and not with pots.So now if one of the replicas of your application pod would die the service will.Forward the requests to another one.So, your application would still be iaccessible for the user.</p>
<p>说话人 1 18:55<br>So now you’re probably wondering what about the database pod because if the database pod died your application also wouldn’t be.Accessible so we need a database replicas.Well, however, we can’t replicate database using a deployment and the reason for that is because database has state.Which is its data meaning that if we have clones are replicas of the database they would all need to access the same shared data storage and there, you would need some kind of mechanism.Some energies, which parts are currently writing to that storage or which parts are reading from the storage in order to avoid data inconsistencies and that mechanism.In addition to replicating feature is offered by another Kubernetes component called stateful set so this component is meant specifically for applications like databases.So my SQL, Mongo DB Elasticsearch or any other stateful applications or databases should be created using stateful sets and not deployments.It’s a very important distinction.And Stateful said just like Deployement would take care of replicating the pots and scaling them up or scaling them down, but making sure that database reads and writes are synchronized so that no database inconsistencies.Are offered?</p>
<p>说话人 1 20:28<br>However, I must mention here that deploying database applications using stateful sets in Kubernetes cluster can be somewhat tedious so it’s definitely more difficult than.Working with deployements where you don’t have all these challenges that’s why it’s also a common practice to host database applications outside of the Cabinet is cluster and just have the deployments or stateless applications.That replicate and scale with no problem inside of the Cabinet is cluster and communicate with external database.</p>
<p>说话人 1 21:04<br>So now that we have 2 replicas of my application pod and 2 replicas of the database and there, both.Balanced our setup is more robust, which means that now, even if node one.The whole node server was actually rebooted or crashed and nothing could run on it, we would still have a second note.With application and database pods running on it, and the application would still be accessible by the user.Until this 2 replicas get recreated so you can avoid downtime so to summarize.</p>
<p>说话人 1 21:39<br>We have looked at the most used combinators components.We started with the pods and services in order to communicate between the parts and the Ingress Component.Which is used to route traffic into the cluster.We’ve also looked at external configuration using config Maps and secrets and data persistence using?Volumes and finally we’ve looked at pod blueprints with replicating mechanisms like deployments and stateful sets where stateful set is used specifically for stateful applications like?Databases and yes, there are a lot more components that Kubernetes offers but these are really the core.The basic ones just using this core components you can actually build pretty powerful.</p>
<p>说话人 1 22:26<br>Kubernetes clusters.In this video we’re gonna talk about basic architecture of Kubernetes.So we’re going to look at 2 types of notes that Kubernetes operates on one is master in another one is slave.And we’re going to see what is the difference between those in which role each one of them has inside of the cluster and we’re going to go through the basic concepts of how Kubernetes does what it does and how the cluster.Is self managed and self healing an automated and how you as a operator of the companies cluster should end up having much less manual effort.And we’re going to start with this basic setup of one node with 2 application parts running on it, so one of the main components of carbonates architecture are its worker servers or notes.Each node will have multiple application pods with containers running on that node and the way communities does it is using 3 processes that must be installed on every node?That are used to schedule an manage those pots, so notes are the cluster servers that actually do the work.That’s why sometimes also called worker.</p>
<p>说话人 1 23:49<br>Notes so the first process that needs to run on every node is the container runtime.In my example, I have docker, but it could be some other technology as well so because application pods have containers running inside a container runtime needs to be installed on every note, but the process that actually schedules.Those those pods in the containers, then underneath is kubelet, which is a process of Kubernetes itself, unlike container runtime that has interface with both.Container runtime end the machine the note itself because at the end of the day.Kubelet is responsible for taking that configuration and actually running a pod or starting a pod with a container inside.And then assigning resources from that node to the container like CPU ram and storage resources.So usually Kubernetes cluster is made up of multiple nodes which also must have?Container runtime and Kubelet Service is installed, and you can have hundreds of those worker notes, which will run.Other pots and containers in replicas of the existing parts like my app and database parts in this example.And the way that communication between them works is using services which is sort of a load balancer.That basically catches the request directed to the pod or the application like database for example.And then forwards it to the respective pot, and the third process that is responsible for forwarding requests from services to pods is actually Q Proxy that also must be installed.On every note in Q Proxy has actually intelligent forwarding logic inside, that makes sure that.</p>
<p>说话人 1 25:40<br>Communication also works in a performance way with low overhead.For example, if an application Myapp replica is making a request database instead of service just randomly.Forwarding the requests to any replica it will actually forward it to the replica that is running on the same node as the pod that initiated the request, thus this way, avoiding the network overhead.Of sending the request to another machine, so to summarize 2 Kubernetes processes kubelet and Q Proxy must be installed on every Kubernetes worker node.Along with an independent container runtime in order for Kubernetes cluster to function properly, but now the question is how do you interact with this cluster or do you decide on which nodes a new application pod?Or database part should be scheduled or if replica pod dies.What process actually monitor is it an then reschedules it or restarts.It again or when we add another server?How does it join the cluster?To become another nose and get parts and other components created on it, and the answer is all these managing processes are done by master notes.So must have servers or must notes have completely different processes running inside and these are 4 processes that run on every masternode that control the cluster state and the worker nodes as well.So the first service is API server, so when you as a user want to deploy a new application and accommodate this cluster.You interact with the API server using some client it could be.Why like Kubernetes dashboard could be command line tool like kubelet or a Kubernetes API O API server is like a cluster gateway, which gets the initial requests of.Any updates into the cluster or even the queries from the cluster and it also acts as a gatekeeper for authentication to make sure that only authenticated and authorized requests get.Through to the cluster that means whenever you want to schedule new pots, diploid new applications create new service or any other components.</p>
<p>说话人 1 28:03<br>You have to talk to the API server on the master node and the API server.Then validate your request and if everything is fine.Then it will forward your request to other processes in order to schedule the pod or create this component that you requested.And also, if you want to query.The status of your deployment or the cluster health etc.You make a request to the API server and it gives you the response, which is good for security because you just have one entry point into the cluster.Another must process is a scheduler so as I mentioned if you.Send an API server request to schedule a new pod.Api server after its validates your request will actually hand it over to the scheduler in order to start that application.Hold on one of the worker nodes and of course, instead of Justice randomly, assigning it to any node schedule has this whole intelligent way of deciding on which specific worker node.The next pod will be scheduled or next component, will be scheduled so first it will look at your request and see how much resources.The application that you want.Schedule will need how much CPU how much ram and then it’s going to look at and it’s going to go through the worker notes and see the available resources on each one of them and if it sees that.Onenote is.The least busy or has the most resources available.It will schedule the new part on that note an important point here is that scheduler just decides on which nodes and new pod will be scheduled that process that.Actually does the scheduling that actually starts that pod with a container is the kubelet so it gets the request from the scheduler and executes that request on that note the next component.</p>
<p>说话人 1 30:05<br>Is controller manager which is another crucial component because?What happens when pods die on any note there must be a way to detect that nodes died and then reschedule.Those parts as soon as possible So what controller manager does is detect state changes like crashing of pods for example, so when pots die controller, manager detects that.And tries to recover.The cluster state as soon as possible on for that it makes a request for the scheduler to reschedule those dead parts in the same cycle happens here where the scheduler decides based on the resource calculation.Which worker notes should restart those pots again and makes requests to the corresponding cubelets on those worker nodes to actually restart the pots and finally the last master.</p>
<p>说话人 1 31:02<br>Process is at city, which is a key value store of a cluster state.You can think of it as a cluster brain.Actually, which means that every change in the cluster for example, when a?New pod get scheduled when a pod dies all of these changes get saved or updated into this key value store of Etsitty and the reason why it’s a D story is a cluster brain is because.</p>
<p>说话人 1 31:29<br>All of these mechanism with scheduler controller, manager etc works because of its data.So for example, how does scheduler know what resources are available or on each worker node or how does controller manager know that a cluster state changed in some way for example.Pods died?Or that Kubelet restarted new pots upon the request of a scheduler or when you make a query request to API server about the cluster health or for example, your application deployment state.Where does API server get all this state information from so all of this information is stored in SD cluster?What is not stored in the HDD key value store is the actual application data for example, if you have a?Database application running inside of the cluster that data will be stored somewhere else not in that city.This is just a cluster state information, which is used for master processes to communicate with them work processes.And vice versa, so now you probably already see that master processes are absolutely crucial for the cluster operation, especially the it’s a DS store, which contains some data must be reliable E stored.Or replicated so in practice communities cluster is usually made up of multiple Masters, where each masternode runs its master processes where of course, the API.Server is load balanced and the Exedy store forms at distributed storage across all the Masternodes.</p>
<p>说话人 1 33:09<br>So now that we saw what processes run on worker nodes an master notes.Let’s actually have a look at and really stick example of a cluster setup so in a very small cluster you’d probably have.</p>
<p>说话人 1 33:22<br>2 master notes and 3 worker.Notes also to note here.The hardware resources of Master, an notes servers actually differ.The master processes are more important, but they actually have less load of work so they need less.Resources, like CPU ram and storage whereas the worker nodes do the actual job of running those pods with containers inside.Therefore, they need more resources and as your application complexity.An it’s dim end of resources increases.</p>
<p>说话人 1 33:53<br>You may actually add more master and notes servers to your cluster and thus forming a more powerful and robust cluster to meet your application resource requirements.So, in an existing Kubernetes cluster, you can actually add new master or node servers pretty easily.So if you want to add a master server.You just get a new bear server, you install all the master processes on it.In edit to the covenant is cluster same way if you need 2 worker nodes you get their servers.You install all the worker node processes like container runtime kubelet and Q Proxy and 8 and add it to the covenant is cluster.That’s it and this way, you can infinitely increase the power and resources of your communities cluster is a replication complexity and its resource demand increases.</p>
<p>说话人 1 34:50<br>So, in this video I’m going to show you what mini cube and Cube.Ctl are and how to set them up.So first of all let’s see what is mini cube usually in Kubernetes world when you’re setting up a production cluster?It will look something like this so you would have multiple Masters.At least 2 in a production setting and you would have multiple worker nodes and Masternodes and worker nodes have their own separate responsibility.So as you see on the diagram, you would have actual separate virtual or physical machines that each represent an note.</p>
<p>说话人 1 35:27<br>Now, if you want to test something on your local environment or if you want to try something out very quickly for example.Deploying new application or new components.You want to test it on your local machine.Obviously setting up a cluster like this will be pretty difficult.Or maybe even impossible if you don’t have enough resources.Like memory and CPU, etc and exactly for that use case.</p>
<p>说话人 1 35:53<br>There is this open source tool that is called a mini cube So what a mini cube?Is is basically one node cluster where the master processes.And the worker processes both run on OneNote and this node will have a docker container runtime pre installed.So you will be able to run the containers or the pods with containers.On this note in the way it’s going to run on your laptop is through a virtual box or some other hypervisor.So basically mini cube will create a virtual box on your laptop and the nodes.That you see here is this node will run in that virtual box.So to summarize Mini Cube is a OneNote communities cluster that runs in a virtual box.On your laptop, which you can use for testing Kubernetes on your local setup so now that you’ve set up a cluster or a mini cluster on your laptop or PC on your local machine.You need some way to interact with a cluster.So you want to create components configure it etc.And that’s where Cube Cityel comes in the picture.So now that you have this virtual node on your local machine that represents Mini Cube.You need some way to interact with the cluster so you need a way to create pods.Ain other combinators components on the note.And the way to do it is using Cube City, L, which is a command line tool for Kubernetes cluster so let’s see how it actually works.Remember we said that mini cube runs.</p>
<p>说话人 1 37:26<br>Both Master and work processes so one of the master process is called?Api server is actually the main entry point into the carbonated cluster so if you want to do anything in the Kubernetes If you want to configure anything create any component.You first had to talk to the API server and the way to talk to the API server.Is through different clients so you can have a UI like a dashboard you can talk to it using Kubernetes API or a command line tool, which is Cube City.L&amp;qctl is actually the most powerful of all the 3 clients.Because with capacity L you can basically do anything in the communities that you want and throughout this video tutorials, where you’re going to be using cube CTL mostly so once the cube.Ctl submits commands through the API server to create components delete components.Etc.The work processes on mini cube nodes will actually make it happen.So they will be actually executing the commands to create the pods to destroy the parts to create services etc.So this is the mini cube setup and this is how cube city.L is used to interact with the cluster an important thing to note here is that keeps a TL isn’t just for Mini Cube cluster if you have a cloud cluster aura.Hybrid cluster whatever keeps it here is the tool to use to interact with any type of Kubernetes cluster setup so that’s important to note here.</p>
<p>说话人 1 38:51<br>So now that we know what mini cube and keeps a TLR.Let’s actually install them to see them in.Practice.I’m using Max so the installation process will probably be easier, but I’m going to put the links to the installation guides in the description.So you can actually follow them to install it on your operating system just one thing to note here is that?Mini cube needs a virtualization because as we mentioned it’s going to run in a virtual box set up or some hypervisor so you will need to install some type of hypervisor could be VirtualBox.I’m going to install a hyper kid but it’s going to be in those step by step instructions as well.So I’m going to show you how to install it on a Mac.So I have a Mac OS, Mojave, so I’m going to show you how to install mini cube on these Mac OS version and I’m going to be using brew to install it so update.And the first thing is that I’m going to install.</p>
<p>说话人 1 39:53<br>A hypervisor hyper kit.So I’m going to go with the hyper kit.Go ahead and install it.I already had him install it so with you if you’re doing, it for the first time it might take longer because it has to download all these dependencies and stuff, and now I’m going to install Mini Cube.</p>
<p>说话人 1 40:22<br>And here’s the thing many cube has cube city L as a dependency.So when I execute this, it’s going to install cubes ETL as well.So I don’t need to install it separately.</p>
<p>说话人 1 40:38<br>So let’s see here.Installing dependencies for Mini Cube, which is Kubernetes CLI.This is cube.Ctl again because I already had it installed before it still has a local copy of Dependencies That’s why it’s.Pretty fast, it might take longer if you’re doing, it for the first time so now that everything is installed.It’s actually check the commands so cube.Ctl command should be working, so I get this list of the commands with qol so it’s.There, an mini cube should be working as well, and as you see many cube comes with this command line tool, which is pretty simple so with one command.It’s going to bring up the whole combinators cluster in this OneNote.Set up and then you can do stuff with it and you can just stop it or delete it.It’s pretty easy.</p>
<p>说话人 1 41:30<br>So now that we have both installed and the commands are there?Let’s actually create a mini cube communities cluster?And as you see, there is this start command.Let’s actually clear this so this is how we’re going to start a carbonated cluster cute mini cube start and here is where the hypervisor installed comes in.Because this mini cube needs to run in virtual environment.We’re going to tell many cube which hypervisor it should use to start a cluster, so for that.We’re going to specify an option, which is.Vm driver.</p>
<p>说话人 1 42:07<br>And here I’m going to set the hyper key that I installed so I’m telling Me Cube.Please use hyper kit hypervisor to start this virtual mini Kube Cluster.So when I execute this, it’s going to download some stuff.So again it may take a little bit longer if you’re doing for the first time.</p>
<p>说话人 1 42:28<br>And is a mentioned Mini Cube has docker runtime or Docker Daemon preinstalled so even if you don’t have Docker on your machine.It’s still going to work so you will be able to create containers inside.Because it already contains soccer, which is a pretty good thing.If you don’t have docker already installed so done.</p>
<p>说话人 1 42:49<br>Qctl is now configured to use Mini Cube, which means the Mini Kube cluster is set up.Ioncube CTL Command, which is meant to interact with the carbonated clusters is also connected with that Mini Kube cluster, which means if I.Do cube city will get notes, which just gets me a status of the notes of the companies cluster.It’s going to tell me that the Mini Cube note is ready, and as you see it.It’s the only node an it has a must roll because it obviously has to run the master processes.I can also get the status with Mini Cube.Executing miniclip status so I see host is running kubelet, which is a service that actually runs the pods using container runtime is running so basically everything is running.</p>
<p>说话人 1 43:44<br>And by the way if you want to see Kubernetes architecture in more detail and to understand how master and worker nodes actually work and what all these processes are I have a separate video that covers communities architecture.So you can check it out on this link.And we can also check which version of Kubernetes.We have installed and usually it’s going to be the latest version, so with Q City old version, you actually know what the client version of communities is an what the server version of Kubernetes.And here we see we are using one dot 17 and that’s the Kubernetes version that is running in the mini Kube cluster.So if you see both client version and server version in the output it means that Mini Cube.Is correctly installed so from this point on?We are going to be interacting with the mini kube cluster using cube CTL Command line tool so Mini Cube is basically just for the start up an for deleting the cluster.Everything else configuring we’re going to be doing through Cube Citycell and all these commands that are executed here.I’m going to put them in at least in the comment section so you can actually copy them.In this video I’m going to show you some basic cube city of commands and how to create in debug pots in Mini Cube.So now we have a mini Kube Cluster, an cube CTL installed and once the cluster is set up you’re going to be using cube CTL to basically do anything in the cluster to create components.To get the status etc.So first thing we’re going to just get the status of the notes.So we see that there is OneNote which is a master and everything is going to run on that node because it’s a Mini Cube.</p>
<p>说话人 1 45:34<br>So we keep still get I can check the pots and I don’t have any that’s why no resources.I can check the services keeps detailed kit services.And I just have one default service and so on, so this keeps the tailgate.I can least any comments components.So now since we don’t have any parts were going to create one and to create Kubernetes components there is.The Cube Cityel creates comment so if I do.Help on that cube city create command, I can see available commands for it.So I can create all these components using Q City will create but there is no part on the list.Because in Kubernetes world, the way it works is that part is the smallest unit of the Kubernetes cluster, but usually in practice, you’re not creating parts or you’re not working with the parts directly.There is an abstraction layer over the parts that is called Deployement.So this is what we’re going to be creating and that’s going to create the pods underneath and this is a usage of qol create.</p>
<p>说话人 1 46:47<br>Deployment so I need to give a name of the deployment and then provide some options and the option that is required is the image because the part needs to be created based on certain some image or some container image so let’s actually go ahead and create.</p>
<p>说话人 1 47:03<br>Engine X deployment.So keep city oh create deployment.We let’s call it engine X deployment.Image equals engine X is just going to go ahead and download the latest engine X image from.Docker hub that’s how it’s going to work so when I execute this.You see deployment engine X people created so now if I do Coop City, oh get deployment.You see that I have one deployment created I have the status here, which says it’s not ready yet.So if I do cube CTL get pot.You see that now I have a pot, which has a prefix of the deployment and some random hash here and it says container creating so it’s not ready yet.So if I do it again it’s running.</p>
<p>说话人 1 48:05<br>And the way it works here is that when I create a deployment.Deployment has all the information or the blueprints for creating the pod.The The This is the minimalistic or the most basic configuration for deployment.We just saying the name and the image.That’s it the rest is just defaults and between deployment and a pool.</p>
<p>说话人 1 48:29<br>There is another layer, which is automatically managed by Kubernetes deployment called replica set.So if I do cube cityel get replica set.Written together.You see I have an engine X Dippel replica set hash and it just gives me a state an if you notice here, the pod name has.A prefix of deployment in the replica sets ID and then its own ID, so this is how the pod name is made up and the replica said basically is managing.The replicas of a pod you in practice will never have to create replica set or delete.A replica set or update in any way you’re going to be working with deployments directly.Which is more convenient because in deployment you can configure the pod blueprint completely you can say how many replicas of the pod.You want and you can do the rest of the configuration there here with this command.We just created.One pot or one replica, but if you wanted to have 2 replicas of the engineers spot.We can just provide as additional options.So this is how the layers work first you have.</p>
<p>说话人 1 49:52<br>The deployment the deployment manage is a replica set replica set manage is all the replicas of that pot and the pod is again an abstraction of a container.And everything below the deployment should be managed automatically by Kubernetes usually have to worry about any of it.For example, the image that it uses I will have to edit that in the deployement directly and not in the pot.So let’s go ahead and do that right away, so I’m going to keep CTL edit deployment.And I’m going to provide the name Phoenix.</p>
<p>说话人 1 50:33<br>An we get an auto generated configuration file of the deployment because in the command line.We just gave 2 options.Everything else is default in auto generated by Kubernetes.And you don’t have to understand this now, but I’m going to make a separate video where I breakdown.</p>
<p>说话人 1 50:49<br>The configuration file and the syntax of the configuration file for now, let’s just go ahead and scroll to.The image which is somewhere down below.And let’s say I want to fixate the version 2116.And save that change.And if you see deployment was edited and now when I do coop city El get pot.I see that the old pot.So this one here is terminating an in other one started 25 seconds ago, so if I do it again.The old part is gone and the new one got created with the new image.And if I do if I get replica set.I see that the old one has no parts in it.And a new one has been created as well.So we just edited the deployment configuration and everything else below that.Got automatically updated and that’s the Magic of Kubernetes and that’s how it works.</p>
<p>说话人 1 52:07<br>Another very practical command is Cube City are logs, which basically shows you what the application running inside the pod actually locked so if I do cube sit here logs.And I will need the pod name for this.I will get nothing because engine next didn’t log anything so let’s actually create another deployment.From Mongo DB so let’s call it mongo deployment.And image and image will be one go so let’s see.City oh.</p>
<p>说话人 1 52:48<br>Part so now I have the mongo DB deployment, creating so let’s go ahead and log.That.This state is here means that part was created, but the container inside the pod isn’t running yet and when I try to log.Obviously it tells me there is no container running so it can.Show me and it looks so let’s get the status again.</p>
<p>说话人 1 53:13<br>At this point if I’m seeing that containers and starting I can actually get some additional information by.Keeps detail describe pod and pod name.Which here shows me?What state changes happened inside the pot so it pulled the image created container and started container so cube city will get pod.It should be running already.So now let’s log it keeps ETL logs.And here we see the log output, so we took a little bit, but this is what the market would be application.Container actually locked inside the pot and obviously if container has some problems.It’s going to help with debugging to see what the application is actually printing.So let’s clear that.And get the parts again.</p>
<p>说话人 1 54:09<br>So, in other very useful command when debugging when something is not working or you just want to check what’s going on inside the pod.Is keep cityel exec?So basically what it does is that it gets the terminal of that.Mongo DB application container.So if I do keep city aleksic interactive terminal that’s what it stands for.I will need the pod name.Dash dash?So so with this command.I get the terminal of the mongo DB application container and as you see here.I am inside the container of mongo DB as a root user so I’m in a completely different setting now and as I said, This is useful in debugging.Or when you want.Test something or try something you can enter the container or get the terminal and execute some comments.Inside, there, so we can exit that again.</p>
<p>说话人 1 55:12<br>And, of course, with Coop City, El I can delete the pots.So if I do get deployment.I misspelled it so keeps it here employment.I see that I have 2 of them and if I do.</p>
<p>说话人 1 55:29<br>Qc pod and replica said.I have also 2 of them so let’s say if I wanted to get rid of.All the pods replica sets underneath I will have to delete.</p>
<p>说话人 1 55:40<br>The deployment.So delete deployment and I’ll have to provide the name of the deployment.I’m going to delete it.Delete Mongo DB.Delete it and now if I’m going to say keep city.I’ll get pod.The pod should be terminating an if I do get replica set.The Mongo DB replica set is gone as well in the same if I do delete deployment.</p>
<p>说话人 1 56:12<br>Engine X Temple.Undo the replica said.See everything gone so all the crud operations create delete update etc.Happens on the deployment level and everything underneath just follows automatically and the similar way way we can create other community resources like services, etc.</p>
<p>说话人 1 56:33<br>However, as you notice when we’re creating current components like deployment using cube cityel create deployment.I misspelled it all the time.You’ll have to provide all these options on the command line.So you’ll have to say the name and you have to specify the image and then you have this option, one option, 2, etc.And there could be a lot of things that you want to configure in a deployment or in a pot and obviously it will be impractical to write that all out on a command line zero because of that in practice.You would usually work with communities configuration files, meaning what component you’re creating what the name of the component is what image is it based off in any other options there.All gathered in a configuration file and you just tell Coop City.</p>
<p>说话人 1 57:30<br>El to execute that configuration file and the way you do it is using cubes ETL apply command.And apply basically takes the file the configuration file as a parameter and does whatever you have written there, so apply.It takes an option called minus F let’s dance for file.And here you would say the name of the file so this will be the config file dot yellow.This is the format that usually going to use for configuration files and this is the command that.Executes whatever is in that configuration file so let’s actually called it configuration file.</p>
<p>说话人 1 58:14<br>Engine next deployment.And let’s go ahead and create a very simplistic super basic engineering deployment file so here I’m going to.Create that file.So this is the basic configuration for the deployment.So here I’m just specifying what I want to create I want to create a deployment.The name of that deployment.</p>
<p>说话人 1 58:46<br>You can ignore this labels right now?How many replicas of the pods.I want to create an these plug right here that template and specification is a blueprint.Or the pods so specification for the deployment and specification for a pod and here we’re just saying that we want one container inside of the pod with engine X image.And we’re going to find that on port 80.So this is going to be our configuration file and once we have that we can apply that configuration.So.So deployment created somehow if I get part.I see that engine X deployment pod was created an it’s running and it’s also seated.Deployement was created 52 seconds ago and now if I wanted to change something in that deployment.I can actually change my local configuration.For example, I want it 2 replicas instead of one.I can apply that.Again.Deployment engineers deployment configured and as you see the difference here is that?Communities can detect if the engine X deployment doesn’t exist.Yet it’s going to create one.But if it already exists and I play the configuration file again.It’s going to know that it should update it instead of creating a new one so if I do get employment.</p>
<p>说话人 1 01:00:32<br>I see this is the old one or the old deployment.And if I do.Cube CTL get pod.I see the old one is still there and a new one got created because I increased the replica count, which means that with cube city apply you can both create.And update a component and obviously you can do coops ETL with services.</p>
<p>说话人 1 01:00:54<br>Volumes any other combinators components just like we did it with the deployment so in the next video.I’m going to breakdown.The syntax of the configuration file which is pretty logical and simple actually to understand and I’m going to explain all the different.Attributes and what they mean so you can write your own configuration files for different components.So to summarize.</p>
<p>说话人 1 01:01:15<br>We’ve looked at a couple of Coops.Etl comments in this video.We saw how to create a component like deployement.How to edit it and delete it.We saw how to get status of parts deployments replica sets etc?We also logged on console.Whatever application is writing it to the console in the pod.And we saw how to get a terminal of a running container using cubes.Etl Exec and finally.</p>
<p>说话人 1 01:01:43<br>We saw harder use communities configuration file to create an update components.Using the cube city apply command and last but not least, we saw Cube City of describe command, which will winner containers and starting in a pot and you want to get some additional troubleshooting information about the pod.</p>
<p>说话人 1 01:02:07<br>In this video I’m going to show you the syntax and the contents of Kubernetes configuration file which is the main tool for creating and configuring components in communities cluster if you’ve seen lar.</p>
<p>说话人 1 01:02:20<br>Configuration files it might seem overwhelming, but in reality.It’s pretty simple and intuitive and also very logically structured so let’s go through it step by step.So here I have examples of a deployment and service configuration files side by side, so the first thing is that every configuration file in Kubernetes has 3 parts.The first part is where the metadata of that component that you’re creating results.One of the metadata is obviously name of the component itself, the second part in the?Configuration file is specification, so each component configuration file will have a specification where you basically pulled every kind of configuration that you want to apply for that.Um components the first 2 lines here is you see is just declaring what you want to create here.We are creating deployment in here.We’re creating a service and this is basically you have to look.For each component there is a different API version.</p>
<p>说话人 1 01:03:31<br>So now inside of the specification part.Obviously, the attributes will be specific to the kind of a component.That you are creating so deployment will have its own attributes that only apply for deployment and the service will have its own stuff.But I said there are 3 parts of a configuration file.And we just see metadata and the specification.So where’s the third part so the third part will be a status, but it’s going to be automatically generated and added by Kubernetes.So the way it works is that communities will always compare.What is the desired state and what is the actual stated or the status of their component and if the status and desired state do not match.</p>
<p>说话人 1 01:04:21<br>Then commanded his nose.There’s something to be fixed, there, so it’s going to try to fix it.And this is the basis of the self healing feature that Kubernetes provides for example, here you specify you want.</p>
<p>说话人 1 01:04:35<br>2 replicas of Engineers deployment so when you apply this when you actually create the deployment using this configuration file that’s what ally means committees will add here, the status.Of your deployement and it will update that states continuously so for example, if a status at some point will say just one replica is running then communities will compare that status with the specification.And will know there is a problem there.Another replica needs to be created ASAP now.</p>
<p>说话人 1 01:05:08<br>Another interesting question here is where does communities actually get the status data to automatically add here.Or update continuously that information comes from the IT CD.Remember the cluster brain.One of them must processes that actually stores.The cluster data so it’s Cindy Holt sat.Anytime the current status of any communities component and that’s where the status information comes from.</p>
<p>说话人 1 01:05:40<br>So as you see the format of the configuration files is yamil that’s why the extension here and generally it’s pretty straightforward to understand it’s very simple format, but Yamil is very strict about the.Indentations so for example, if you have something wrongly in.I did hear your file will be invalid So what I do, especially if I have a configuration file that has 200 lines.It’s pretty long.I usually use some yellow online validator.To see where I need to fix that, but other than that, it’s pretty simple and another thing is where do you actually store those configuration files are usual practice is to store them with your code?Because since the deployment in service is going to be applied to your application.It’s a good practice to store these configuration files in your application code so usually it will be part of the whole.Infrastructure as a code concept or you can also have its own git repository just for the configuration files.</p>
<p>说话人 1 01:06:50<br>So, in the previous video, I showed you that deployements manage the parts that are below them.So, whenever you edit something in a deployment.It kind of Cascade style down to all the ports that manage is.And whenever you want to create some parts.You would actually create a deployment and it will take care of the rest.</p>
<p>说话人 1 01:07:11<br>So how does this happen or where?Is this whole thing defining the configuration?So here in the specification part of a deployement you see template.And if I expanded you see the template also has its own metadata.An specification so it’s basically a configuration file inside of a configuration file.And the reason for it is that this configuration.Applies to a pod so part should have its own configuration inside of deployments configuration file and that’s how all the deployments will be defined and this is going to be the blueprint.For a pot like which image it should be based on which port it should open.What is going to be the name of the container etc?</p>
<p>说话人 1 01:08:05<br>So the way the connection is established is using labels and selectors, so as you see metadata part contains the labels.And the specification part contains selectors, it’s pretty simple in a metadata.You give components like deployment or pod.A key value pair and it could be any key value pair that.You think of this case, we have app engine X and that label just sticks to that component so we give pods.Created using this blueprint label engine X and we tell the deployement to connect or to match all the labels.With app engine X?To create that connection.So this way deployment will know which parts belong to it now deployment has its own label app engine.X and these 2 labels are used by the service selector zero in the specification of a service.We define a selector, which basically makes a connection.Between the service and the deployment or it spots because service must know which parts are.Kind of registered with it, so which pods belong to that service and that connection is made through this selector.Off the label and we’re going to see that.The demo so another thing that must be configured in the service and pod is the ports so if I expand this.I see that service has its ports.Configuration and the container inside of a part is obviously running or needs to run its import right so how this is configured is basically service has a port.Where the service itself is accessible at so if other services and the request to engineering service here in needs to send it on port 80 but this service needs to know.To which part it should forward the request, but also at which port is that part listening.And that is the target port so this one should match the container port.</p>
<p>说话人 1 01:10:33<br>And with that, we have our deployment and service basic configurations done and to note here.Most of these attributes that you see here in both parts are required so this will actually be the minimum.</p>
<p>说话人 1 01:10:48<br>Configuration for deployment and service so once we have those files.Let’s actually apply them or create components using that so let’s head over to the console and here I’m going to create both deployment and service.So keep city apply.Genetics deployment.Created and engine X service so now if I.Get the pods I see 2 replicas are running because that’s how we define it here and we have our service as well.</p>
<p>说话人 1 01:11:30<br>Which is engineering service this is a default service?It’s always there this is the one we created?And it’s listening on port 80 as we specified now.How can we validate that the service has the right parts that it forwards the?Requests to we can do it using cube city old describe service and the service name.</p>
<p>说话人 1 01:12:01<br>And here you see the endpoints.Where you have all these status information here like things that we define in the configuration like selector, etc.We have the target port that we define an we have the?Endpoints here and this must be the IP addresses.Imports of the pots.That the service must forward.The request to so how do we know that these are the IP addresses of the right parts because we’ve keeps the tailgate pod.You don’t get this information.So the way we do it or we find that out, is using?Get part and then you do dash.Oh, which is 4 Outputs and then we want.More information so all white.</p>
<p>说话人 1 01:12:55<br>And here we see more columns here, so we have the name and status ready, etc.But we also have the IP address.So here is the IP address endpoint specified here and this is.The other one so we know that the service has right endpoints.</p>
<p>说话人 1 01:13:13<br>So now let’s see the third part of the configuration file which is a status that Kubernetes.Magically generated and the way to do it is, we can get the employment.</p>
<p>说话人 1 01:13:27<br>Engine X deployment in a Yaml format.So when I execute this command.I will get the resulting or the updated configuration of my deployment, which actually resides in the LCD.Because it’s in the stores the status of the whole cluster, including every component.So if I do this.I’ll get the yaml output in my console, but I wanted in the file so I’m going to.</p>
<p>说话人 1 01:13:54<br>Saving into engine X?The employment.Result.And I’m going to save it there and I’m going to open it in my editor next to the original 10 as you see a lot of stuff has been added, but let’s just see the status part.So all this is automatically added an updated constantly by Kubernetes.So it says how many replicas are running what the state of those replicas and some other information.So this part can also be helpful when debugging so that’s the status but also, if you notice.</p>
<p>说话人 1 01:14:40<br>Other stuff has been added in the metadata and specification part as well so for example, creation timestamp.When was the component created is automatically added by communities?Because it is a metadata some unique ID, etc.You don’t have to care about it and in the specification part.It’s just it’s some defaults for that component, but again, you don’t have to.Care one stand most of these attributes but one thing to note here is that if you for example, want to copy deployement that you already have using maybe automated scripts.You will have to remove and get rid of most of these generated stuff.So you have to clean that deployment configuration file first and then you can create another deployment.From that blueprint configuration so let’s it with this video so from now on.We’re going to be working with the configuration files so for example, if I want to delete the deployment and service.I can do it using that file.Configuration file is well using delete.And.Like this.The deployment will be gone and I can do the same for service.Alright so using cube CTL apply and keeps it will delete you can basically work with the configuration files.</p>
<p>说话人 1 01:16:19<br>In this video we’re going to deploy 2 applications.Mongo DB in Mongo Express and I chose these 2 because it demonstrates really well.A typical simple setup of a web application and database.So you can apply this to any similar setup, you have so let’s see how we are going to do this.So first we will create a mongo DB pod and in order to talk to that part we’re going to need a service.An we’re going to create an internal service, which basically means that no external requests are allowed to the pod.Only components inside the same cluster can talk to it, and that’s what we want then we’re going to create a Mongo Express.Employment one we’re gonna need database URL of mongo DB so that Mongo Express can connect to it, and the second.One is credentials.So username and password of the database so that it can authenticate.</p>
<p>说话人 1 01:17:13<br>So the way we can pass this information to Mongo Express deployment is through its deployment configuration file through environmental variables because that’s how the application is configured so we’re going to create a config map.That contains database URL and we’re going to create a secret that contains the credentials and we’re going to reference both inside of that deployment file so once we have that set up we’re going to need Mongo Express to be accessible.Through browser in order to do that.We are going to create an external service that will allow external requests to talk to the pot.So the URL will be patient P IP address of the.</p>
<p>说话人 1 01:17:54<br>Note ends the service port so with this setup, the request flow will now look like this so the request comes from the browser and it goes to the external service of the Mongo Express, which will then forward it to the Mongo Express.Pod the pod will then connect to internal service of Mongo.Db that’s basically the database URL here and it will forward it then to monkey pod, where it will authenticate.The request using the credentials so now let’s go and create this whole setup using Kubernetes configuration files.Let’s dive right into it and create the whole setup so first of all I have a mini Kube cluster running if I do.Cube CTL gets all which basically gets me all the components that are inside the cluster.I only have a default currently service so my cluster is empty an I’m sorry from scratch.So the first thing that I said, We’re going to do is create a mongo DB deployment usually created in and.Editor so I’m going to go to Visual Studio Code and paste prepared deployment file there.For Mongo DB and this is how it’s going to look like so I have deployment kinds.And I have some metadata.I’m just going to call it mongo DB deployment.Labels and selectors in the previous video.I already explained the syntax of Kubernetes.Yaml configuration file so if you want to know what all these attributes mean then you can check out that video.And here in the template.I have a definition or blueprint for parts that this deployment going to create an I’m just going to go with one replica so the container is going to be called Mongo DB.And this is the image that I’m going to take so let’s actually go and check out the image configuration for Mongo DB.So Mongo.And I see.This image here, let’s open this.And basically what I’m looking for is how to use that container, meaning what ports it’s going to open an what’s external configuration is going to take so a default?</p>
<p>说话人 1 01:20:17<br>Port of mongo DB container is 27,017, so I’m going to use that.And we’re going to use variables environmental variables.The root username and root password.So basically I can on the container startup define the admin username and password.So let’s go ahead and.Figure all of that inside the configuration file so here below the image among the beat.So we’re just going to leave the name of the image and it’s going to pull the latest one and that’s what we want.</p>
<p>说话人 1 01:20:53<br>So here I’m going to specify what port I want to expose soportes attribute name and container.Port.And that’s the standard port so I’m going to leave it and below that I’m going to specify those 2 environmental variables, so one is called Let’s see what it’s called?Mongo init DB root username and here is going to be a value.So we’re going to actually leave it blank for now, and the other one is.Cold init root password and we’re going to leave that blank as well, just bad you and once we have the values here.</p>
<p>说话人 1 01:21:40<br>We’re going to have a complete deployment for Mongo DB.This is basically all we need now note that this is a configuration file that it’s going to be checked into a repository so usually you wouldn’t write admin username and password inside the configuration file.So what we’re going to do now is we’re going to create a secret from where we will reference.The values so meaning that the secret is going to leave in Kubernetes and nobody will have access to it in a git repository.So we’re going to save these incomplete deployment file first of all, so let’s call it mongo.</p>
<p>说话人 1 01:22:21<br>Deployment.Or let’s just call it Monroe Yamo and save it here, so that we get the syntax highlight and now before we apply this configuration.We’re going to create the secret where the root username and password will leave.So let’s create a new file and I’m going to paste in the configuration of a secret which is actually pretty simple.So we have a kind secret then we have a metadata, which again is just simply the name.</p>
<p>说话人 1 01:22:53<br>We’re going to create mongo DB secret the type or Peck is actually a default type, which is the most basic key value secret type.Other types for example, include TLS certificates, so you can create a?Secret specifically with the TLS certificate type Anna couple of more types, but mostly you’re going to use the default.One and these are the actual contents.So we have the data and here you have key value pairs.Which of course are the names you come up with so we’re going to specify username or we can actually call it mongo.</p>
<p>说话人 1 01:23:31<br>Route.User name and we’re going to call it Mongo Root password and here’s the thing the values in.In this key value pairs are not plaintext.So when we are creating a secret.The value must be base 64 encoded so the way you can do that the simplest way is go to your terminal.So here I’m going to say Echo minus N very important option don’t leave it out.Otherwise, it’s not going to work.And here I’m going to put a plaintext value, then I want so I’m just going to go with just username.</p>
<p>说话人 1 01:24:08<br>Whatever of course, you can have something more secretive here and I’m going to base 64 Encoding and the value that I get here.I’m going to copy it into the secret configuration as a value and I’m going to do the same with password so again.I’m just going to go with simple password.Obviously, you want to have something more secure.And I’m going to copy that is a value here and save it is Mongo Secret Dot HTML.</p>
<p>说话人 1 01:24:46<br>Ok, now we have only written configuration files.We haven’t created anything yet.In the cluster so this is just preparation work and we have to create secret before the deployement if we’re going to reference the secret.Inside of this so the order of creation matters because if I’m creating a deployement that references a secret that doesn’t exist yet.</p>
<p>说话人 1 01:25:09<br>I’m going to get an error.So it’s not going to start since we have our first component.Let’s actually go ahead and create our secret.From the configuration file so again I’m going to go to my console.It’s actually clear.All this and I’m going to go into the folder where I’m creating all these configuration files.I called it quits configuration and here I have both of my files so I’m going to keep city apply Mongo Secret.And secret created so I’m going to do cube CTL get secret.</p>
<p>说话人 1 01:25:48<br>An I should see my secret has been created.This is something created by default with a different type and this is our secret here.So now that we have our secrets.We can reference it inside over deployment configuration file so let’s go back and this is how you reference contents specific key value.Data of secret, so is there a value.We’re going to say value from.And then I’m going to do secret key ref.Secret key reference.Ann.Name is going to be the secret name so this one here.And key is going to be the key in the data.I want the value of these key value pair.So I want this part of the data.So I’m going to reference it by key so you don’t have to learn it by heart.Obviously all the syntax and attribute names important thing here is that you know approximately how to reference it.The actual syntax.You can always look up in Google or maybe from previous configuration files.But yeah, this is how you reference it and we’re going to do the same with password.So I’m going to do from an I’m just going to copy the rest here.Remember yellow is very strict with the indentation here is the same secret but a different key so I’m going to use password key here.And.That will be it so now we have.The root username and password referenced from the secret and no actual values inside the configuration file which is good for security because you don’t want your credentials in your code repository.Ok, so our deployment file is actually ready so let’s apply that.Ship city out there play.</p>
<p>说话人 1 01:27:55<br>And the deployment created, meaning if I do get all.I should see the pod starting up the deployment and the replica set so let’s actually.Check how hot is doing.Container creating so let’s actually watch it might take some time to create it if it takes long and if you want to see whether there is a problem there.You can also do cube CTL describe pod.In the pod name.So at least we know nothings wrong, there, so we see that it’s just pulling the image so that’s what it takes so long.So let’s see again cube city will get pot and as you see it’s running so we have multiple deployment and the port.One replica of its part running.</p>
<p>说话人 1 01:28:48<br>Now the second step is we’re going to create an internal service.So that other components or other ports can talk to these mongo DB so let’s go ahead and create service configuration so go back to Yemen.And here we can either create a separate yelmo configuration file for secret.Or we can also include it in the same one so in general.You can actually put multiple documents in one file so if I put 3 dashes.That’s basically a syntax for document separation in Yemen.So I need new document is starting so actually I’m going to put both deployment and service in one configuration file because they usually belong together, so here I’m going to.Paste the service configuration and by the way I’m going to put all these configuration files in Git repository and link.The repository in the description of this video so this is a service for Mongo DB.</p>
<p>说话人 1 01:29:46<br>Let’s go through some of the attributes here, so it’s the service kind just the name.We’re going to call it multi service selector.This is an important one because we want this service to connect to the pod right.And the way to do that is using selector and label so using this here.The labels that deployment and part have service can find the pods that it’s going to attach to.Alright so we have the selector here and this is important part where we expose service port so this is going to be the service port and this is going to be the container and since we expose container.</p>
<p>说话人 1 01:30:28<br>Port it this address but here these 2 have to match so target port is container or pot port and this is the service port and obviously these 2 here.Can be different but I’m going to go with the same port and that’s basically it that’s our service, so I’m going to create the service now.So let’s save this file and go back to my.Consult an I’m going to apply.The same file that I applied before to create deployment.So let’s see what happens see both deployment and service configuration, but it’s going to know that I haven’t changed deployment.That’s what it means here and.</p>
<p>说话人 1 01:31:13<br>Services created so if I were to edit both for example, I can reapply the file and diplomatic service can be changed.So I think using local configuration files is a handy way too.</p>
<p>说话人 1 01:31:27<br>Edit your components so now let’s actually check that our service was created get service.And this is our service and it’s listening at port.27,017 and I showed it in one of the previous videos.But we can actually also validate that the service is attached to the correct pod and to do that I’m going to describe.</p>
<p>说话人 1 01:31:55<br>Service you know need the service name for this.So here I have the endpoint, which is an IP address of the pod and the port where the application inside the pot is listening.It so let’s actually check that this is the right pot.I mean, we just have one but still.So if I do get pot Ann.I want additional output to what I get by default.One of the columns includes the IP address, which is this one right here so.172 point 17.06.That’s the pot IP address and this is the port where the application inside the pot is listening.So everything set up perfectly.</p>
<p>说话人 1 01:32:44<br>Mongo DB deployment and service has been created.And by the way if you want to see all the components for one.Application you can also display them using cubes.Etl get all that will show all the components and you can filter them by name so Mongo DB.And here you see the service.</p>
<p>说话人 1 01:33:10<br>Deployement replica, said in the pod so when you do all that component type will be first here OK.That’s just a site info.So now the next step.We’re going to create.Mongo express deployment and service and also an external configuration where we’re going to put the database.Url from going to be so let’s go ahead and do it, so I’m going to clear that up and.Go and create a new file for Mongo Express deployment in service.So this is the deployement draft of Mongo Express.</p>
<p>说话人 1 01:33:49<br>Same things here, Mongo Express that’s the name and here we have the pod definition where the image name is Mongo Express.Let’s actually go ahead and check that image as well.We don’t need this, this is more express.And that’s the name of the image more express and let’s see the same data here.Let’s see the port.</p>
<p>说话人 1 01:34:13<br>The Mongo Express application inside the container starts at is 8081.And.These are some of the environmental variables, so obviously, we need 3 things for Manga Express.We need to tell it, which database application.It should connect to so obviously, we need to tell it the Mongo DB.Address database address, it should connect to the internal service and we’re going to need credentials.So that mongo DB can authenticate that connection in the environment variables to do that is going to be.Admin username and password and the mongo DB endpoint will be this year.</p>
<p>说话人 1 01:34:53<br>So this 3 environments variables.We need so let’s go ahead and use that so first we’re going to open the port.Again.Container ports.And the reason why you have multiple ports that inside of the part where you can actually open multiple ports.So that’s going to be 8081 and now we’re going to.</p>
<p>说话人 1 01:35:20<br>At the environmental variables for the connectivity so the first one is.The username and this is going to be.Obviously, the same username and password that we defined right here.So what I’m going to do is I’m just going to copy them because it’s really the same, so the value from we’re going to read it from the secret.That’s already there, so I’m going to paste it here.</p>
<p>说话人 1 01:35:47<br>Second environmental variable is called and password.And I’m also going to copy that from here.And the third one.He’s gonna be the database server, and since this is also an external configuration.We could either do value here and we could write the mongo DB server address directly here.Or as I showed you in the diagram at the beginning, we can put it in a config map, which is an external configuration, so that it’s centralized so it’s stored in one place and also other components can also use it.So for example, if I have 2 applications that are using mongo DB database.Then I can just reference that external configuration here and if I have to change it at some point I just change it in one place.And nothing else gets updated so because of that.We’re going to keep this incomplete deployment configuration and we’re going to create the config map, which will contain the mongo DB server.</p>
<p>说话人 1 01:36:55<br>Address so I’m going to create a new file that’s actually save.This incomplete deployment.Let’s call it Mongo Express gamelan.We’re going to come back to it later.So save that now we need a config map here, so I’m going to copy the configuration and this is also pretty simple.</p>
<p>说话人 1 01:37:16<br>Just like secret you have the kind.Which is config map name end the same construct see just like you saw here data?Which is key value pair it doesn’t have a type.Because they’re just one config map type and that’s it.And here you again have key value pairs.</p>
<p>说话人 1 01:37:37<br>So database URL and server name is actually the name of the service.It’s as simple as that.So what do we call our service.We called it mongo DB service.So I’m going to copy the service name and that’s going to be the database server.</p>
<p>说话人 1 01:37:53<br>Url so I’m going to copy that and let’s actually call it mongo.Config map for consistency and save it and just like with secret the order of execution or creation matters.So I have to have a config map already.In the cluster so that I can reference it so when we’re done.I have to can create the config map first and then the deployment so the way that I can reference.The config map inside the deployment is very similar to secret, so I’m actually going to copy the whole thing.From secret put it here.The only thing different here is that instead of secret I’m going to say.Config.Map it’s all camel case and obviously the name is going to be.</p>
<p>说话人 1 01:38:46<br>Config map that’s what we called it I think.Yes, that’s the name that’s actually copied and again.The key is the key in the key value pair here so let’s copy that as well.So now we have our Mongo Express deployment.These are just standard stuff and this is where the pod blueprint or container configuration exists.We have exposed port 8081 this is the image.With latest tag and these are the 3 environmental variables that Mongo Express needs to connect and authenticate with mongo DB so deployment is done and let’s go ahead and create.Config map first and then Mongo Express deployment.Ctl apply?Config map.</p>
<p>说话人 1 01:39:41<br>And I’m going to do conceal apply.We Express.And let’s see the pot.So container creating.Looks good so see the pod.And it’s running.An I actually want to see the Lux so I’m going to lock that, Mongo Express.And here you see that express service started and database connected.</p>
<p>说话人 1 01:40:14<br>So now the final step is to access Mongo Express from a browser and in order to do that, we are going to need.An external service for mobile express so let’s go ahead and create that one as well.So it’s clear these output.Go back to visual code Ann as we did last time in the same file as a deployment.</p>
<p>说话人 1 01:40:35<br>I’m going to create more express service because actually in practice.You never have deployment without the service.So it makes sense to keep them together and this is Mongo Express External Service.</p>
<p>说话人 1 01:40:49<br>And this configuration right now looks exactly the same as the Mongo.Db service configuration and even ports are the same, like here, I have exposed service port 8081.And target port is where the container port is listening.</p>
<p>说话人 1 01:41:07<br>So how do I make these external service is by doing 2 things so in this specification?Section so I’m going to do it below the selector I’m going to put a type.In a type of this external services load balancer.Which I think is a bad name for external service because internal service also acts as a load balancer so if I had 2.Mongo DB parts.The internal service would also load balance, the requests coming to these pots.So I think the load balancer type name was chosen not very well because it could be confusing.But what this type load balancer does basically it accepts external requests.By assigning the service an external IP address so another thing that we’re going to do here to make this service.</p>
<p>说话人 1 01:42:05<br>External is right here.We’re going to provide third port and this is going to be called.Note port.And what this is basically is the port where this, external IP address will be open so this will be the port that I’ll have to put in the browser to access this service.In this note port actually has a range and that range is between 30,032 thousand something so I can not give it the?Imports here is I said it has to be between that range.So I’m just going to go with the 30,000 that’s the minimum in that range and that would be it.</p>
<p>说话人 1 01:42:50<br>So this configuration here will create an external service.Let’s go ahead and do it and I will show you.Exactly how this ports differ from each other so I’m going to apply.</p>
<p>说话人 1 01:43:06<br>Express.So service created and if I do get service.I see that mongo DB service that we created previously has a type of cluster IP in the Mongo Express service that we just created is load balancer, which is the type that we specifically defined.An internal service within specify any type because cluster IP, which is same as internal service type is default.So you don’t have to define it when you’re creating internal service.And the difference here is that cluster IP will give the service and internal IP address, which is this one right here.So this is an internal IP address of the service.</p>
<p>说话人 1 01:43:55<br>And load balancer will also give service an internal IP address.But in addition to that it will also give the service.An external IP address where the external requests will be coming from.</p>
<p>说话人 1 01:44:08<br>And here it says pending because we’re in Mini Cube and it works.A little bit differently.In a regular community set up here.You would also see an actual IP address at public one and this is another difference because with?Internal IP address you just have port for that IP address with both internal and external IP addresses.You have ports for both of them and that’s why we had to define third port, which was for the.</p>
<p>说话人 1 01:44:35<br>External IP address this is said pending means that he doesn’t have the external IP address yet so in Mini Cube, the way to do that is using the command Mini Cube.</p>
<p>说话人 1 01:44:46<br>Service and I’m going to need the name of the service.So this command will basically assign external service at public IP address so I’m going to execute this and the browser window will open.And I will see my Mongo Express page.So if I go back to the command line.You see that this command here assigned Mongo Express Service.A URL with the public IP address or with an external IP address.In the port which is what we defined in the node port so I can basically copy that command, which is the same as this one here.</p>
<p>说话人 1 01:45:26<br>And I get the page Formula Express so now with this setup, the way it’s going to work is that when I make changes here for example, I’m going to create a new database.Let’s call a test.Db whenever an I’m going to create a request.What just happened in background is that this request blended with the external service of Mongo Express, which then forwarded it to the Mongo Express.Part in the manga express pod connected to the Mongo.Db Service, an internal service.An mongo DB service, then forwarded that request finally to the mongo DB pot and then all the way back.</p>
<p>说话人 1 01:46:07<br>And we have the changes here.So that’s how you deploy a simple application set up in a Kubernetes cluster.In this video.Going to go through the usages of a namespace and the best practices of when and how to use a namespace.First of all what is a namespace in communities encourages cluster you can organize resources in namespaces so you can have multiple namespaces in a cluster you can think of a name space is a virtual cluster inside of a Kubernetes cluster.Now, when you created cluster by default Kubernetes gives you namespace is out of the box so in the command line.If I Type Cube.Ctl get namespaces.I see the list of those out of the box.Namespaces that Kubernetes offers and let’s go through them one by one.</p>
<p>说话人 1 01:47:01<br>The Kubernetes dashboard.Namespace is shipped automatically in Mini Cube.So it’s specific to mini cube installation, you will not have this in a standard cluster.The first one, is cube system.Kube system namespace is not meant for your use so basically you shouldn’t create anything or shouldn’t modify anything in cube system namespace.The components that are diploid in the namespace or the system.Processes there from master managing processes or cubes ETL, etc.</p>
<p>说话人 1 01:47:34<br>The Next One is Q Public and what Q Public contains is basically the publicly accessible data, it has a config map.That contains cluster information, which is accessible.Even without authentication.So if I type here.Q City of cluster info.This is the output that I get through that.Information and the third one is cube node list, which is actually a recent addition to communities and the purpose of that namespaces that it holds information about the Heartbeats of notes so each node basically.Gets its own object that contains the information about that.</p>
<p>说话人 1 01:48:13<br>Nodes availability and the fourth namespace use the default namespace and default namespace is the one that you’re going to be using to create.The resources at the beginning if you haven’t created a new namespace, but of course, you can add and create new name spaces and the way that you can do it is using cube CTL create namespace command.With the name of the namespace so I can create my name space.And if I do.Coops ETL get namespaces.I see that in my list.</p>
<p>说话人 1 01:48:45<br>Now, another way to create namespaces.Is using namespace configuration file?Which I think is a better way to create namespaces because you also have a history in your configuration file repository of what resources.Rated in the cluster OK, so now we saw what namespaces are and that you can create new ones.And that Kubernetes offers some of them by default, but the question is what is the need for namespaces?When should you create them and how you should use them and the first use case of using or creating your own namespaces is the following imagine you have only default namespace, which is provided by.Communities and you create all your resources in that default namespace.If you have a complex application that has multiple deployments, which create replicas of many parts and you have resources like Services, an config Maps, etc.Very soon your default namespace is going to be filled with different components and it will be really difficult to have an overview of what’s in there, especially we have multiple users, creating stuff inside so a better way to use namespaces.</p>
<p>说话人 1 01:49:59<br>In the.Case is to group resources into namespaces, so for example, you can have a database name space where you deploy your database and all its required resources and you can have a monitoring.</p>
<p>说话人 1 01:50:14<br>Name space where you diploid the parameters and all the stuff that it needs you can also have elastic stack namespace where all the Elasticsearch Kibana, etc resources goal and you can have engine X Ingress resources.So, just one way of logically grouping your resources inside of the cluster now, according to the official documentation of communities.</p>
<p>说话人 1 01:50:39<br>You shouldn’t use namespaces if you have smaller projects.End up to 10 users.I personally think that it’s always a good idea to group your resources in namespaces because as I said, even if you have a small project and 10 users.</p>
<p>说话人 1 01:50:58<br>You might still need some additional resources for application like logging system and money.During system and even with the minimum set up you can already get too much to just throw everything in a default namespace.</p>
<p>说话人 1 01:51:13<br>Another use case where you will need to use namespaces if you have multiple teams.So imagine this scenario, you have 2 teams that use the same cluster in one team.Deployes an application, which is called my app deployment.That’s the name of the deployment they create.And that deployment has its certain configuration now if another team had a deployment that accidentally had the same name.But a different configuration and they created the deployment or they applied it.They would overwrite the first teams deployment and if they’re using for example.A Jenkins or some automated way to deploy those that application or to create the deployment they wouldn’t even know that.They overwrote or disrupted in other teams deployment.So to avoid such kind of conflicts again.You can use namespaces so that each team can work in their own namespace without disrupting the other.</p>
<p>说话人 1 01:52:15<br>Another use case for using namespaces is let’s say you have one cluster and you want to host both staging and development environment in the same cluster in the reason for that is that for example, if you’re using?Something like engine X controller or elastic SEK use for logging for example, you can deploy it in one cluster an use it for both environments in that way.You don’t have to deploy this common resources.Twice in 2 different clusters so now the staging can use both resources as well as the development environment.</p>
<p>说话人 1 01:52:51<br>Another use case for using namespaces is when you use blue green deployment for application?Which means that in the same cluster you want to have 2 different versions of production so the one that is active that is in production now and another one that is going to be the next production version.The versions of the applications in those blue and green production namespaces will be different.However, the same as we saw before in staging and Development.This namespaces might need to use the same resources.</p>
<p>说话人 1 01:53:24<br>Think again answer next controller or elastic stake in this way again.They can both use.This common shared resources without having to set up a separate cluster so one more use case.For using namespaces is too.Limit the resources and access to namespaces when you’re working with multiple teams.</p>
<p>说话人 1 01:53:46<br>So again.We have a scenario where we have 2 teams working on the same cluster and each one of them has their own namespace.So what you can do in this scenario is that you can give.The teams access to only their name space so they can only be able to create updates.Delete resources in their own namespace, but they can’t do anything.In the other namespaces and this way, you even restrict or even minimize the risk of one team accidentally interfering with another teams work so each one has their own secured isolated environment.</p>
<p>说话人 1 01:54:21<br>Additional thing that you can do on the namespace level is limit the resources that each namespace consumes because if you have a cluster with limited resources.You want to give each team share of resources.For their application so if one team.Let’s say consumes too much resources than other teams will eventually have much less and their applications may not schedule because the cluster will run out of the resources.So what you can do is that per namespace.You can define resource quotas that limit how much CPU.</p>
<p>说话人 1 01:54:55<br>Ram storage resources.One namespace can use so I hope walking through this scenarios helped you.Analyze in which use cases and how you should use namespaces in your specific project.There are several characteristics that you should consider before deciding how to group and how to use namespaces.The first one, is that you can’t.Access most of the resources from another namespace, so for example, if you have a configuration map in project.A namespace that references the database service, you can’t use that config map.In Project B namespace, but instead you will have to create the same config map that also references the database service, so each namespace will define or must define its own config map.Even if it’s the same reference in the same applies to secret, so for example, we have credentials of a shared service, you will have to create that secret in each namespace where you are going to need that however.A resource that you can share across namespaces is service and that’s what we saw in the previous slide.So config map in Project B namespace references service that is going to be used eventually in a pot.And the way it works is that in a config map definition that database URL.In addition to its name, which is my SQL service will have namespace at the end, so using that URL you can actually access services.From other namespaces, which is a very practical thing and this is how you can actually use shared resources like Elasticsearch or engine X from other namespaces and one more characteristic is that?</p>
<p>说话人 1 01:56:40<br>We saw that most of the components resources can be created within a namespace.But there are some components in Kubernetes.They’re not namespaced so to say basically they leave just.Globally, in the cluster and you can’t isolate them or put them in a certain namespace and examples of such resources are volume or persistent volume and note.So basically when you create the volume?It’s going to be accessible throughout the whole cluster because it’s not in a namespace and you can actually least components.They are not bound to a namespace using a command cube CTL API resources.Dash dash namespaced false and the same way you can also leased all the resources that are bound to a namespace using namespace true.</p>
<p>说话人 1 01:57:29<br>So now that you’ve learned what the namespaces are why to use them.In which cases it makes sense to use them in which way and also some characteristics that you should consider let’s actually see how to create components in a namespace in the last example.</p>
<p>说话人 1 01:57:46<br>We’ve created components using configuration files.In know where there we have defined in namespace, So what happens is by default.If you don’t provide an namespace to a component.It creates them in a default namespace, so if I apply this config map component.And let’s do that actually right now, so keep CD apply minus F config map.If I apply that an eye.Dooku city will get config map my config map was created in a default namespace and notice that.Even in the Cube Cityel gets config map command.I didn’t use a namespace because Coop City, will get or keep serial commands.They take the default namespace is a default so coupes, it’ll get config map.Is actually same as cube city will get config map dash an or namespace and default namespace so these are the same commands is just a shortcut because it takes default as a default namespace, OK, so one way that I can create this config map.</p>
<p>说话人 1 01:58:45<br>In specific namespace is using cubes it’ll apply command, but adding Flake Namespace.And the namespace name.So this will create config map in my name space and this is one way to do it.</p>
<p>说话人 1 01:59:01<br>Another way is inside the configuration file itself, so I can adjust these config map configuration file.To include the information about the destination namespace itself, so in the metadata.I can add namespace attribute so if I apply this configuration file again using cube CTL apply and now if I want to get the component that I created in this specific namespace.Then I have to add the option or the flag to coosa tailgate comment because as I said, We’re default.It will check only in the default namespace.So I recommend using the namespace attribute in a configuration file instead of providing it to the Cube City L command because one, it’s it’s better documented so you know.By just looking at the configuration file where the component is getting created because there could be an important information and second if you’re using automated deployment where you’re just applying the configuration files.</p>
<p>说话人 1 02:00:03<br>Then again, this will be more convenient way to do it no if for example, we take a scenario where one team gets their own namespace in there has to work entirely in the namespace.It could be pretty annoying to have to.At this namespace tagged every cube cityel command, so in order to make it more convenient.There is a way to change.This default or active namespace, which is default namespace to whatever namespace you choose.And communities or keep still doesn’t have any out of the box solution for that.But there’s a tool called Cube and S or Cubans and you have to install the tool so on Mac.So I’m going to execute brew install.Keep City X so this will install Cubans tool as well, so once I have the Cubans installed I can just.</p>
<p>说话人 1 02:00:58<br>Execute Cubans comment.And this will give me a list of all the namespaces and highlight the one that is active, which is default right now and if I want to change the active namespace, I can do cube ends.</p>
<p>说话人 1 02:01:13<br>My name space.And this will switch the active namespace, so if I do Cubans now.I see that active.One is my name space so now I can execute cubes detail commands without providing my namespace namespace.But obviously if you switch a lot between the namespaces.This will not be so much convenient for your own operating system and environment there will be.</p>
<p>说话人 1 02:01:45<br>Different installation process so I’m going to link the Cube City X installation guide in the description below.So, in this video we’re going to talk about what Ingress is and how you should use it and also what are different use cases for Ingress?So first of all let’s imagine a simple Kubernetes cluster.We have a pot of my application and its corresponding service.My service so the first thing you need for UI application is to be accessible.Through browser right so for external requests to be able to reach your application.So one way to do that and easy way is through an external service, where basically you can access the application.Using HTTP protocol the IP address of the node and the port.</p>
<p>说话人 1 02:02:37<br>However, this is good for test cases.And if you want to try something very fast, but this is not what the?Final product should look like the final product should be like this so you have a domain name for application and you want to secure connection using HTTPS so the way to do that is using this component called?Ingress so you’ll have my app Ingress and instead of external service, you would instead have an internal service.So you would not open your application through the IP address and the.Port and now if the request comes from the browser.It’s going to first reach the Ingress and Ingress then will re directed to the internal service and then it will eventually end up with the pot.</p>
<p>说话人 1 02:03:23<br>So now let’s actually take a look.And see how external service configuration looks like so that you have a practical understanding.So you have the service, which is of type load balancer.This means we’re opening it to public by assigning.An external IP address with the service and this is the port number that user can access the application at so basically IP address the external IP address and the port number that you.Specify here now with Ingress of course, it looks differently.So let’s go through the syntax of Ingress.Basically, you have a kind.Ingress instead of a service and in the specification where the whole configuration happens.You have so called rules or routing rules and this basically defines that you domain address or all the requests to that host must be forwarded to an internal service.So this is the host that user will enter in the browser and in English use define a mapping So what happens when the request to the host gets issued you redirected internally to a service.</p>
<p>说话人 1 02:04:34<br>Path you basically means the URL path so everything after the domain name.So slash whatever path comes up to that you can define those rules here and we’ll see some different examples of the path configuration later and as you see here in this configuration we have HTTP protocol.So later in this video I’m going to show you how to configure HTTPS connection using English component so right now in the specification.We don’t have anything configured for the secure connection is just a.Issue the P Ain one thing to note here is that this HTP attribute here does not correspond to this one here.This is a protocol that the incoming request gets forwarded to to the internal service.So this is actually the second step and not to confuse it with this one.And uh let’s see how the internal service to that Ingress will look like so basically back end is the target where the request.The incoming request will be redirected and the service name should correspond to the internal service name like this.And the port should be internal service port and as you see here.The only difference between the external and internal services is that here in internal service.I don’t have the third port switches.The node ports starting from 30,000, we now have that attribute here.And the type is a default type, not a load balancer, but internal service type, which is cluster.</p>
<p>说话人 1 02:06:06<br>Ip so this should be a valid domain address so you can just write anything here.It has to be first of all valid.And you should map that domain name to IP address of the node that represents an entry point to your Kubernetes cluster so for example, if you decide that one of the nodes inside the cabinets cluster.Is going to be the entry point then you should map this to the IP address of that note or and we will see that later if you configure a server outside of the cabinets cluster that will become the entry points.</p>
<p>说话人 1 02:06:41<br>2 companies cluster then you should map this host name to the IP address of that server.So now that we saw?What Kubernetes Ingress components looks like let’s see how to actually configure Ingress.In the cluster so remember this diagram.I showed you the beginning.</p>
<p>说话人 1 02:06:59<br>So basically you have a pod service in corresponding Ingress now.If you create that English components alone.That won’t be enough for Ingress routing rules to work what you need in addition, is an implementation for Ingress and that implementation is called Ingress Controller, so the step.One will be to install an?Ingress controllers which is basically another pod, or another set of pods that run on your note in your cabinets cluster and us evaluation and processing of Ingress rules.So the yellow file that I showed you with the Ingress component is basically this part right here.And this has to be Additionally installed incumbents cluster So what is Ingress controller?Exactly the function of Ingress Controller is to evaluate all the rules that you have defined in your cluster and this way to manage all the re directions.So basically this will be the entry point.In the cluster for all the requests to that domain or sub domain rules that you’ve configured and this will evaluate all the rules because you may have 50 rules or 50 Ingress components created in your cluster.It will evaluate all.Rules and decide based on that which forwarding rule applies for that specific request so in order to install this implementation of Ingress in your cluster you have to decide which one.Of many different third party implementations.You want to choose from.</p>
<p>说话人 1 02:08:37<br>I will put a link of the whole list and description where you see different kinds of English controllers you can choose from.There is one from Kubernetes itself, which is coordinated.Engine X Inggris Controller, but there are others as well so once we install Ingress Controller in your cluster.You’re good to go create English roles and the whole configuration is going to work so now that I’ve shown you.</p>
<p>说话人 1 02:09:01<br>How Ingress can be used in acuminatus cluster but there is one thing that I think is important to understand in terms of setting up the whole cluster to be able to receive external requests now first of all.You have to consider the environment, where you come in at this cluster is running if you are using some cloud service provider like Amazon Web Services, Google Cloud Linode, there a couple more that have.Out of the book screen.It is solutions or they have their own virtualized load balances etc.Your cluster configuration would look something like this so you would have a cloud load balancer that is specifically implemented by that cloud.Provider and external requests coming from the browser will first heat the load balancer and that load balancer.Then will redirect the requests to English controller.</p>
<p>说话人 1 02:09:57<br>Now, this is not the only way to do it even in cloud environment.You can do it in a couple of different ways, but this is one of the most common strategies.An advantage of using cloud provider for that is that you don’t have to implement a load balancer.Yourself so with minimal effort probably on most cloud providers.You will have the load balancer up and running and ready to receive those requests and forward those requests into your cabinets cluster.So very easy set up now.If you are deploying equipment is cluster on a bare metal environment.Then you would have to do.That part yourself.So basically you would have to configure some kind of entry point to your covenants cluster yourself.And there’s a whole list of different ways to do that.And I’m going to put that also in the description, but generally speaking, either inside of a cluster or outside is a separate server.You will have to provide an entry point in one of those types is an external proxy server, which can be a software, or hardware solution that will take a roll of that.</p>
<p>说话人 1 02:11:10<br>Load balancer an entry point to your cluster so basically what this would mean is that you will have a separate server, and you would give this a public IP address and you would open the ports in order for the requests.To be accepted, and this proxy server, then will act as an entry point to your cluster so this will be the only one accessible externally so none of the servers in your communities cluster will have.Publicly, accessible IP address, which is obviously a very good security practice.So all the requests will enter the proxy server, and that will then redirect the requests to Ingress Controller and English controller.Will then decide which Ingress rule applies to that specific request and the whole internal?Request forwarding will happen.</p>
<p>说话人 1 02:12:01<br>So is it said there are different ways to configure that and to set it up depending on which environment you are, and also which approach you choose.But I think it’s a very important concept to understand how the whole.Cluster setup works so in my case since I’m using mini cube to demonstrate all this on my laptop.The setup will be pretty easy and even though this might not apply exactly to your cluster setting.Still, you will see in practice how all these things work.So the first thing is to install Ingress Controller in Mini Cube and the way to do that is by executing mini cube add ONS enabled.Ingress.So what this does is automatically configures or automatically starts the Kubernetes engine.X implementation of Ingress controller, so that’s 1 of the many third party implementations, which you can also.Safely use in production environments, not just mini cube, but this is what mini cube actually offers you out of the box so with one simple command, Ingress Controller will be configured in your cluster and.If you do Coop City.I’ll get pod in a cube system namespace.You will see the engine X Ingress Controller Pod running in your cluster so once I have English controller installed now I can create an Ingress rule that the controller can.Evaluate so let’s actually head over to the command line, where I’m going to create Ingress rule for Kubernetes dashboard components so in my mini Kube cluster, I have.Kubernetes dashboard, which is right now not accessible externally So what I’m going to do is since I already have internal service for communities dashboard and a pot for that.</p>
<p>说话人 1 02:13:48<br>I’m going to configure an Ingress rule.For the dashboard so I can access it from a browser using some domaining.So I’m going to.So this shows me all the components that I have in common is dashboard.And since I already have internal service.</p>
<p>说话人 1 02:14:07<br>Kubernetes dashboard and the pod.That’s running I can now create an Ingress.Our rule in order to access the Kubernetes dashboard using some host name, so let’s go ahead and do that.So I’m going to create an Ingress for quantities dashboard so these are just metadata.The name is going to be dashboard.Ingress and the namespace.It’s going to be in the same namespace as the service an pot.So, in the specification we’re going to define the rules so the first rule is the host name.I’m just going to call.I’m going to definedashboard.Com.And the HTTP forwarding to internal service.Path let’s leave it at all path.And this is the back end of the service so service name will be what we saw here.So this is the service name.And service port.Is what the service listens so this is actually 80 right here?And this will be it.That’s the English configuration for forwarding every request.That is directed to dashboard.Com to internal carbonated dashboard service and we know it’s internal because its type.These cluster IP so no external IP address so obviously I just made.Host namedashboard.Com it’s not registered anywhere, and I also didn’t configure anywhere, which IP address.This host name should resolve to and this is something that you will.Always have to configure so first of all let’s actually create that Ingress rule so cube city will apply.And it’s called Dashboard Ingress.Mo.See English was created so if I do get increase in the namespace.I should see my English here and as you see address is now empty because it takes a little bit of time to assign the address to Ingress so.We’ll have to wait for that to get the IP address that will map to this host so I’m just going to.Watch this and it’s I see that address was assigned So what I’m going to do now is that I’m going to take that address.An in my.It is see hosts file.</p>
<p>说话人 1 02:16:55<br>At the end I’m going to define that mapping so that IP address will be mapped to dashboard.Dot com and again this works locally if I’m going to typedashboard.Com in the browser.This will be the IP address that it’s going to be mapped to.Which basically means that the request will come into my mini kube cluster will be handed over to English controller and English.Controller then we’ll go and evaluate this rule that I’ve defined here and forward that.</p>
<p>说话人 1 02:17:27<br>Request to service so this is all the configuration, we need so now I’m going to go and.And enterdashboard.Com.And I will see my Kubernetes dashboard here.So Ingress also has something called a default back end, so if I do cube CTL describe Ingress.The name of the Ingress and the namespace.I’ll get this output and here.There is an attribute called default back end.That Maps to default HTTP back end port 80.So what this means is that whenever a request comes into the cabinets cluster.That is not mapped to any back end, so there is no rule for mapping that request to into a service.Then this default back end is used to handle that request.So obviously if you don’t have this service created or defined in your cluster communities will try to forward it to the service.It won’t find it and you would get some default.</p>
<p>说话人 1 02:18:43<br>Error response so for example, if I entered some path that I have configured.I just get page.Not found so it could use it for that is to define custom error messages when.Pages and font when request comes in that you can handle or the application can handle so that users still sees meaningful error message or just the custom page where you can re direct them to your home page.Or something like this so all you have to do is create an internal service with the same name so default HTTP back end and.Port number and also create a pod or application that sends that error, custom error message response.</p>
<p>说话人 1 02:19:29<br>So to know I have shown you what increases and how you can use it.I’ve also shown you a demo of how to create an English rule in Mini Cube.But we’ve used only very basic Ingress Yaml configuration just a simple forwarding to one internal service.With one path, but you can do much more with Ingress configuration than just basic forwarding and in the next section will going to go through more use cases.</p>
<p>说话人 1 02:20:01<br>Of how you can define more fine granular routing for applications inside cabinets cluster so the first thing is defining multiple path of the same host.So consider following use case.Google has one domain, but has many services that it offers so for example, if you have a Google account.You can use its analytics.You can use it shopping.You have a calendar you have a Gmail etc.So all of these are separate applications that are accessible with the same domain so consider, you have an application that does something similar so you offer 2.Separate applications there are part of the same ecosystem, but you still want to have them on separate URLs So what you can do is that in rules, you can define the host.</p>
<p>说话人 1 02:20:53<br>Which is myIP.Com and in the path section you can define multiple path so if user wants to access your analytics application, then they have to enter myapp.Com slash Analytics.And that will forward the request to internal and Analytics Service in the pot or if they want to access the shopping application.Then the URL for that will be myapp.Com slash.Shopping so this way, you can do forwarding with one Ingress of the same host to multiple applications using multiple path another use case is when instead of using?Urls to make different applications accessible some companies use subdomains.So instead of having myapp.Com slash Analytics.They create a sub domain.Analytics dotmyapp.Com, so if you have your application configured that way.Your configuration will look like this.So instead of having one host like in the previous example and multiple path here inside.Now you have multiple hosts where each host represents a sub domain and inside.You just have one path that again redirects that request to analytics service.Pretty straightforward so now in the same request, setting you have analytics service, and apart behind it.Now, the requests will look like this using the sub domain instead of path.</p>
<p>说话人 1 02:22:25<br>And one final topic that I mentioned that will cover here is configuring TLS certificate till now we’ve only seen Ingress configuration for HTTP requests, but it’s super easy to configure.Https forwarding in Ingress, so the only thing that you need to do is define attribute called TLS above the rules section with host which is the same host is right here and.The secret name, which is a reference of a secret that you have to create in a cluster that holds that TLS certificate.So the secret configuration would look like this so the name is the reference right here and the data or the actual contents contain TLS certificate and TLS.</p>
<p>说话人 1 02:23:13<br>Keep if you’ve seen my other videos where I create different components like secret you probably notice that type additional type attribute here in Kubernetes.There is a specific type of a secret.Called TLS so have to use that type when you create a TLS secret and there are 3 small notes To to be made here.One is that the keys of this data have to be named.Exactly like that, the values are the actual file contents of the certificate or key contents and not the file path or location.So you have to put the whole content here base 64 encoded.And the third one is that you have to create the secret in the same namespace as the English component for it to be able to use that otherwise you can’t reference a secret from another namespace.And these 4 lines is all you need to configure mapping of an HTTPS request to that host to internal service.</p>
<p>说话人 1 02:24:22<br>In this video I’m going to explain all the main concepts of helm, so that you are able to use it in your own projects also helmed changes.A lot from version to version so understanding the basic common principles and more importantly, its use cases too.When and why we use helm will make it easier for you to use it in practice, no matter which version you choose.So the topics.I’m going to go through in this video are Helman Helm charts what they are how to use them.And in which scenarios there used and also what is Steeler and what part it plays in the helm architecture So what is helm.</p>
<p>说话人 1 02:24:59<br>Helm has a couple of main features that it’s useful the first one is.Is the package manager for Kubernetes so you can think of it as EPD Yum or homebrew Kubernetes?So it’s a convenient way for packaging collections of Kubernetes.Yaml files and distributing them in public and private registry.</p>
<p>说话人 1 02:25:22<br>Now, this definitions may sound a bit abstract, so let’s break them down.With specific examples.So let’s say you have diploid your application in cabinets cluster.And you want to deploy Elasticsearch.Additionally, new cluster that your application will use to collect its logs.In order to deploy elastic stick in your Kubernetes cluster.You would need a couple of communities components so you would need a stateful set which is for stateful applications like databases.You will need a config map with external configuration, you would need a secret where some credentials.And secret data are stored you will need to create the communities user with its respective permissions, and also create a couple of services.</p>
<p>说话人 1 02:26:12<br>Now, if you were to create all of these files manually.By searching for each one of them separately on Internet be a tedious job and until we have all these yellow files collected and tested and try it out, it might take some time and seems elastic stack deployment.Is pretty much the standard across all clusters other people will probably have to go through the same?So it made perfect sense.Is that someone created this yellow files once and package them up and made it available somewhere so that other people also use the same kind of deployment could use them in their community.Cluster and that bundle of yellow files is called Helm chart.So using helm, you can create your own helm charts or bundles of those yellow files and push them to some helm repository to make it available for others.Or you can consume so you can use download and use existing helm charts that other people pushed and made available in different repositories, so commonly used deployments like database applications.Elasticsearch mongo DB my SQL or monitoring applications like Prometheus that all have this kind of complex setup.All have charts available in some helm repository so using a simple helm install chart name command.You can reuse the configuration that someone else has already made.Without additional effort and sometimes that someone is even the company that created the application.And this functionality of sharing charts that became pretty widely used actually was one of the contributors to why.Home became so popular compared to its alternative tools.</p>
<p>说话人 1 02:28:06<br>So now if your if you have a cluster and you need some kind of deployment that you think should be available out there, you can actually look it up.Either using command line so you can do helm search with a keyword or you can go to either Helms on public repository helm hub or on helm charts pages or other repositories.That are available and I will put all the relevant links for this video in the description.So you can check them out now.</p>
<p>说话人 1 02:28:37<br>Apart from those public registries for helm charts.There are also private registries because.When companies start creating those charts.They also started distributing them among or internally in the organization.So it made perfect sense to create registries to share those charts.Within the organization and not publicly so there are a couple of tools out there.There used as helm charts.</p>
<p>说话人 1 02:29:05<br>Private repositories as well.In other functionality of helm is.That, it’s a templating engine So what does that actually mean imagine you have an application that is made up of multiple microservices and you’re deploying all of them in your cabinets cluster.And deployment and service of each of those microservices are pretty much the same with the only difference that the application name and version are different or the Docker image name and version.Tags are different so without helm.You would write separate YAML files configuration files for each of those microservices so you would have multiple deployment service files where?Each one has its own.Application name and version defined but since the only difference between those yellow files are just a couple of lines or couple of values using helm, where you can do is that you can define.A common blueprint for all the microservices in the values that are dynamic or the values that are going to change.</p>
<p>说话人 1 02:30:14<br>Replace by placeholders and that would be a template file.So the template file would look something like this, you would have a template file which is standard eml, but instead of values in some places, you would have this syntax, which means that you are taking a value from.External configuration and that external configuration if you see the syntax here.</p>
<p>说话人 1 02:30:37<br>Dot values that external configuration comes from an additional yellow file which is called value stored Yemen and.Here you can define all those values that you’re going to use in that template file so for example, here.Those 4 values are defined in and values Yaml file and what values is.It’s an object that is being created.Based on the values that are supplied via values.Yaml file and also through command line.Using dash dash set flag zero, which every way you define those additional values their combined.And put together in dark values object that you can then use in those template files to get the values out.</p>
<p>说话人 1 02:31:25<br>So now instead of having yellow files for each microservice you just have one and you can simply replace those values.Dynamically and this is especially practical when you’re using continuous delivery continuous integration for application because what you can do is that in your builds pipeline, you can use those template demo.</p>
<p>说话人 1 02:31:47<br>Files in replace the values on the fly before deploying them another use case where you can use the helm features of package manager and templating engine.Is when you deploy the same set of applications across different Kubernetes clusters so consider use case?Where you have your microservice application that you want to deploy on development.Staging and production clusters, so instead of deploying the individual yellow files.Separately, in each cluster.You can package them up to make your own application chart that will have.All the necessary yellow files that that particular deployment needs and then you can use them to redeploy the same application in different communities cluster environments.Using one command, which can also make the whole deployment process easier.</p>
<p>说话人 1 02:32:46<br>So now that you know what helm charts are used for it.Let’s actually look at an example helm chart structure to have a better understanding.So typically chart is made up of such a directory structure, so we have the top level will be the name of the chart an inside the directory.You would have following so chart dot UML is basically.The file that contains all the meta information about the chart could be name and version, maybe list of Dependencies etc.Values to demo that I mentioned before, is place where all the values are configured for the template files and this will actually be the default values that you can.</p>
<p>说话人 1 02:33:30<br>Override later.The charts directory will have chart dependencies inside, meaning that if this chart depends on other charts, then those chart dependencies will be stored here and templates.Folder is basically when the template files are stored so when you execute helm install command to actually deploy those yellow files into communities.The template files from here will be.It filled with the values from values dot yamil producing valid communities manifest that can then be diploid into communities.And optionally you can have some other files in this folder like Readme or license file etc.So to have a better understanding of how values are injected into helm templates.</p>
<p>说话人 1 02:34:23<br>Consider that in values that yellow, which is a default value configuration.You have following 3 values image name.Port inversion and as I mentioned the default values that are defined here.</p>
<p>说话人 1 02:34:37<br>Can be over ridden in a couple of different ways one way is that when executing helm install command you can provide an alternative E values Yaml file using values flake.So for example, if values, Yaml file will have following 3 values, which are image name.</p>
<p>说话人 1 02:34:57<br>Porten version you can define your own values, yellow file called my values dot eml an you can.Override one of those values or you can even add some new attributes there and those 2 will be merged which will result into adult values object that will look like this so would have.Image name import from values or demo and the one that you overrode with your own values file.</p>
<p>说话人 1 02:35:25<br>Alternatively, you can also provide additional individual values using?Set flag where you can define the values directly on the command line but of course.It’s more organized and better manageable to have files where you store all those values instead of just providing them on the command line.</p>
<p>说话人 1 02:35:45<br>Another feature of helm is release management, which is provided based on it’s set up but it’s important to note here.The difference between health versions 2 and 3 in version 2.</p>
<p>说话人 1 02:35:59<br>Of helm to helm installation comes in 2 parts.You have helped client and the server and the server part is called Tiller so whenever you deploy helm chart using helm install.My chart help client will send the yellow files to Taylor that actually runs has to run in a Kubernetes cluster and Taylor then will execute this request and create components.From this yellow files inside the currents cluster and exactly this architecture offers additional valuable feature of helm, which is release management so the way helm clients server setup works.Is that whenever you create or change deployement?Peeler will store a copy of each configuration client sent for future reference thus creating a history of chart executions.So when you execute helm upgrade chart name.The changes will be applied to the existing deployment instead of removing it and creating a new one and also in case the upgrades goes wrong for example, some yellow files where false or some configuration was wrong.You can rollback that upgrade using helm rollback chart name comment.And all this is possible because of that chart execution history that Taylor keeps whenever you send those requests from helm client to dealer.</p>
<p>说话人 1 02:37:29<br>However, this setup has a big caveat, which is.That Taylor has too much power inside the covenants, cluster, it can create update delete compose.And it has too much permissions.And this makes it actually a big security issue and this was one of the reasons why in hell 3.They actually removed.The teal apart and it’s just the simple helm.Binary now and it’s important to mention here.Because a lot of people have heard of Taylor and when you deploy helm version 3.You should be confused that Taylor isn’t actually there anymore.In this video I will show you how you can persist data in Kubernetes using volumes.We will cover 3 components of Kubernetes Storage.Persistent volume persistent volume claim and storage class.</p>
<p>说话人 1 02:38:24<br>And see what each component does and how it’s created and used for data persistence consider a case where you have a my SQL database pod, which your application uses data gets added.Updated in the database, maybe you create a new database with a new user etc.But default when you restart the pod.All those changes will be gone because Kubernetes doesn’t give you.Data persistence out of the box that something that you have to explicitly configure for each application that needs saving data between pod restarts.So basically you need a storage that doesn’t depend on the Pod Lifecycle.So it will still be there.When Paradise in new one gets created so the new part can pick up where the previous one left.Off so it will read the existing data from that storage to get up-to-date data.However, you don’t know on which node the new pod restarts.So, your storage must also be available on all nodes.</p>
<p>说话人 1 02:39:29<br>Not just one specific one so that when the new pod tries to read the existing data.The up-to-date data is there on any node in the cluster.Anne also you need a highly available storage that will survive, even if the whole cluster crashed.So these are the criteria or the requirements that your storage for example, your database storage will need to have to be reliable.</p>
<p>说话人 1 02:39:59<br>Another use case for persistent storage, which is not for database.Is a directory?Maybe you have an application that writes and reads files from pre configured directory.This could be session files for application or configuration files etc.An you can configure.</p>
<p>说话人 1 02:40:16<br>Any of these type of storage using carbonated component called persistent volume.Think of a persistent volume as a cluster resource just like ram or CPU that is used to store.</p>
<p>说话人 1 02:40:30<br>Data.Persistent volume just like any other component gets created using communities yellow file where you can specify the kind which is persistent volume and in the specification section you have to define.Different parameters like how much storage should be created for the volume.But since persistent volume is just an abstract component.It must take the storage from the actual physical storage right.Like local hard drive from the cluster nodes or your external NFS servers outside of the cluster or maybe cloud storage like KWS block storage or from Google Cloud Storage.Etc.So the question is where does this storage back end come from local or remote sore on cloud.Who configures it?Who makes it available to the cluster and that’s the tricky part of data persistence in communities because Kubernetes doesn’t care about your actual storage it gives you?</p>
<p>说话人 1 02:41:33<br>Persistent volume component as an interface to the actual storage that you as a maintainer or administrator have to take care of so you have to decide what type of storage your cluster.Services or applications would need and create an manage them by yourself managing, meaning do backups and make sure they don’t get corrupt etc.</p>
<p>说话人 1 02:41:57<br>So think of storage in Kubernetes.As an external plug into your cluster whether it’s a local storage on actual nodes where the cluster is running or a remote storage doesn’t matter there all plugins to the cluster.And you can have multiple storage is configured for your cluster where one application in your cluster uses local disk storage.Another one uses the NFS server and another one uses some cloud storage.Or one application may also use multiple of those storage types and by creating persistent volumes.</p>
<p>说话人 1 02:42:36<br>You can use this actual physical storage is so in the persistent volume specification section.You can define which storage back end, you want to use to create that storage abstraction or storage resource for applications, so this is an example where we use.</p>
<p>说话人 1 02:42:55<br>Nfs storage back end, so basically we define how much storage.We need some additional parameters to that storage like should it be readwrite or readonly, etc and the storage back end.With its parameters.And this is another example where we use, Google Cloud as a storage back end again with the storage back end specified here and capacity and access modes here now, obviously depending on the storage type.On the storage, Beck and some of the attributes in the specification will be different because there are specific to the storage type.</p>
<p>说话人 1 02:43:35<br>This is another example of a local storage, which is on the node itself.Which has additional node affinity attribute now you don’t have to remember and know all these attributes at once because you may may not need all of them and also I will make separate videos covering some of the most used volumes.And explain them individually with examples and demos so there.</p>
<p>说话人 1 02:44:00<br>I’m going to explain in more detail, which attributes should be used for this specific volumes and what they actually mean in the official Kubernetes documentation, you can actually see the complete list.Of more than 25 storage backends that Kubernetes supports note here that persistent volumes are not namespaced meaning there accessible to the whole cluster.In unlike other components that we saw like parts and services.They’re not in any namespace there just available to the whole cluster to all the namespaces.</p>
<p>说话人 1 02:44:35<br>Now it’s important to differentiate here between 2 categories of the volumes local and remote each volume type in these 2 categories has its own use case.Otherwise, they won’t exist.And we will see some of these use cases later in this video.However, the local volume types violate the second and third requirements of data persistence for data.This is that I mentioned at the beginning, which is one, not being tide to one specific node.But rather to each node equally because you don’t know where the new pod will.Start in the second surviving in cluster crash scenarios because of these reasons for database persistence.You should almost always use remote storage.So who creates these persistent volumes and win.As I said persistent volumes are resources like CPU or ram so they have to be already there.In the cluster when the pod that depends on it or that uses it is created so a side note here.That there are 2 main roles in Kubernetes.There is an administrator who sets up the cluster and maintains it and also make sure the cluster has enough resources.These are usually system administrators or DevOps engineers and accompany.In the second role is communities user that deploys the applications in the cluster either directly or through CI pipeline.These are developer.Devops teams who create the applications and deploy them.In this case, the Kubernetes administrator would be the one to configure the actual storage, meaning to make sure that the NFS server storage?Is there an configured or maybe create and configure.A cloud storage that will be available for the cluster and second create persistent volume components.From this storage beckons based on the information from developer team of what types of storage.Their applications would need and the developers, then we’ll know that storage is there an can be used by their applications.But for that developers have to explicitly configure the application.Yellow file to use those persistent volume components in other words, application has to claim that volume storage and you do that using another component of Kubernetes called persistent.</p>
<p>说话人 1 02:47:09<br>Volume claim persistent volume claims also PVCS are also created with Yaml configuration.Here’s an example claim again don’t worry about understanding each and every attribute that is defined here.Put on the higher level, the way it works is that PVC claims of volume with certain storage size or capacity, which is defined in the persistent volume claim an some additional characteristics.Like excess type should be read only or read rights or the type etc.And whatever persistent volume matches.This criteria or in other words, satisfies this claim.</p>
<p>说话人 1 02:47:51<br>Will be used for the application, but that’s not all, you have to now use that claim in your parts configuration like this so in the pod specification here, you have the volumes.Attribute that references the persistent volume claim with its name.So now the pod and all the containers inside the pod will have access to that.Persistent volume storage so to go through those levels of abstractions that by step pods excess storage by using the claim, as a volume right so they request, the volume?Through claim the claim, then we’ll go and try to find a volume persistent volume in the cluster that satisfies the clay.In the volume will have a storage, the actual storage back end, that it will create that storage resource from in this way.The pod will now be able to use that actual.</p>
<p>说话人 1 02:48:54<br>Storage back end note here that claims must exist in the same namespace as the pod using the claim while as I mentioned before persistent volumes are not namespaced so once the pod.Finds the matching persistent volume through the volume claim through the persistent volume claim.The volume is then mounted into the pod like this here.This is a pod level.And then that volume can be mounted into the container inside the pot, which is this level right here.And if you have multiple containers here in the pod you can decide.To Mount this volume in all the containers or just some of those so now the container.And the application inside the container can read and write to that storage and when the pod dies in new one gets created it will have access to the same storage and see all the changes the previous pod, or the previous containers.</p>
<p>说话人 1 02:49:54<br>Meet again the attributes here like volumes and volume mounts, etc and how they’re used.I will show you more specifically and explain in a later demo video now you may be wondering why so many abstractions.For using volume where admin role has to create persistent volume and reuse.The role creates a claim on that.Persistent volume and that is in use in pot?Can I just use one component and configure everything there?</p>
<p>说话人 1 02:50:21<br>Well, this actually has a benefit because as a user meaning a developer who just wants to deploy their application in the cluster.You don’t care about where the actual storage is you know you want your database to have persistence.And whether the data will leave on the gluster FS or awos or local storage doesn’t matter for you as long as the data is safely stored or if you need a directory storage.For files you don’t care where the directory actually leaves as long as it has enough space and works properly and you sure don’t want to care about setting up these actual storage is yourself, you just want.50 Gigabyte storage for your elastic or 10 Gigabyte for application.That’s it.So you make a claim for storage using PVC and assume that cluster has storage resources.Already, there, and this makes diploid the applications easier for developers because they don’t have to take care of the stuff beyond deploying the applications.</p>
<p>说话人 1 02:51:28<br>Now there are 2 of volume types that I think needs to be mentioned separately because they are a bit different from the rest and these are config map and secret now.If you have watched my other video on components components.Then you are already familiar with both both of them are local volumes.But unlike the rest.These 2 aren’t created via PV and PVC but a rather own components and managed by Kubernetes itself.</p>
<p>说话人 1 02:51:57<br>Consider a case where you need a configuration file for your Prometheus pod.Or maybe a message broker service like mosquito or consider when you need a certificate file mounted inside your application.In both cases, you need a file available to your pod, so how this works is that you create config map or secret component.You can Mount that into your pod and into your container the same way as you would Mount persistent volume claim.So instead you would have a conflict map or secret here and I will show you a demo of this in a video where I cover local volume types.</p>
<p>说话人 1 02:52:37<br>So to quickly summarize what we’ve covered so far.You see at its core volume is just a directory, possibly with some data in it, which is accessible to the containers in a pod how that directory is made available or what storage medium actually.Effects that and the contents of that directory are defined by specific volume type you use?</p>
<p>说话人 1 02:53:03<br>To use in volume apart specifies what volumes to provide for the pod in the specification volumes attribute and inside the pool then you can decide where to Mount.That storage into using volume mounts attribute inside the container section.And this is a path inside the container where application can access whatever storage.We mounted into the container and as I said if you have multiple containers, you can decide.Which container should get access to that storage interesting note for you?Is that a pod can actually use multiple volumes of different types simultaneously.</p>
<p>说话人 1 02:53:47<br>Let’s say you have an elastic search.Application or pod running in your cluster that needs a configuration file mounted through config map needs a certificate.Let’s say client certificate amounted.As a secret Anet needs database storage.Let’s say which is backed with AWS elastic block storage so in this case you can configure all 3 inside your pot.Or Deployement.So this is the part specification that we saw before.And here on the volumes level, you will just list all the volumes that you want to Mount into your pod.So let’s say you have a persistent volume claim that in the background claims.Persistent volume from AWS block storage.</p>
<p>说话人 1 02:54:38<br>And here you have the config map and here have a secret and here in the volume mounts you can list.All those storage mounts using the names right so you have the persistent storage.Then you have the config map and secret and each one of them is mounted to a certain path inside the container.</p>
<p>说话人 1 02:55:00<br>Now we saw that to persist data in communities admins need to configure storage for the cluster create persistent volumes and developers then can claim them, using PC’s but consider cluster with hundreds of applications.Where things get deployed daily and storage is needed for these applications so developers need to ask admins to create persistent volumes.They need for applications before deploying them and admins, then may have to manually request storage from cloud or storage provider.And create hundreds of persistent volumes for all the applications that need storage manually and that can be tedious time consuming and can get messy very quickly.So to make this process more efficient.</p>
<p>说话人 1 02:55:48<br>There is a third component of Kubernetes persistence called storage class storage class basically creates or provisions persistent volumes.Dynamically.Never PVC claims it and this way, creating or provisioning volumes in a cluster.Maybe automated storage class also gets created using Yaml configuration file so this is an example file.We have the kind storage class storage class creates persistent volumes dynamically in the background.So remember, we defined storage back end in the persistent volume component.Now we have to define it.In the storage class component and we do that using the provisioner attribute.</p>
<p>说话人 1 02:56:34<br>Which is the main part of the storage class configuration because it tells Kubernetes which provision are to be used for a specific storage platform or cloud provider to create the persistent.Volume component out of it, so each storage back end has its own provisioner that communities offers internally, which are prefixed with communities dot IO like this one here.</p>
<p>说话人 1 02:57:00<br>And these are internal provisioners and for others or other storage types their external provisioners that you have to then explicitly going find and use that?In your storage class.And in addition to provision or attribute we configure parameters of the storage.We want to request for our persistent volume like this ones here, so storage classes basically another abstraction level.That abstracts the underlying storage provider as well as parameters for that storage characteristics for the storage like what disk type or etc.So how does it work or how do you use?</p>
<p>说话人 1 02:57:41<br>Storage class in the pod configuration same as persistent volume.It is requested or claimed by PVC so in the PVC configuration here we add additional attribute.That is cold storage class name that references the storage class to be used to create a persistent volume that satisfies the claims.Of this PC so now when a pod claims storage through PVC.The PVC will request that storage from storage class, which then will provision or create.Persistent volume that meets the needs of that claim using provisioner from the actual storage back end now.</p>
<p>说话人 1 02:58:29<br>This should help you understand the concepts of how data is persisted in communities.Is a high level overview?In this video we’re going to talk about what stateful settings.In Kubernetes, an what purpose.It has So what is stateful set its accumulated component that is used specifically for stateful applications?So, in order to understand that first you need to understand what a stateful application is examples of stateful applications are all databases like my SQL Elasticsearch mongo DB etc.Or any application that stores data to keep track of its state in other words.These are applications that tracks state by saving that information in some storage stateless applications on the other hand.Do not keep records of previous interaction in each request or interaction is handled as a completely new isolated interaction based entirely on the information that comes with it.And sometimes stateless applications connect to the stateful application to forward those requests.</p>
<p>说话人 1 02:59:40<br>So imagine a simple setup of a node JS application that is connected to Mongo.Db database when a request comes into the node JS application.It doesn’t depend on any previous data to handle this incoming.Request it can handle it based on the payload in the request itself.Now a typical such request will Additionally need to update some data in the database or query.The data that’s where mongo DB comes in.So when node JS forwards that request to Morgan to be.Mongo DB will update the data based on its previous state or query.The data from its storage so for each request.It needs to handle data and obviously always depends on the most up to date data.Or state to be available while node JS is just a pass through for data updates or queries and it just processes code.</p>
<p>说话人 1 03:00:37<br>Now, because of this difference between stateful and stateless applications.There both diploid different ways, using different components in Kubernetes stateless applications.Are diploid using deployment component but deployment?Is an abstraction of parts an allows you to replicate that application meaning run 2510 identical parts of the same stateless application.In the cluster so while stateless applications are diploid using deployement stateful applications in Kubernetes are diploid using stateful set components in just like deployments stateful set makes it possible to replicate this stateful.Yep, parts or to run multiple replicas of it in other words, they both manage parts that are based on an identical container specification.And you can also configure storage with both of them equally in the same way so if both manage the replication of pots and also configuration of data persistence in the same way.</p>
<p>说话人 1 03:01:47<br>The question is what a lot of people ask in are also often confused about what is the difference between those 2 components?Why we use different ones for each type of application so in the next section.We’re going to talk about that.Difference is now replicating stateful application is more difficult and has a couple of requirements that stateless.</p>
<p>说话人 1 03:02:09<br>Applications do not have so let’s look at this first with the example of my SQL database.Let’s say you have one my SQL database pod that handles requests from a Java application, which is deployed using a deployment component and let’s say you scale the Java application to 3 parts.So they can handle more client requests in parallel.You want to scale my SQL app.So we can handle more Java requests as well, scaling your Java application here is pretty straightforward Java.Applications replica parts will be identical and interchangeable so you can scale it.</p>
<p>说话人 1 03:02:49<br>Using the deployment pretty easily deployment will create the pods in any order in any random order.They will get random hashes at the end of the pod name, they will get one service that load balances to any one of the replica parts.For any requests and also when you delete them.They get deleted in a random order or at the same time right or when he scaled them down from 3 to 2 replicas for example, one random replica part gets.Chosen to be deleted so no.Vacations there on the other hand, my SQL pod.Replicas cannot be created and deleted at the same time in any order and they can’t be randomly addressed and the reason for that is.Because the replica parts are not identical.In fact, they each have their own additional identity on top of the common blueprint of the part that they get created from.Giving each part its own required individual identity is actually what stateful set does different from deployment.It maintains a sticky identity for each of its parts.And as I said, these pods are created from the same specification, but they’re not interchangeable.Each has a persistent identifier that it maintains across in a rescheduling so meaning when pod dies.And gets replaced by new part it keeps their identity so the question you may be asking now is why do these parts need their own identities?Why they can’t be interchangeable just like with deployment so why is that?</p>
<p>说话人 1 03:04:28<br>And this is a concept that you need to understand about scaling database applications in general.When you start with a single my SQL pod.It will be used for both reading and writing data.But when you add a second one, it cannot act the same way because if you allow 2 independent instances of my SQL.To change the same data you will end up with data inconsistency so instead.There is a mechanism that decides that only one.Paul is allowed to write or change the data, which is shared.Reading at the same time by multiple parts my SQL instances from the same.Data is completely fine and the part that is allowed to update the data is called the master the others are called slaves.So this is the first thing that differentiates these parts from each other so not all ports are same identical.But there is a must pot and then the slave parts right and there is also difference between those slave parts.</p>
<p>说话人 1 03:05:29<br>Terms of storage, which is the next point, so The thing is that this pods do not have access to the same physical storage.Even though they use the same data.They’re not using the same physical storage.Of the data.They each have their own replicas of this storage that each one of them can access for itself, and this means that each pod replica at anytime must have the same data as the other ones.And in order to achieve that they have to continuously synchronize their data and since Master is the only one allowed to change data and the slaves need to take care of their own data storage.Obviously, the slaves must know about.Each such change, so they can update their own data storage to be up to date for the next query requests and there is a mechanism in such clustered database setup that allows for continuous data.</p>
<p>说话人 1 03:06:26<br>Pronunciation.Master changes data and all slaves update their own data storage to keep In Sync and to make sure that each pod has the same state now let’s say you have one master into slave parts.</p>
<p>说话人 1 03:06:41<br>Of my SQL now, what happens when a new pod replica joins the existing setup because now that new pod also needs to create its own storage and then take care of synchronizing it?</p>
<p>说话人 1 03:06:54<br>What happens is that it first.Close the data from the previous part, not just any part in the in.Set up but always from the previous part in once it has the up-to-date data cloned it starts continuous synchronization as well to listen for any updates by must report and this also means an I want to point this out since it’s pretty interesting.</p>
<p>说话人 1 03:07:15<br>Point.It means that you can actually have a temporary storage for a stateful application and not persist.The data at all since the data gets replicated between the pots, so theoretically.It is possible to just rely on data replication.</p>
<p>说话人 1 03:07:31<br>Between the pots, but this will also mean that the whole data will be lossed when all the pods die, so for example, if stateful set gets deleted or the cluster crashes or all the nodes where these pod replicas are running crash.And every pod dice at the same time, the data will be gone and therefore it’s still a best practice to use data persistence for stateful applications.If losing the data will be unacceptable, which is the case in most database applications.And with persistent storage data will survive, even if all the parts of the stateful set dying or even if you delete the complete stateful set component in all the parts get wiped out as well.The persistent storage and the data will still remain because persistent volume.Lifecycle isn’t connected or isn’t tide to life cycle of other components like?Deployment or stateful set and the way to do this is configuring persistent volumes for your stateful set and since each pod has its own data storage.Meaning it’s the.Own persistent volume that is then picked up by its own physical storage, which includes the synchronized data or the replicated database data but also the state of the pod so each pod.Has its own state, which has information about whether it’s a master port or a slave or other individual characteristics and all of these get stored in the pods own storage.And that means when a pot dies and gets replaced the persistent pot.Identifiers make sure that the storage volume gets reattached to the replacement pot.Is a sad because that storage has the state of the pod?In addition to that replicated data.I mean, you can clone the data again.There will be no problem.But it shouldn’t lose its state or identity state so to say, and for this reattachment to work.It’s important to use a remote storage because if the pod gets rescheduled from OneNote to another node.The previous storage must be available on the other node as well, and you cannot do that using local.</p>
<p>说话人 1 03:09:52<br>Volume storage because they are usually tide to a specific node and the last difference between deployment and stateful set is something that I mentioned before is the pot identifier.Meaning that every pod has its own identifier so unlike deployment, where parts get random hashes at the end stateful set parts get fixed ordered names, which is made up of the stateful set name.In the ordinal it starts from zero and each additional part will get the next numeral.So if you create a stateful set called my SQL with 3 replicas.You’ll have parts with names must equal 01 and 2.The first one, is the Master and then come the slaves in the order of start up an important note here is that?The stateful set will not create the next pod in the replica if the previous one isn’t already up and running if first pod creation for example, failed.Or if it was pending the next one won’t get created at all.It would just wait in the same order is held deletion.But in reverse order so for example, if you delete the stateful set or if you scaled it down too.One for example, from 3, the deletion will start from the last pot.So my SQL tool deleted first it will wait until that part is successfully deleted and then it will delete my SQL.One and then it will delete my SQL zero and again.</p>
<p>说话人 1 03:11:24<br>All these mechanisms are in place in order to protect the data and the state that this stateful application depends on in addition to this.Fixed predictable names each pod in a stateful set gets its own DNS endpoint from a service so there’s a service name for the stateful application just like for deployement for example, that will address any.Replica pot and plus.</p>
<p>说话人 1 03:11:50<br>In addition to that there is individual DNS name for each pod, which deployement pods do not have the individual DNS names are made up of pod name and.The manage of the governing service name, which is basically a service name that you define inside the stateful set so these 2 characteristics, meaning having a predictable or fixed.Name as well as its fixed individual DNS name means that when pod restarts.The IP address will change.But the name in endpoint will stay the same.That’s why it said pods get sticky identities so it.Gets stuck to it, even between the restarts and the sticky identity makes sure that each replica pod can retain its state and its role.Even when it dies and gets recreated and finally I want to mention important point here.Is it see replicating stateful apps like databases with its persistent storage requires a complex mechanism in Kubernetes helps you and supports you to set this whole thing up, but you still need to do.A lot by yourself with Kubernetes doesn’t actually help you or doesn’t provide you out of the box solutions.For example, you need to configure the cloning and data synchronization inside the stateful set and also make the remote storage available.As well as take care of managing and backing it up all of this, you have to do yourself and the reason is that stateful applications are not a perfect candidate for containerized environments.In fact, Docker Kubernetes and generally containerization.Is perfectly fitting for stateless applications that do not have any state data dependency and only process code so scaling and replicating them in containers is super easy.</p>
<p>说话人 1 03:13:46<br>In this video I will give you a complete overview of Kubernetes Services first.I’ll explain shortly.What service component is in Kubernetes and when we need it and then we’ll go through the different service types.Cluster IP service headless service note port and load balancer services.I will explain the differences between them.And when to use which 10 by the end of the video you will have a great understanding.Of community services and will be able to use them in practice, so let’s get started.So.What is the service in Kubernetes in?</p>
<p>说话人 1 03:14:21<br>Why do we need it in Kubernetes cluster each part gets its own internal IP address but the pods in communities are ephemeral, meaning that they come and go very frequently.And when the pod restarts or when old one dies and the new one gets started in its place.It gets a new IP address.So it doesn’t make sense to use pot IP addresses directly because then you would have to adjust that.Every time the pod gets recreated with the service.However, you have a solution of a stable or static IP address that stays even when the pod dies, so basically in front of each pod, we set a service.Which represents a persistent stable IP address excess that pod service also provides load balancing because when you have pod replicas for example, 3 replicas of your micro service application.Or 3 replicas of my SQL application.The service will basically get each request target to that my SQL or your microservice application and then forwarded to one of those.Parts so clients can call a single stable IP address instead of calling each pod individually so services are a good abstraction for loose coupling for communication within the cluster.So within the cluster components or parts inside the cluster, but also from external services like if you have browser requests coming to the cluster or if you’re talking to an external database for example.</p>
<p>说话人 1 03:15:56<br>There are several types of services in Kubernetes, the first and the most common one that you probably will use most of the time is the cluster IP type.This is a default type of service.Meaning when you create a service and not specify type.It will automatically take cluster.Ip is a type so let’s see how cluster IP works an where it’s used in Kubernetes setup.Imagine we have a micro service application deployed in the cluster so we have a pod with microservice container running inside that pod and beside that microservice container we have.A sidecar container that collects the logs of the microservice and then sends that to some destination database.So these 2 containers are running in the pot and let’s say your microservice container is running at pod.3000 and you’re logging container.Let’s say is running on port 9000.This means that those 2 ports will be now open and accessible inside the pot.And pod will also get an IP address from a range that is assigned to a note.So the way it works is that if you have for example, 3 worker nodes in your community.Cluster each worker node will get a range of IP addresses, which are internal in the cluster so for example, the pod.One will get IP addresses from a range of 10.2, .1.Onwards the second worker node will get this IP range and the third worker node will get this one.So let’s say this pod starts on node 2.So it get IP address that looks like this, if you want to see the IP addresses of.Your pods in the cluster you can actually check them using cubes.</p>
<p>说话人 1 03:17:51<br>A tailgate pod.Output wide command where you will get some extra information about the pods, including its IP address in here.See the IP address that it got it signed and as I mentioned these are from the IP address range that each worker node in the cluster will get so this is from the first worker node and these are from the second worker node.So now we can access those containers inside the pot.If this IP address at these ports if we set the replica count to 2.We’re going to have another pod, which is identical to the first one, which will open the same.Ports and it will get a different IP address.Let’s say if it starts on worker node.One you will get an IP address that looks something like this.</p>
<p>说话人 1 03:18:37<br>Now let’s say this microservices accessible through a browser.So we have Ingress configured and the requests coming in from the browser to the micro service will be handled by Ingress?How does this incoming request get forwarded from Ingress?All the way to the pod and that happens through a service.</p>
<p>说话人 1 03:18:59<br>A cluster IP or so-called internal service.A service in Kubernetes is a component just like a pod, but it’s not a process.It’s just an abstraction layer that basically represents an IP address so service will get an IP address that it is iaccessible at and service will also be accessible at a certain port.</p>
<p>说话人 1 03:19:20<br>Let’s say we define that.For it to be 3200 so Ingress will talk to the service or hand over the request to the service at this IP address at this port so this is how service is.Accessible within the cluster so the way it works is that we define Ingress rules that forward the request based on the request address to certain services and we define the service by.Its name and the DNS resolution than Maps.That service name to an IP address that this service actually got assigned so this is how Ingress knows.How to talk to the service so once the request gets handed over to the service at this address and service will know to forward that request to one of those parts that are registered as.</p>
<p>说话人 1 03:20:15<br>The service endpoints now here 2 questions how does ServiceNow which pods it is managing or which parts to forward the request to and the second one is how the service know which port.To forward that request 2 on that specific pod.The first one, is defined by selectors as service identifies its member pots or its endpoint parts using selector attribute zero in the service specification.</p>
<p>说话人 1 03:20:47<br>Yellow file from which we create the service.We specify the selector attribute that has a key value pairs defined as least now.This key value pairs are basically labels that pots should have.To match that selector so in the pod configuration file we assign the pod.Certain labels in the metadata section and this labels can be arbitrary name.So we can say my app for example.And give it some other labels.This is basically something that we define ourselves.We can give it any name that we want.These are just key value pairs that identify a set of pots and in the service animal file then we define a selector.To match any part that has all of these labels.This means if we have a deployment component that creates 3 replicas of pots with label called app my app.And type micro service for example, an in service selector attribute.We define those 2 labels then service will match all of those, 3 pod replicas and it will register all 3 parts.As its endpoints and as I said it should match all the selectors, not just one so this is how service will know which parts belong to it, meaning where to forward that request to.</p>
<p>说话人 1 03:22:07<br>The second question was if a part has multiple ports open with 2 different applications are listening inside the pod.How does ServiceNow?Which ports to forward the request to and this is defined?In the target port attribute so this target port attribute so let’s say target port in our example is 3000.What this means is that when we create the service.It will find all the parts.That match this selector so this ports will become endpoints of the service and when the service gets a request.It will pick one of those pod replicas randomly because it’s a load balancer and it will send the request.Received to that specific pod on a port defined by Target.Port attribute in this case 3000.</p>
<p>说话人 1 03:23:00<br>Also note that when you create a service.Kubernetes creates an endpoints object that has the same name as the service itself.An Kubernetes will use these endpoints object to keep track of which pods are members of the service.Or as I said, which parts are the endpoints of the service and since this is dynamic because whenever you create a new pod replica or a pod dies.The endpoints get updated so this object will basically track that.And note here that the service port itself is arbitrary so you can define it yourself, whereas the target port is not arbitrary.It has to match the port where container the application container inside the pod.Is listening at now let’s say our microservice application got its request from the browser through Ingress.An internal cluster IP service and now it needs to communicate with the database.To handle that request for example, an in our example.Let’s assume that the Micro Service application uses.</p>
<p>说话人 1 03:24:08<br>Mongo DB database.So we have 2 replicas of mongo DB in the cluster which.Also have their own service endpoint so mongo DB service is also of cluster IP and it has its own IP address so now the microservice application inside the pod.Can talk to the mongo DB database also using the service endpoint so the request will come from one of the parts that gets the request from the service to the mongo DB service.At this IP address and the port that service has open and the service will again select one of those pod replicas and forward that request to the selected pod.It’s the port the target port defined here and this is the port where mongo DB application inside the pod is listening at now let’s assume that inside that mongo DB pod.There is another container running that selects the monitoring metrics for Prometheus for example.And that will be a mongo DB Explorer and that container.Let’s say is running at port now.Thousand 216 and this is where the application is accessible at an in the cluster.We have a Prometheus application that scrapes.The metrics endpoint from this mongo DB exporter container.</p>
<p>说话人 1 03:25:34<br>From this end point now that means that service has to handle 2 different endpoint requests, which also means that service has 2 of its own ports open.For handling these 2 different requests one from the clients that want to talk to the mongo.Db database and one from the clients like Prometheus that want to talk to the mongo DB export are application.And this is an example of a multi port Service, an note here.That’s when you have multiple ports defined in a service, you have to name those ports if it’s just one port then you can.Leave it so to say anonymous you don’t have to use the name attribute it’s optional.But if you have multiple ports defined.Then you have to name each one of those so these were examples of cluster IP service type.</p>
<p>说话人 1 03:26:28<br>Now let’s see another service type, which is called headless service.So let’s see what headless service type is as we saw each request to the service is forwarded to one of the pod replicas.That are registered as service endpoints.</p>
<p>说话人 1 03:26:44<br>But imagine if a client wants to communicate with one of the parts directly and selectively or what, if the endpoint pods need to communicate with each other directly.Without going through the service, obviously in this case, it wouldn’t make sense to talk to the service endpoint, which will randomly select one of the pots because we want the communication with specific pots now, what would be such a use case.A use case where this is necessary is when we are deploying stateful applications in Kubernetes.</p>
<p>说话人 1 03:27:18<br>Stateful applications like databases.My SQL Mongo.Db Elasticsearch and so on in such applications that pod replicas.Aren’t identical but rather each one has its individual state and characteristic for example.If we’re deploying a my SQL application.You would have a master instance of my SQL an worker instances.Of my SQL application and master is the only part allowed to write to the database and the worker pods must connect to the Master to synchronize their data after master pod has.Made changes to the database so they get the up-to-date data as well, an when new worker pod starts.It must connect directly to the most recent worker node to clone the data from.Anne also get up to date with the data state so that’s the most common use case where you need direct communication with individual pots for such case for client to connect to all parts.Individually, it needs to figure out the IP address of each individual pod.</p>
<p>说话人 1 03:28:26<br>One option to achieve.This would be to make an API call to coordinate this API server.And it will return the list of parts and their IP addresses.But this will make your application to tide to the Kubernetes specific API and also this will be inefficient because you will have to get.The whole list of parts and their IP addresses every time you want to connect to one of the parts.</p>
<p>说话人 1 03:28:51<br>But as an alternative solution Kubernetes allows clients to discover pot IP addresses through DNS.Look up.Ann usually the way it works is that when a client performs a DNS.Look up for a service.The DNS server returns a single IP address, which belongs to the service and this will be this services cluster IP address.Which we saw previously however if you tell Kubernetes that you don’t need a cluster IP address of the service by setting the cluster.Ip field to none when creating this service, then the DNS server will return the pot IP addresses instead.Of the services IP address another client can do a simple DNS.Look up to get the IP address of the pods that are members of that service and then client can use that IP address to connect to.The specific party wants to talk to or all of the parts, so the way we define a headless service in a service configuration file is basically setting the cluster IP to none.So when we create these service from this configuration file.Bernese will not assign the service at cluster IP address.And we can see that in the output when I list.</p>
<p>说话人 1 03:30:08<br>My services so I have a cluster.Ip service that I created for the microservice.Anna headless service and note here that when we deploy stateful applications.In the cluster like Mongo, DB for example, we have the normal service that cluster.Ip service that basically handles the communication to mongo DB and maybe other container inside the pod.And in addition to that service we have a headless service.So we always have these 2 services alongside each other so this can do the usual load balancing stuff for these kind of use case and.</p>
<p>说话人 1 03:30:47<br>For use cases where client needs to communicate with one of those parts directly like a master node directly to perform the right commands or the parts to talk to each other for data synchronization.The headless service will be used for that.</p>
<p>说话人 1 03:31:04<br>When we define a service configuration, we can specify a type of the service and the type attribute can have 3 different values.It could be cluster IP which is the default.That’s why we don’t have to specify that we have node port and load balancer.So type node.Port basically creates a service that is accessible on aesthetic port on each worker node in the cluster.</p>
<p>说话人 1 03:31:30<br>Not to compare that to our previous example.The cluster IP services only accessible within the cluster itself, so no external traffic can directly address the cluster IP service.The node port service, however, makes the external traffic accessible on static or fixed port on each worker node so in this case instead of Ingress, the browser requests will come directly.</p>
<p>说话人 1 03:31:59<br>To the worker node at the port that the service specification defines in the port that note port service type exposes is defined in the node port attribute.And here note that the note port value has a predefined range between 30,032 thousand 767.So you can have one of the values from that range.As a note port value anything outside that range won’t be accepted so this means that the node.</p>
<p>说话人 1 03:32:33<br>Port services accessible for the external traffic like browser requests for example, add IP address of the work.Note and the note port defined here, however, just like in cluster IP.We have a port of the service.So when we create the node port service.A cluster IP service to which node port service will.Wrote is automatically created and here as you see if I list the services.The note port will have the cluster IP address and for each IP address.It will also have the ports open where the service is iaccessible at and also note that service spends all the worker nodes.So if you have 3 pod replicas on 3 different nodes.Basically, the service will be able to handle that request coming on any of the worker nodes and then forward it to one of those.</p>
<p>说话人 1 03:33:26<br>Pod replicas.Now that type of service exposure is not very efficient and also not secure because you are basically opening the ports to directly talk to the services on each worker node so the external clients basically.Have access to the worker nodes directly so if we gave all the services.</p>
<p>说话人 1 03:33:46<br>This node port service.Type then we would have a bunch of ports open on the worker nodes clients from outside can directly talk to.It’s not very efficient and secure way to handle that and is a better alternative.</p>
<p>说话人 1 03:34:00<br>There is a load balancer service type and the way it works with load balancer service type is that the service becomes accessible externally.Through a cloud providers load balancer functionality so each cloud provider has its own native load balancer implementation and that is created and used whenever we create a load balancer service type.</p>
<p>说话人 1 03:34:22<br>Google cloud platform, WS Azure Linode open stack and so on.All of them offer.This functionality so whenever we create a load balancer service.Note Portan cluster.I services are created.Automatically by Kubernetes to which the external load balancer of the cloud platform will route the traffic too.And this is an example of how we define load balancer service configuration so instead of node port type.We have a load balancer and the same way we have the port of the service, which belongs to the cluster IP.And we have the note port, which is the port that opens in the worker node.But it’s not directly accessible externally but only through the load balancer itself, so the entry point becomes a load balancer first.And it can then direct the traffic to node port on the worker node and the cluster.Ip the internal service, so that’s how the flow would work with a load balancer service.So, in other words, the load balancer service type is an extension of the node port type, which itself is an extension of the cluster.</p>
<p>说话人 1 03:35:34<br>Ip type and again if I create a load balancer service type.And least all the services you consider differences in the display as well, where for each service type.You see the IP addresses.You see the type and you see the ports that the service has opened.</p>
<p>说话人 1 03:35:54<br>An I should mention here that in a real community set of example.You would probably not use node port for external connection.You would maybe use it to test some service very quickly but not for production use cases.So for example, if you have a application that is iaccessible through browser.You will either configure Ingress for each such request.So you would have internal services, the cluster IP services that Ingress.Will Route 2 or you would have a load balancer that uses the cloud platforms.</p>
<p>说话人 1 03:36:24<br>Native load balancer implementation congratulations.You made it to the end.I hope you learned a lot and got some valuable knowledge from this course.If you want to learn about modern DevOps tools be sure to check out my tutorials on that topic and subscribe to my channel for more content.Also, if you want to stay connected.You can follow me on social media or join the private Facebook group.I would love to see you there, so thank you for watching and see you in the next video.</p>
]]></content>
      <categories>
        <category>学习</category>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>云原生</tag>
      </tags>
  </entry>
</search>
